{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uTv0D26B9W2h"
   },
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O9VX-OHxC1FM"
   },
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "id": "oODLwt1QzgGa"
   },
   "outputs": [],
   "source": [
    "#@title Link your assignment folder & install requirements\n",
    "#@markdown Enter the path to the assignment folder in your Google Drive\n",
    "# If you run this notebook locally or on a cluster (i.e. not on Google Colab)\n",
    "# you can delete this cell which is specific to Google Colab. You may also\n",
    "# change the paths for data/logs in Arguments below.\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "\n",
    "\n",
    "# Install requirements\n",
    "!pip install -qr requirements.txt\n",
    "\n",
    "# Check if CUDA is available\n",
    "import torch\n",
    "if not torch.cuda.is_available():\n",
    "  warnings.warn('CUDA is not available.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dt3NTvpsy4Oc"
   },
   "source": [
    "### Running on GPU\n",
    "For this assignment, it will be necessary to run your experiments on GPU. To make sure the notebook is running on GPU, you can change the notebook settings with\n",
    "* (EN) `Edit > Notebook Settings`\n",
    "* (FR) `Modifier > ParamÃ¨tres du notebook`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "RLVSmv9HoMH5"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import urllib.request\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from lstm_solution import LSTM\n",
    "from gpt1_solution import MiniGPT1\n",
    "from utils.wikitext2 import Wikitext2\n",
    "from utils.torch_utils import seed_experiment, to_device\n",
    "from utils.data_utils import save_logs\n",
    "from run_exp import train, evaluate\n",
    "\n",
    "EMBEDDINGS_URL = \"https://ift6135-h2021.s3.us-east-2.amazonaws.com/assignment2/embeddings.npz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MZr3Fh-qaGAZ"
   },
   "source": [
    "## Public tests\n",
    "Run the following cell in order to run the public tests to check to tensor shapes of the outputs of your functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "GRwCZpSaaE9V"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........\n",
      "----------------------------------------------------------------------\n",
      "Ran 10 tests in 0.765s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python -m unittest discover -s ./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-PtvL_yKp3PW"
   },
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iWiJme7XaLiR"
   },
   "source": [
    "Below we define a few default arguments to get you started with your experiments. You are encouraged to modify the function `main()`, as well as these arguments, to fit your needs (e.g. changing hyperparameters, the optimizer, adding regularization, adding logs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "YUrqebfCobD1"
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Arguments:\n",
    "  # Data\n",
    "  data_folder: str = './data'\n",
    "  batch_size: int = 16\n",
    "\n",
    "  # Model\n",
    "  model: str = 'lstm'  # [lstm, gpt1]\n",
    "  embeddings: str = './data/embeddings.npz'\n",
    "  layers: int = 1\n",
    "\n",
    "  # Optimization\n",
    "  optimizer: str = 'adamw'  # [sgd, momentum, adam, adamw]\n",
    "  epochs: int = 10\n",
    "  lr: float = 1e-3\n",
    "  momentum: float = 0.9\n",
    "  weight_decay: float = 5e-4\n",
    "\n",
    "  # Experiment\n",
    "  exp_id: str = 'debug'\n",
    "  log: bool = True\n",
    "  log_dir: str = './logs'\n",
    "  seed: int = 42\n",
    "\n",
    "  # Miscellaneous\n",
    "  num_workers: int = 2\n",
    "  device: str = 'cuda'\n",
    "  progress_bar: bool = False\n",
    "  print_every: int = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ntfY6yyad_F"
   },
   "source": [
    "The 12 configurations you need to run in Problem 3. Be careful that there is no discrepency between the configurations defined in `run_exp.py` and the ones below. In case there is a difference, the version from `run_exp.py` should be considered the ones to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-q6AwUVDX78-"
   },
   "outputs": [],
   "source": [
    "# Note: if there is any discrepency with the configurations in run_exp.py, the\n",
    "# version from run_exp.py should be the ones to use in Problem 3.\n",
    "configs = {\n",
    "  1: Arguments(model='lstm', layers=1, batch_size=16, log=True, epochs=10, optimizer='adam'),\n",
    "  2: Arguments(model='lstm', layers=1, batch_size=16, log=True, epochs=10, optimizer='adamw'),\n",
    "  3: Arguments(model='lstm', layers=1, batch_size=16, log=True, epochs=10, optimizer='sgd'),\n",
    "  4: Arguments(model='lstm', layers=1, batch_size=16, log=True, epochs=10, optimizer='momentum'),\n",
    "\n",
    "  5: Arguments(model='gpt1', layers=1, batch_size=16, log=True, epochs=10, optimizer='adam'),\n",
    "  6: Arguments(model='gpt1', layers=1, batch_size=16, log=True, epochs=10, optimizer='adamw'),\n",
    "  7: Arguments(model='gpt1', layers=1, batch_size=16, log=True, epochs=10, optimizer='sgd'),\n",
    "  8: Arguments(model='gpt1', layers=1, batch_size=16, log=True, epochs=10, optimizer='momentum'),\n",
    "\n",
    "  9: Arguments(model='lstm', layers=2, batch_size=16, log=True, epochs=10, optimizer='adamw'),\n",
    "  10: Arguments(model='lstm', layers=4, batch_size=16, log=True, epochs=10, optimizer='adamw'),\n",
    "  11: Arguments(model='gpt1', layers=2, batch_size=16, log=True, epochs=10, optimizer='adamw'),\n",
    "  12: Arguments(model='gpt1', layers=4, batch_size=16, log=True, epochs=10, optimizer='adamw'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "g2rjoY-5phTY"
   },
   "outputs": [],
   "source": [
    "def main(args):\n",
    "  # Seed the experiment, for repeatability\n",
    "  seed_experiment(args.seed)\n",
    "\n",
    "  # Dataloaders\n",
    "  train_dataset = Wikitext2(args.data_folder, split=\"train\")\n",
    "  train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=args.num_workers,\n",
    "  )\n",
    "\n",
    "  valid_dataset = Wikitext2(args.data_folder, split=\"validation\")\n",
    "  valid_dataloader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=args.num_workers,\n",
    "  )\n",
    "\n",
    "  test_dataset = Wikitext2(args.data_folder, split=\"test\")\n",
    "  test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=args.num_workers,\n",
    "  )\n",
    "\n",
    "  # Download the embeddings\n",
    "  if not os.path.isfile(args.embeddings):\n",
    "    print(\"Downloading embeddings...\")\n",
    "    urllib.request.urlretrieve(EMBEDDINGS_URL, args.embeddings)\n",
    "\n",
    "  # Model\n",
    "  if args.model == \"lstm\":\n",
    "    model = LSTM.load_embeddings_from(\n",
    "      args.embeddings, hidden_size=512, num_layers=args.layers\n",
    "    )\n",
    "  elif args.model == \"gpt1\":\n",
    "    model = MiniGPT1.load_embeddings_from(\n",
    "      args.embeddings, num_layers=args.layers\n",
    "    )\n",
    "  else:\n",
    "    raise ValueError(\"Unknown model {0}\".format(args.model))\n",
    "  model.to(args.device)\n",
    "\n",
    "  # Optimizer\n",
    "  if args.optimizer == \"adamw\":\n",
    "    optimizer = optim.AdamW(\n",
    "      model.parameters(), lr=args.lr, weight_decay=args.weight_decay\n",
    "    )\n",
    "  elif args.optimizer == \"adam\":\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "  elif args.optimizer == \"sgd\":\n",
    "    optimizer = optim.SGD(\n",
    "      model.parameters(), lr=args.lr, weight_decay=args.weight_decay\n",
    "    )\n",
    "  elif args.optimizer == \"momentum\":\n",
    "    optimizer = optim.SGD(\n",
    "      model.parameters(),\n",
    "      lr=args.lr,\n",
    "      momentum=args.momentum,\n",
    "      weight_decay=args.weight_decay,\n",
    "    )\n",
    "\n",
    "  print(\n",
    "    f\"Initialized {args.model.upper()} model with {sum(p.numel() for p in model.parameters())} \"\n",
    "    f\"total parameters, of which {sum(p.numel() for p in model.parameters() if p.requires_grad)} are learnable.\"\n",
    "    f\"args are: {args}\"  \n",
    "  )\n",
    "\n",
    "  train_losses, valid_losses = [], []\n",
    "  train_ppls, valid_ppls = [], []\n",
    "  train_times, valid_times = [], []\n",
    "  for epoch in range(args.epochs):\n",
    "\n",
    "    tqdm.write(f\"====== Epoch {epoch} ======>\")\n",
    "\n",
    "    loss, ppl, wall_time = train(epoch, model, train_dataloader, optimizer, args)\n",
    "    train_losses.append(loss)\n",
    "    train_ppls.append(ppl)\n",
    "    train_times.append(wall_time)\n",
    "\n",
    "    loss, ppl, wall_time = evaluate(epoch, model, valid_dataloader, args)\n",
    "    valid_losses.append(loss)\n",
    "    valid_ppls.append(ppl)\n",
    "    valid_times.append(wall_time)\n",
    "\n",
    "  test_loss, test_ppl, test_time = evaluate(\n",
    "    epoch, model, test_dataloader, args, mode=\"test\"\n",
    "  )\n",
    "\n",
    "  print(f\"===== Best validation perplexity: {min(valid_ppls):.3f} =====>\")\n",
    "\n",
    "  return (\n",
    "    train_losses,\n",
    "    train_ppls,\n",
    "    train_times,\n",
    "    valid_losses,\n",
    "    valid_ppls,\n",
    "    valid_times,\n",
    "    test_loss,\n",
    "    test_ppl,\n",
    "    test_time,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ZyJPWO1ppcTx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized LSTM model with 34107392 total parameters, of which 3019520 are learnable.\n",
      "====== Epoch 0 ======>\n",
      "[TRAIN] Epoch: 0, Iter: 0, Loss: 10.60695\n",
      "[TRAIN] Epoch: 0, Iter: 10, Loss: 8.43617\n",
      "[TRAIN] Epoch: 0, Iter: 20, Loss: 7.88891\n",
      "[TRAIN] Epoch: 0, Iter: 30, Loss: 7.69509\n",
      "[TRAIN] Epoch: 0, Iter: 40, Loss: 7.58836\n",
      "[TRAIN] Epoch: 0, Iter: 50, Loss: 7.54249\n",
      "[TRAIN] Epoch: 0, Iter: 60, Loss: 7.41036\n",
      "[TRAIN] Epoch: 0, Iter: 70, Loss: 7.34132\n",
      "[TRAIN] Epoch: 0, Iter: 80, Loss: 7.20208\n",
      "[TRAIN] Epoch: 0, Iter: 90, Loss: 7.13149\n",
      "[TRAIN] Epoch: 0, Iter: 100, Loss: 7.08324\n",
      "[TRAIN] Epoch: 0, Iter: 110, Loss: 7.00574\n",
      "[TRAIN] Epoch: 0, Iter: 120, Loss: 7.02443\n",
      "[TRAIN] Epoch: 0, Iter: 130, Loss: 6.97269\n",
      "[TRAIN] Epoch: 0, Iter: 140, Loss: 6.92367\n",
      "[TRAIN] Epoch: 0, Iter: 150, Loss: 6.70746\n",
      "[TRAIN] Epoch: 0, Iter: 160, Loss: 6.64843\n",
      "[TRAIN] Epoch: 0, Iter: 170, Loss: 6.78570\n",
      "[TRAIN] Epoch: 0, Iter: 180, Loss: 6.72047\n",
      "[TRAIN] Epoch: 0, Iter: 190, Loss: 6.65904\n",
      "[TRAIN] Epoch: 0, Iter: 200, Loss: 6.53216\n",
      "[TRAIN] Epoch: 0, Iter: 210, Loss: 6.69315\n",
      "[TRAIN] Epoch: 0, Iter: 220, Loss: 6.59130\n",
      "[TRAIN] Epoch: 0, Iter: 230, Loss: 6.62703\n",
      "[TRAIN] Epoch: 0, Iter: 240, Loss: 6.56969\n",
      "[TRAIN] Epoch: 0, Iter: 250, Loss: 6.58871\n",
      "[TRAIN] Epoch: 0, Iter: 260, Loss: 6.44787\n",
      "[TRAIN] Epoch: 0, Iter: 270, Loss: 6.46430\n",
      "[TRAIN] Epoch: 0, Iter: 280, Loss: 6.49778\n",
      "[TRAIN] Epoch: 0, Iter: 290, Loss: 6.47434\n",
      "[TRAIN] Epoch: 0, Iter: 300, Loss: 6.46833\n",
      "[TRAIN] Epoch: 0, Iter: 310, Loss: 6.29399\n",
      "[TRAIN] Epoch: 0, Iter: 320, Loss: 6.42970\n",
      "[TRAIN] Epoch: 0, Iter: 330, Loss: 6.33460\n",
      "[TRAIN] Epoch: 0, Iter: 340, Loss: 6.23785\n",
      "[TRAIN] Epoch: 0, Iter: 350, Loss: 6.38792\n",
      "[TRAIN] Epoch: 0, Iter: 360, Loss: 6.26581\n",
      "[TRAIN] Epoch: 0, Iter: 370, Loss: 6.26148\n",
      "[TRAIN] Epoch: 0, Iter: 380, Loss: 6.18509\n",
      "[TRAIN] Epoch: 0, Iter: 390, Loss: 6.35488\n",
      "[TRAIN] Epoch: 0, Iter: 400, Loss: 6.17337\n",
      "[TRAIN] Epoch: 0, Iter: 410, Loss: 6.10148\n",
      "[TRAIN] Epoch: 0, Iter: 420, Loss: 6.21699\n",
      "[TRAIN] Epoch: 0, Iter: 430, Loss: 6.11806\n",
      "[TRAIN] Epoch: 0, Iter: 440, Loss: 6.07455\n",
      "[TRAIN] Epoch: 0, Iter: 450, Loss: 6.07404\n",
      "[TRAIN] Epoch: 0, Iter: 460, Loss: 5.97589\n",
      "[TRAIN] Epoch: 0, Iter: 470, Loss: 6.09834\n",
      "[TRAIN] Epoch: 0, Iter: 480, Loss: 5.98227\n",
      "[TRAIN] Epoch: 0, Iter: 490, Loss: 5.97386\n",
      "[TRAIN] Epoch: 0, Iter: 500, Loss: 6.01093\n",
      "[TRAIN] Epoch: 0, Iter: 510, Loss: 5.99318\n",
      "[TRAIN] Epoch: 0, Iter: 520, Loss: 6.10881\n",
      "[TRAIN] Epoch: 0, Iter: 530, Loss: 5.99273\n",
      "[TRAIN] Epoch: 0, Iter: 540, Loss: 6.06810\n",
      "[TRAIN] Epoch: 0, Iter: 550, Loss: 5.86133\n",
      "[TRAIN] Epoch: 0, Iter: 560, Loss: 5.94180\n",
      "[TRAIN] Epoch: 0, Iter: 570, Loss: 5.77177\n",
      "== [TRAIN] Epoch: 0, Perplexity: 723.929 ==>\n",
      "[VAL] Epoch: 0, Iter: 0, Loss: 5.92035\n",
      "[VAL] Epoch: 0, Iter: 10, Loss: 5.94873\n",
      "[VAL] Epoch: 0, Iter: 20, Loss: 6.09270\n",
      "[VAL] Epoch: 0, Iter: 30, Loss: 5.98844\n",
      "[VAL] Epoch: 0, Iter: 40, Loss: 5.79234\n",
      "[VAL] Epoch: 0, Iter: 50, Loss: 5.63890\n",
      "=== [VAL] Epoch: 0, Iter: 59, Perplexity: 368.983 ===>\n",
      "====== Epoch 1 ======>\n",
      "[TRAIN] Epoch: 1, Iter: 0, Loss: 5.76879\n",
      "[TRAIN] Epoch: 1, Iter: 10, Loss: 5.87797\n",
      "[TRAIN] Epoch: 1, Iter: 20, Loss: 5.88290\n",
      "[TRAIN] Epoch: 1, Iter: 30, Loss: 5.99779\n",
      "[TRAIN] Epoch: 1, Iter: 40, Loss: 5.73488\n",
      "[TRAIN] Epoch: 1, Iter: 50, Loss: 5.69419\n",
      "[TRAIN] Epoch: 1, Iter: 60, Loss: 5.83334\n",
      "[TRAIN] Epoch: 1, Iter: 70, Loss: 5.85061\n",
      "[TRAIN] Epoch: 1, Iter: 80, Loss: 5.75851\n",
      "[TRAIN] Epoch: 1, Iter: 90, Loss: 6.00729\n",
      "[TRAIN] Epoch: 1, Iter: 100, Loss: 5.79863\n",
      "[TRAIN] Epoch: 1, Iter: 110, Loss: 5.70927\n",
      "[TRAIN] Epoch: 1, Iter: 120, Loss: 5.97617\n",
      "[TRAIN] Epoch: 1, Iter: 130, Loss: 5.80022\n",
      "[TRAIN] Epoch: 1, Iter: 140, Loss: 5.74723\n",
      "[TRAIN] Epoch: 1, Iter: 150, Loss: 5.81648\n",
      "[TRAIN] Epoch: 1, Iter: 160, Loss: 5.66616\n",
      "[TRAIN] Epoch: 1, Iter: 170, Loss: 5.67845\n",
      "[TRAIN] Epoch: 1, Iter: 180, Loss: 5.83744\n",
      "[TRAIN] Epoch: 1, Iter: 190, Loss: 5.65558\n",
      "[TRAIN] Epoch: 1, Iter: 200, Loss: 5.89579\n",
      "[TRAIN] Epoch: 1, Iter: 210, Loss: 5.66563\n",
      "[TRAIN] Epoch: 1, Iter: 220, Loss: 5.78436\n",
      "[TRAIN] Epoch: 1, Iter: 230, Loss: 5.63363\n",
      "[TRAIN] Epoch: 1, Iter: 240, Loss: 5.62499\n",
      "[TRAIN] Epoch: 1, Iter: 250, Loss: 5.78710\n",
      "[TRAIN] Epoch: 1, Iter: 260, Loss: 5.66499\n",
      "[TRAIN] Epoch: 1, Iter: 270, Loss: 5.95855\n",
      "[TRAIN] Epoch: 1, Iter: 280, Loss: 5.73439\n",
      "[TRAIN] Epoch: 1, Iter: 290, Loss: 5.80612\n",
      "[TRAIN] Epoch: 1, Iter: 300, Loss: 5.67263\n",
      "[TRAIN] Epoch: 1, Iter: 310, Loss: 5.57889\n",
      "[TRAIN] Epoch: 1, Iter: 320, Loss: 5.79003\n",
      "[TRAIN] Epoch: 1, Iter: 330, Loss: 5.53944\n",
      "[TRAIN] Epoch: 1, Iter: 340, Loss: 5.62948\n",
      "[TRAIN] Epoch: 1, Iter: 350, Loss: 5.62490\n",
      "[TRAIN] Epoch: 1, Iter: 360, Loss: 5.51327\n",
      "[TRAIN] Epoch: 1, Iter: 370, Loss: 5.75759\n",
      "[TRAIN] Epoch: 1, Iter: 380, Loss: 5.65057\n",
      "[TRAIN] Epoch: 1, Iter: 390, Loss: 5.46972\n",
      "[TRAIN] Epoch: 1, Iter: 400, Loss: 5.75722\n",
      "[TRAIN] Epoch: 1, Iter: 410, Loss: 5.69835\n",
      "[TRAIN] Epoch: 1, Iter: 420, Loss: 5.54482\n",
      "[TRAIN] Epoch: 1, Iter: 430, Loss: 5.66403\n",
      "[TRAIN] Epoch: 1, Iter: 440, Loss: 5.65962\n",
      "[TRAIN] Epoch: 1, Iter: 450, Loss: 5.53375\n",
      "[TRAIN] Epoch: 1, Iter: 460, Loss: 5.73921\n",
      "[TRAIN] Epoch: 1, Iter: 470, Loss: 5.60173\n",
      "[TRAIN] Epoch: 1, Iter: 480, Loss: 5.71167\n",
      "[TRAIN] Epoch: 1, Iter: 490, Loss: 5.63337\n",
      "[TRAIN] Epoch: 1, Iter: 500, Loss: 5.51450\n",
      "[TRAIN] Epoch: 1, Iter: 510, Loss: 5.50110\n",
      "[TRAIN] Epoch: 1, Iter: 520, Loss: 5.61017\n",
      "[TRAIN] Epoch: 1, Iter: 530, Loss: 5.45433\n",
      "[TRAIN] Epoch: 1, Iter: 540, Loss: 5.61508\n",
      "[TRAIN] Epoch: 1, Iter: 550, Loss: 5.37852\n",
      "[TRAIN] Epoch: 1, Iter: 560, Loss: 5.44027\n",
      "[TRAIN] Epoch: 1, Iter: 570, Loss: 5.38253\n",
      "== [TRAIN] Epoch: 1, Perplexity: 297.406 ==>\n",
      "[VAL] Epoch: 1, Iter: 0, Loss: 5.51236\n",
      "[VAL] Epoch: 1, Iter: 10, Loss: 5.57087\n",
      "[VAL] Epoch: 1, Iter: 20, Loss: 5.73048\n",
      "[VAL] Epoch: 1, Iter: 30, Loss: 5.66653\n",
      "[VAL] Epoch: 1, Iter: 40, Loss: 5.41874\n",
      "[VAL] Epoch: 1, Iter: 50, Loss: 5.34092\n",
      "=== [VAL] Epoch: 1, Iter: 59, Perplexity: 249.621 ===>\n",
      "====== Epoch 2 ======>\n",
      "[TRAIN] Epoch: 2, Iter: 0, Loss: 5.44395\n",
      "[TRAIN] Epoch: 2, Iter: 10, Loss: 5.55923\n",
      "[TRAIN] Epoch: 2, Iter: 20, Loss: 5.55531\n",
      "[TRAIN] Epoch: 2, Iter: 30, Loss: 5.39996\n",
      "[TRAIN] Epoch: 2, Iter: 40, Loss: 5.58654\n",
      "[TRAIN] Epoch: 2, Iter: 50, Loss: 5.21856\n",
      "[TRAIN] Epoch: 2, Iter: 60, Loss: 5.44112\n",
      "[TRAIN] Epoch: 2, Iter: 70, Loss: 5.48313\n",
      "[TRAIN] Epoch: 2, Iter: 80, Loss: 5.44675\n",
      "[TRAIN] Epoch: 2, Iter: 90, Loss: 5.51321\n",
      "[TRAIN] Epoch: 2, Iter: 100, Loss: 5.35763\n",
      "[TRAIN] Epoch: 2, Iter: 110, Loss: 5.54502\n",
      "[TRAIN] Epoch: 2, Iter: 120, Loss: 5.32286\n",
      "[TRAIN] Epoch: 2, Iter: 130, Loss: 5.52716\n",
      "[TRAIN] Epoch: 2, Iter: 140, Loss: 5.46985\n",
      "[TRAIN] Epoch: 2, Iter: 150, Loss: 5.51559\n",
      "[TRAIN] Epoch: 2, Iter: 160, Loss: 5.55389\n",
      "[TRAIN] Epoch: 2, Iter: 170, Loss: 5.39583\n",
      "[TRAIN] Epoch: 2, Iter: 180, Loss: 5.39770\n",
      "[TRAIN] Epoch: 2, Iter: 190, Loss: 5.50279\n",
      "[TRAIN] Epoch: 2, Iter: 200, Loss: 5.40359\n",
      "[TRAIN] Epoch: 2, Iter: 210, Loss: 5.52362\n",
      "[TRAIN] Epoch: 2, Iter: 220, Loss: 5.28362\n",
      "[TRAIN] Epoch: 2, Iter: 230, Loss: 5.31223\n",
      "[TRAIN] Epoch: 2, Iter: 240, Loss: 5.30546\n",
      "[TRAIN] Epoch: 2, Iter: 250, Loss: 5.49542\n",
      "[TRAIN] Epoch: 2, Iter: 260, Loss: 5.29439\n",
      "[TRAIN] Epoch: 2, Iter: 270, Loss: 5.38687\n",
      "[TRAIN] Epoch: 2, Iter: 280, Loss: 5.40375\n",
      "[TRAIN] Epoch: 2, Iter: 290, Loss: 5.43275\n",
      "[TRAIN] Epoch: 2, Iter: 300, Loss: 5.23593\n",
      "[TRAIN] Epoch: 2, Iter: 310, Loss: 5.48560\n",
      "[TRAIN] Epoch: 2, Iter: 320, Loss: 5.27385\n",
      "[TRAIN] Epoch: 2, Iter: 330, Loss: 5.31810\n",
      "[TRAIN] Epoch: 2, Iter: 340, Loss: 5.39261\n",
      "[TRAIN] Epoch: 2, Iter: 350, Loss: 5.47980\n",
      "[TRAIN] Epoch: 2, Iter: 360, Loss: 5.16330\n",
      "[TRAIN] Epoch: 2, Iter: 370, Loss: 5.39519\n",
      "[TRAIN] Epoch: 2, Iter: 380, Loss: 5.39295\n",
      "[TRAIN] Epoch: 2, Iter: 390, Loss: 5.41806\n",
      "[TRAIN] Epoch: 2, Iter: 400, Loss: 5.12468\n",
      "[TRAIN] Epoch: 2, Iter: 410, Loss: 5.45106\n",
      "[TRAIN] Epoch: 2, Iter: 420, Loss: 5.37128\n",
      "[TRAIN] Epoch: 2, Iter: 430, Loss: 5.17771\n",
      "[TRAIN] Epoch: 2, Iter: 440, Loss: 5.26782\n",
      "[TRAIN] Epoch: 2, Iter: 450, Loss: 5.34049\n",
      "[TRAIN] Epoch: 2, Iter: 460, Loss: 5.16363\n",
      "[TRAIN] Epoch: 2, Iter: 470, Loss: 5.27241\n",
      "[TRAIN] Epoch: 2, Iter: 480, Loss: 5.28143\n",
      "[TRAIN] Epoch: 2, Iter: 490, Loss: 5.11208\n",
      "[TRAIN] Epoch: 2, Iter: 500, Loss: 5.35600\n",
      "[TRAIN] Epoch: 2, Iter: 510, Loss: 5.29056\n",
      "[TRAIN] Epoch: 2, Iter: 520, Loss: 5.22020\n",
      "[TRAIN] Epoch: 2, Iter: 530, Loss: 5.31957\n",
      "[TRAIN] Epoch: 2, Iter: 540, Loss: 5.18099\n",
      "[TRAIN] Epoch: 2, Iter: 550, Loss: 5.37938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch: 2, Iter: 560, Loss: 5.43663\n",
      "[TRAIN] Epoch: 2, Iter: 570, Loss: 5.14930\n",
      "== [TRAIN] Epoch: 2, Perplexity: 211.882 ==>\n",
      "[VAL] Epoch: 2, Iter: 0, Loss: 5.26923\n",
      "[VAL] Epoch: 2, Iter: 10, Loss: 5.38992\n",
      "[VAL] Epoch: 2, Iter: 20, Loss: 5.54671\n",
      "[VAL] Epoch: 2, Iter: 30, Loss: 5.49916\n",
      "[VAL] Epoch: 2, Iter: 40, Loss: 5.24185\n",
      "[VAL] Epoch: 2, Iter: 50, Loss: 5.17168\n",
      "=== [VAL] Epoch: 2, Iter: 59, Perplexity: 208.056 ===>\n",
      "====== Epoch 3 ======>\n",
      "[TRAIN] Epoch: 3, Iter: 0, Loss: 5.33706\n",
      "[TRAIN] Epoch: 3, Iter: 10, Loss: 5.23129\n",
      "[TRAIN] Epoch: 3, Iter: 20, Loss: 5.04408\n",
      "[TRAIN] Epoch: 3, Iter: 30, Loss: 5.40912\n",
      "[TRAIN] Epoch: 3, Iter: 40, Loss: 5.16361\n",
      "[TRAIN] Epoch: 3, Iter: 50, Loss: 5.01146\n",
      "[TRAIN] Epoch: 3, Iter: 60, Loss: 5.38484\n",
      "[TRAIN] Epoch: 3, Iter: 70, Loss: 5.11159\n",
      "[TRAIN] Epoch: 3, Iter: 80, Loss: 5.13397\n",
      "[TRAIN] Epoch: 3, Iter: 90, Loss: 5.24537\n",
      "[TRAIN] Epoch: 3, Iter: 100, Loss: 4.93726\n",
      "[TRAIN] Epoch: 3, Iter: 110, Loss: 5.18550\n",
      "[TRAIN] Epoch: 3, Iter: 120, Loss: 5.12564\n",
      "[TRAIN] Epoch: 3, Iter: 130, Loss: 5.09749\n",
      "[TRAIN] Epoch: 3, Iter: 140, Loss: 5.13642\n",
      "[TRAIN] Epoch: 3, Iter: 150, Loss: 5.16816\n",
      "[TRAIN] Epoch: 3, Iter: 160, Loss: 5.22870\n",
      "[TRAIN] Epoch: 3, Iter: 170, Loss: 5.19758\n",
      "[TRAIN] Epoch: 3, Iter: 180, Loss: 5.07056\n",
      "[TRAIN] Epoch: 3, Iter: 190, Loss: 5.17491\n",
      "[TRAIN] Epoch: 3, Iter: 200, Loss: 5.13351\n",
      "[TRAIN] Epoch: 3, Iter: 210, Loss: 5.27655\n",
      "[TRAIN] Epoch: 3, Iter: 220, Loss: 5.17450\n",
      "[TRAIN] Epoch: 3, Iter: 230, Loss: 5.33787\n",
      "[TRAIN] Epoch: 3, Iter: 240, Loss: 5.07532\n",
      "[TRAIN] Epoch: 3, Iter: 250, Loss: 5.11841\n",
      "[TRAIN] Epoch: 3, Iter: 260, Loss: 5.17125\n",
      "[TRAIN] Epoch: 3, Iter: 270, Loss: 5.11528\n",
      "[TRAIN] Epoch: 3, Iter: 280, Loss: 5.31561\n",
      "[TRAIN] Epoch: 3, Iter: 290, Loss: 5.26509\n",
      "[TRAIN] Epoch: 3, Iter: 300, Loss: 5.07939\n",
      "[TRAIN] Epoch: 3, Iter: 310, Loss: 5.18268\n",
      "[TRAIN] Epoch: 3, Iter: 320, Loss: 5.07171\n",
      "[TRAIN] Epoch: 3, Iter: 330, Loss: 5.18419\n",
      "[TRAIN] Epoch: 3, Iter: 340, Loss: 5.15321\n",
      "[TRAIN] Epoch: 3, Iter: 350, Loss: 5.14937\n",
      "[TRAIN] Epoch: 3, Iter: 360, Loss: 4.99823\n",
      "[TRAIN] Epoch: 3, Iter: 370, Loss: 5.00469\n",
      "[TRAIN] Epoch: 3, Iter: 380, Loss: 5.15601\n",
      "[TRAIN] Epoch: 3, Iter: 390, Loss: 5.06207\n",
      "[TRAIN] Epoch: 3, Iter: 400, Loss: 5.14182\n",
      "[TRAIN] Epoch: 3, Iter: 410, Loss: 5.12997\n",
      "[TRAIN] Epoch: 3, Iter: 420, Loss: 5.20566\n",
      "[TRAIN] Epoch: 3, Iter: 430, Loss: 5.01152\n",
      "[TRAIN] Epoch: 3, Iter: 440, Loss: 5.14516\n",
      "[TRAIN] Epoch: 3, Iter: 450, Loss: 5.03915\n",
      "[TRAIN] Epoch: 3, Iter: 460, Loss: 4.97429\n",
      "[TRAIN] Epoch: 3, Iter: 470, Loss: 5.20408\n",
      "[TRAIN] Epoch: 3, Iter: 480, Loss: 5.08042\n",
      "[TRAIN] Epoch: 3, Iter: 490, Loss: 5.18260\n",
      "[TRAIN] Epoch: 3, Iter: 500, Loss: 5.06565\n",
      "[TRAIN] Epoch: 3, Iter: 510, Loss: 5.08819\n",
      "[TRAIN] Epoch: 3, Iter: 520, Loss: 5.10739\n",
      "[TRAIN] Epoch: 3, Iter: 530, Loss: 5.18938\n",
      "[TRAIN] Epoch: 3, Iter: 540, Loss: 5.29587\n",
      "[TRAIN] Epoch: 3, Iter: 550, Loss: 5.06125\n",
      "[TRAIN] Epoch: 3, Iter: 560, Loss: 5.06455\n",
      "[TRAIN] Epoch: 3, Iter: 570, Loss: 4.99116\n",
      "== [TRAIN] Epoch: 3, Perplexity: 168.083 ==>\n",
      "[VAL] Epoch: 3, Iter: 0, Loss: 5.11210\n",
      "[VAL] Epoch: 3, Iter: 10, Loss: 5.25935\n",
      "[VAL] Epoch: 3, Iter: 20, Loss: 5.35577\n",
      "[VAL] Epoch: 3, Iter: 30, Loss: 5.40428\n",
      "[VAL] Epoch: 3, Iter: 40, Loss: 5.12800\n",
      "[VAL] Epoch: 3, Iter: 50, Loss: 5.02824\n",
      "=== [VAL] Epoch: 3, Iter: 59, Perplexity: 182.781 ===>\n",
      "====== Epoch 4 ======>\n",
      "[TRAIN] Epoch: 4, Iter: 0, Loss: 5.00444\n",
      "[TRAIN] Epoch: 4, Iter: 10, Loss: 4.91642\n",
      "[TRAIN] Epoch: 4, Iter: 20, Loss: 5.07349\n",
      "[TRAIN] Epoch: 4, Iter: 30, Loss: 5.21511\n",
      "[TRAIN] Epoch: 4, Iter: 40, Loss: 4.80457\n",
      "[TRAIN] Epoch: 4, Iter: 50, Loss: 4.91478\n",
      "[TRAIN] Epoch: 4, Iter: 60, Loss: 5.06435\n",
      "[TRAIN] Epoch: 4, Iter: 70, Loss: 4.88348\n",
      "[TRAIN] Epoch: 4, Iter: 80, Loss: 4.95363\n",
      "[TRAIN] Epoch: 4, Iter: 90, Loss: 4.86539\n",
      "[TRAIN] Epoch: 4, Iter: 100, Loss: 5.05398\n",
      "[TRAIN] Epoch: 4, Iter: 110, Loss: 4.95485\n",
      "[TRAIN] Epoch: 4, Iter: 120, Loss: 5.02738\n",
      "[TRAIN] Epoch: 4, Iter: 130, Loss: 4.87323\n",
      "[TRAIN] Epoch: 4, Iter: 140, Loss: 4.98186\n",
      "[TRAIN] Epoch: 4, Iter: 150, Loss: 4.87450\n",
      "[TRAIN] Epoch: 4, Iter: 160, Loss: 5.05332\n",
      "[TRAIN] Epoch: 4, Iter: 170, Loss: 4.81430\n",
      "[TRAIN] Epoch: 4, Iter: 180, Loss: 4.95598\n",
      "[TRAIN] Epoch: 4, Iter: 190, Loss: 5.10272\n",
      "[TRAIN] Epoch: 4, Iter: 200, Loss: 4.94055\n",
      "[TRAIN] Epoch: 4, Iter: 210, Loss: 5.05661\n",
      "[TRAIN] Epoch: 4, Iter: 220, Loss: 5.04552\n",
      "[TRAIN] Epoch: 4, Iter: 230, Loss: 4.94436\n",
      "[TRAIN] Epoch: 4, Iter: 240, Loss: 4.97315\n",
      "[TRAIN] Epoch: 4, Iter: 250, Loss: 4.94502\n",
      "[TRAIN] Epoch: 4, Iter: 260, Loss: 4.83241\n",
      "[TRAIN] Epoch: 4, Iter: 270, Loss: 4.94273\n",
      "[TRAIN] Epoch: 4, Iter: 280, Loss: 4.94004\n",
      "[TRAIN] Epoch: 4, Iter: 290, Loss: 4.99848\n",
      "[TRAIN] Epoch: 4, Iter: 300, Loss: 5.01575\n",
      "[TRAIN] Epoch: 4, Iter: 310, Loss: 4.86622\n",
      "[TRAIN] Epoch: 4, Iter: 320, Loss: 5.12221\n",
      "[TRAIN] Epoch: 4, Iter: 330, Loss: 4.82415\n",
      "[TRAIN] Epoch: 4, Iter: 340, Loss: 5.02622\n",
      "[TRAIN] Epoch: 4, Iter: 350, Loss: 4.92940\n",
      "[TRAIN] Epoch: 4, Iter: 360, Loss: 4.80524\n",
      "[TRAIN] Epoch: 4, Iter: 370, Loss: 4.93373\n",
      "[TRAIN] Epoch: 4, Iter: 380, Loss: 4.82644\n",
      "[TRAIN] Epoch: 4, Iter: 390, Loss: 4.90090\n",
      "[TRAIN] Epoch: 4, Iter: 400, Loss: 4.87972\n",
      "[TRAIN] Epoch: 4, Iter: 410, Loss: 5.01401\n",
      "[TRAIN] Epoch: 4, Iter: 420, Loss: 5.01759\n",
      "[TRAIN] Epoch: 4, Iter: 430, Loss: 4.91445\n",
      "[TRAIN] Epoch: 4, Iter: 440, Loss: 4.81503\n",
      "[TRAIN] Epoch: 4, Iter: 450, Loss: 4.81602\n",
      "[TRAIN] Epoch: 4, Iter: 460, Loss: 4.89504\n",
      "[TRAIN] Epoch: 4, Iter: 470, Loss: 5.11177\n",
      "[TRAIN] Epoch: 4, Iter: 480, Loss: 4.80705\n",
      "[TRAIN] Epoch: 4, Iter: 490, Loss: 4.89308\n",
      "[TRAIN] Epoch: 4, Iter: 500, Loss: 4.97933\n",
      "[TRAIN] Epoch: 4, Iter: 510, Loss: 4.96728\n",
      "[TRAIN] Epoch: 4, Iter: 520, Loss: 4.85439\n",
      "[TRAIN] Epoch: 4, Iter: 530, Loss: 4.91583\n",
      "[TRAIN] Epoch: 4, Iter: 540, Loss: 4.95587\n",
      "[TRAIN] Epoch: 4, Iter: 550, Loss: 4.89341\n",
      "[TRAIN] Epoch: 4, Iter: 560, Loss: 4.84489\n",
      "[TRAIN] Epoch: 4, Iter: 570, Loss: 5.03462\n",
      "== [TRAIN] Epoch: 4, Perplexity: 140.349 ==>\n",
      "[VAL] Epoch: 4, Iter: 0, Loss: 5.02756\n",
      "[VAL] Epoch: 4, Iter: 10, Loss: 5.18809\n",
      "[VAL] Epoch: 4, Iter: 20, Loss: 5.29101\n",
      "[VAL] Epoch: 4, Iter: 30, Loss: 5.31046\n",
      "[VAL] Epoch: 4, Iter: 40, Loss: 5.05435\n",
      "[VAL] Epoch: 4, Iter: 50, Loss: 4.94511\n",
      "=== [VAL] Epoch: 4, Iter: 59, Perplexity: 167.415 ===>\n",
      "====== Epoch 5 ======>\n",
      "[TRAIN] Epoch: 5, Iter: 0, Loss: 4.74357\n",
      "[TRAIN] Epoch: 5, Iter: 10, Loss: 4.79704\n",
      "[TRAIN] Epoch: 5, Iter: 20, Loss: 4.90681\n",
      "[TRAIN] Epoch: 5, Iter: 30, Loss: 4.72851\n",
      "[TRAIN] Epoch: 5, Iter: 40, Loss: 4.70409\n",
      "[TRAIN] Epoch: 5, Iter: 50, Loss: 4.64963\n",
      "[TRAIN] Epoch: 5, Iter: 60, Loss: 4.70245\n",
      "[TRAIN] Epoch: 5, Iter: 70, Loss: 4.95829\n",
      "[TRAIN] Epoch: 5, Iter: 80, Loss: 4.87985\n",
      "[TRAIN] Epoch: 5, Iter: 90, Loss: 4.86840\n",
      "[TRAIN] Epoch: 5, Iter: 100, Loss: 4.80883\n",
      "[TRAIN] Epoch: 5, Iter: 110, Loss: 4.87030\n",
      "[TRAIN] Epoch: 5, Iter: 120, Loss: 4.76212\n",
      "[TRAIN] Epoch: 5, Iter: 130, Loss: 4.88057\n",
      "[TRAIN] Epoch: 5, Iter: 140, Loss: 4.96389\n",
      "[TRAIN] Epoch: 5, Iter: 150, Loss: 4.94957\n",
      "[TRAIN] Epoch: 5, Iter: 160, Loss: 4.84827\n",
      "[TRAIN] Epoch: 5, Iter: 170, Loss: 4.76747\n",
      "[TRAIN] Epoch: 5, Iter: 180, Loss: 4.68555\n",
      "[TRAIN] Epoch: 5, Iter: 190, Loss: 4.98323\n",
      "[TRAIN] Epoch: 5, Iter: 200, Loss: 4.79771\n",
      "[TRAIN] Epoch: 5, Iter: 210, Loss: 4.87716\n",
      "[TRAIN] Epoch: 5, Iter: 220, Loss: 4.59926\n",
      "[TRAIN] Epoch: 5, Iter: 230, Loss: 4.88985\n",
      "[TRAIN] Epoch: 5, Iter: 240, Loss: 4.75778\n",
      "[TRAIN] Epoch: 5, Iter: 250, Loss: 4.80574\n",
      "[TRAIN] Epoch: 5, Iter: 260, Loss: 4.77377\n",
      "[TRAIN] Epoch: 5, Iter: 270, Loss: 4.82112\n",
      "[TRAIN] Epoch: 5, Iter: 280, Loss: 4.91763\n",
      "[TRAIN] Epoch: 5, Iter: 290, Loss: 4.90647\n",
      "[TRAIN] Epoch: 5, Iter: 300, Loss: 4.66213\n",
      "[TRAIN] Epoch: 5, Iter: 310, Loss: 4.80365\n",
      "[TRAIN] Epoch: 5, Iter: 320, Loss: 4.76750\n",
      "[TRAIN] Epoch: 5, Iter: 330, Loss: 4.61544\n",
      "[TRAIN] Epoch: 5, Iter: 340, Loss: 4.75235\n",
      "[TRAIN] Epoch: 5, Iter: 350, Loss: 4.76403\n",
      "[TRAIN] Epoch: 5, Iter: 360, Loss: 4.94960\n",
      "[TRAIN] Epoch: 5, Iter: 370, Loss: 4.85043\n",
      "[TRAIN] Epoch: 5, Iter: 380, Loss: 4.80030\n",
      "[TRAIN] Epoch: 5, Iter: 390, Loss: 4.79469\n",
      "[TRAIN] Epoch: 5, Iter: 400, Loss: 4.69125\n",
      "[TRAIN] Epoch: 5, Iter: 410, Loss: 4.82035\n",
      "[TRAIN] Epoch: 5, Iter: 420, Loss: 4.78209\n",
      "[TRAIN] Epoch: 5, Iter: 430, Loss: 4.71924\n",
      "[TRAIN] Epoch: 5, Iter: 440, Loss: 5.01094\n",
      "[TRAIN] Epoch: 5, Iter: 450, Loss: 4.72009\n",
      "[TRAIN] Epoch: 5, Iter: 460, Loss: 4.75989\n",
      "[TRAIN] Epoch: 5, Iter: 470, Loss: 4.57505\n",
      "[TRAIN] Epoch: 5, Iter: 480, Loss: 4.82816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch: 5, Iter: 490, Loss: 4.62626\n",
      "[TRAIN] Epoch: 5, Iter: 500, Loss: 4.83478\n",
      "[TRAIN] Epoch: 5, Iter: 510, Loss: 4.87435\n",
      "[TRAIN] Epoch: 5, Iter: 520, Loss: 4.90751\n",
      "[TRAIN] Epoch: 5, Iter: 530, Loss: 4.75859\n",
      "[TRAIN] Epoch: 5, Iter: 540, Loss: 4.77661\n",
      "[TRAIN] Epoch: 5, Iter: 550, Loss: 4.63683\n",
      "[TRAIN] Epoch: 5, Iter: 560, Loss: 4.77397\n",
      "[TRAIN] Epoch: 5, Iter: 570, Loss: 4.83596\n",
      "== [TRAIN] Epoch: 5, Perplexity: 121.331 ==>\n",
      "[VAL] Epoch: 5, Iter: 0, Loss: 4.96142\n",
      "[VAL] Epoch: 5, Iter: 10, Loss: 5.13907\n",
      "[VAL] Epoch: 5, Iter: 20, Loss: 5.23252\n",
      "[VAL] Epoch: 5, Iter: 30, Loss: 5.27534\n",
      "[VAL] Epoch: 5, Iter: 40, Loss: 4.97841\n",
      "[VAL] Epoch: 5, Iter: 50, Loss: 4.88363\n",
      "=== [VAL] Epoch: 5, Iter: 59, Perplexity: 158.030 ===>\n",
      "====== Epoch 6 ======>\n",
      "[TRAIN] Epoch: 6, Iter: 0, Loss: 4.76083\n",
      "[TRAIN] Epoch: 6, Iter: 10, Loss: 4.55351\n",
      "[TRAIN] Epoch: 6, Iter: 20, Loss: 4.42005\n",
      "[TRAIN] Epoch: 6, Iter: 30, Loss: 4.69695\n",
      "[TRAIN] Epoch: 6, Iter: 40, Loss: 4.88025\n",
      "[TRAIN] Epoch: 6, Iter: 50, Loss: 4.52526\n",
      "[TRAIN] Epoch: 6, Iter: 60, Loss: 4.76489\n",
      "[TRAIN] Epoch: 6, Iter: 70, Loss: 4.62744\n",
      "[TRAIN] Epoch: 6, Iter: 80, Loss: 4.69428\n",
      "[TRAIN] Epoch: 6, Iter: 90, Loss: 4.83001\n",
      "[TRAIN] Epoch: 6, Iter: 100, Loss: 4.66765\n",
      "[TRAIN] Epoch: 6, Iter: 110, Loss: 4.86577\n",
      "[TRAIN] Epoch: 6, Iter: 120, Loss: 4.53212\n",
      "[TRAIN] Epoch: 6, Iter: 130, Loss: 4.60708\n",
      "[TRAIN] Epoch: 6, Iter: 140, Loss: 4.58437\n",
      "[TRAIN] Epoch: 6, Iter: 150, Loss: 4.71514\n",
      "[TRAIN] Epoch: 6, Iter: 160, Loss: 4.66620\n",
      "[TRAIN] Epoch: 6, Iter: 170, Loss: 4.79728\n",
      "[TRAIN] Epoch: 6, Iter: 180, Loss: 4.70071\n",
      "[TRAIN] Epoch: 6, Iter: 190, Loss: 4.66949\n",
      "[TRAIN] Epoch: 6, Iter: 200, Loss: 4.72686\n",
      "[TRAIN] Epoch: 6, Iter: 210, Loss: 4.81402\n",
      "[TRAIN] Epoch: 6, Iter: 220, Loss: 4.56009\n",
      "[TRAIN] Epoch: 6, Iter: 230, Loss: 4.89756\n",
      "[TRAIN] Epoch: 6, Iter: 240, Loss: 4.71305\n",
      "[TRAIN] Epoch: 6, Iter: 250, Loss: 4.59548\n",
      "[TRAIN] Epoch: 6, Iter: 260, Loss: 4.84148\n",
      "[TRAIN] Epoch: 6, Iter: 270, Loss: 4.62732\n",
      "[TRAIN] Epoch: 6, Iter: 280, Loss: 4.72582\n",
      "[TRAIN] Epoch: 6, Iter: 290, Loss: 4.66860\n",
      "[TRAIN] Epoch: 6, Iter: 300, Loss: 4.52444\n",
      "[TRAIN] Epoch: 6, Iter: 310, Loss: 4.57255\n",
      "[TRAIN] Epoch: 6, Iter: 320, Loss: 4.55635\n",
      "[TRAIN] Epoch: 6, Iter: 330, Loss: 4.58548\n",
      "[TRAIN] Epoch: 6, Iter: 340, Loss: 4.68155\n",
      "[TRAIN] Epoch: 6, Iter: 350, Loss: 4.61887\n",
      "[TRAIN] Epoch: 6, Iter: 360, Loss: 4.68511\n",
      "[TRAIN] Epoch: 6, Iter: 370, Loss: 4.58528\n",
      "[TRAIN] Epoch: 6, Iter: 380, Loss: 4.59614\n",
      "[TRAIN] Epoch: 6, Iter: 390, Loss: 4.53700\n",
      "[TRAIN] Epoch: 6, Iter: 400, Loss: 4.77984\n",
      "[TRAIN] Epoch: 6, Iter: 410, Loss: 4.74795\n",
      "[TRAIN] Epoch: 6, Iter: 420, Loss: 4.61549\n",
      "[TRAIN] Epoch: 6, Iter: 430, Loss: 4.71527\n",
      "[TRAIN] Epoch: 6, Iter: 440, Loss: 4.70054\n",
      "[TRAIN] Epoch: 6, Iter: 450, Loss: 4.60810\n",
      "[TRAIN] Epoch: 6, Iter: 460, Loss: 4.58320\n",
      "[TRAIN] Epoch: 6, Iter: 470, Loss: 4.78362\n",
      "[TRAIN] Epoch: 6, Iter: 480, Loss: 4.85228\n",
      "[TRAIN] Epoch: 6, Iter: 490, Loss: 4.85829\n",
      "[TRAIN] Epoch: 6, Iter: 500, Loss: 4.72729\n",
      "[TRAIN] Epoch: 6, Iter: 510, Loss: 4.77762\n",
      "[TRAIN] Epoch: 6, Iter: 520, Loss: 4.82018\n",
      "[TRAIN] Epoch: 6, Iter: 530, Loss: 4.82963\n",
      "[TRAIN] Epoch: 6, Iter: 540, Loss: 4.72733\n",
      "[TRAIN] Epoch: 6, Iter: 550, Loss: 4.68201\n",
      "[TRAIN] Epoch: 6, Iter: 560, Loss: 4.58504\n",
      "[TRAIN] Epoch: 6, Iter: 570, Loss: 4.69072\n",
      "== [TRAIN] Epoch: 6, Perplexity: 107.433 ==>\n",
      "[VAL] Epoch: 6, Iter: 0, Loss: 4.90781\n",
      "[VAL] Epoch: 6, Iter: 10, Loss: 5.09644\n",
      "[VAL] Epoch: 6, Iter: 20, Loss: 5.17851\n",
      "[VAL] Epoch: 6, Iter: 30, Loss: 5.23483\n",
      "[VAL] Epoch: 6, Iter: 40, Loss: 4.95624\n",
      "[VAL] Epoch: 6, Iter: 50, Loss: 4.84873\n",
      "=== [VAL] Epoch: 6, Iter: 59, Perplexity: 151.845 ===>\n",
      "====== Epoch 7 ======>\n",
      "[TRAIN] Epoch: 7, Iter: 0, Loss: 4.44613\n",
      "[TRAIN] Epoch: 7, Iter: 10, Loss: 4.48042\n",
      "[TRAIN] Epoch: 7, Iter: 20, Loss: 4.65086\n",
      "[TRAIN] Epoch: 7, Iter: 30, Loss: 4.55699\n",
      "[TRAIN] Epoch: 7, Iter: 40, Loss: 4.68252\n",
      "[TRAIN] Epoch: 7, Iter: 50, Loss: 4.45181\n",
      "[TRAIN] Epoch: 7, Iter: 60, Loss: 4.58433\n",
      "[TRAIN] Epoch: 7, Iter: 70, Loss: 4.66446\n",
      "[TRAIN] Epoch: 7, Iter: 80, Loss: 4.69160\n",
      "[TRAIN] Epoch: 7, Iter: 90, Loss: 4.55180\n",
      "[TRAIN] Epoch: 7, Iter: 100, Loss: 4.50377\n",
      "[TRAIN] Epoch: 7, Iter: 110, Loss: 4.56679\n",
      "[TRAIN] Epoch: 7, Iter: 120, Loss: 4.58868\n",
      "[TRAIN] Epoch: 7, Iter: 130, Loss: 4.46527\n",
      "[TRAIN] Epoch: 7, Iter: 140, Loss: 4.61214\n",
      "[TRAIN] Epoch: 7, Iter: 150, Loss: 4.64317\n",
      "[TRAIN] Epoch: 7, Iter: 160, Loss: 4.51539\n",
      "[TRAIN] Epoch: 7, Iter: 170, Loss: 4.70372\n",
      "[TRAIN] Epoch: 7, Iter: 180, Loss: 4.65151\n",
      "[TRAIN] Epoch: 7, Iter: 190, Loss: 4.58315\n",
      "[TRAIN] Epoch: 7, Iter: 200, Loss: 4.38464\n",
      "[TRAIN] Epoch: 7, Iter: 210, Loss: 4.62633\n",
      "[TRAIN] Epoch: 7, Iter: 220, Loss: 4.62128\n",
      "[TRAIN] Epoch: 7, Iter: 230, Loss: 4.69094\n",
      "[TRAIN] Epoch: 7, Iter: 240, Loss: 4.62945\n",
      "[TRAIN] Epoch: 7, Iter: 250, Loss: 4.43286\n",
      "[TRAIN] Epoch: 7, Iter: 260, Loss: 4.39933\n",
      "[TRAIN] Epoch: 7, Iter: 270, Loss: 4.67972\n",
      "[TRAIN] Epoch: 7, Iter: 280, Loss: 4.63423\n",
      "[TRAIN] Epoch: 7, Iter: 290, Loss: 4.66887\n",
      "[TRAIN] Epoch: 7, Iter: 300, Loss: 4.74146\n",
      "[TRAIN] Epoch: 7, Iter: 310, Loss: 4.54553\n",
      "[TRAIN] Epoch: 7, Iter: 320, Loss: 4.72431\n",
      "[TRAIN] Epoch: 7, Iter: 330, Loss: 4.39201\n",
      "[TRAIN] Epoch: 7, Iter: 340, Loss: 4.82384\n",
      "[TRAIN] Epoch: 7, Iter: 350, Loss: 4.57470\n",
      "[TRAIN] Epoch: 7, Iter: 360, Loss: 4.60956\n",
      "[TRAIN] Epoch: 7, Iter: 370, Loss: 4.40563\n",
      "[TRAIN] Epoch: 7, Iter: 380, Loss: 4.52265\n",
      "[TRAIN] Epoch: 7, Iter: 390, Loss: 4.64592\n",
      "[TRAIN] Epoch: 7, Iter: 400, Loss: 4.64968\n",
      "[TRAIN] Epoch: 7, Iter: 410, Loss: 4.64708\n",
      "[TRAIN] Epoch: 7, Iter: 420, Loss: 4.61475\n",
      "[TRAIN] Epoch: 7, Iter: 430, Loss: 4.57885\n",
      "[TRAIN] Epoch: 7, Iter: 440, Loss: 4.70500\n",
      "[TRAIN] Epoch: 7, Iter: 450, Loss: 4.58420\n",
      "[TRAIN] Epoch: 7, Iter: 460, Loss: 4.42286\n",
      "[TRAIN] Epoch: 7, Iter: 470, Loss: 4.74677\n",
      "[TRAIN] Epoch: 7, Iter: 480, Loss: 4.69904\n",
      "[TRAIN] Epoch: 7, Iter: 490, Loss: 4.45265\n",
      "[TRAIN] Epoch: 7, Iter: 500, Loss: 4.41281\n",
      "[TRAIN] Epoch: 7, Iter: 510, Loss: 4.72428\n",
      "[TRAIN] Epoch: 7, Iter: 520, Loss: 4.62475\n",
      "[TRAIN] Epoch: 7, Iter: 530, Loss: 4.79401\n",
      "[TRAIN] Epoch: 7, Iter: 540, Loss: 4.46472\n",
      "[TRAIN] Epoch: 7, Iter: 550, Loss: 4.80711\n",
      "[TRAIN] Epoch: 7, Iter: 560, Loss: 4.57919\n",
      "[TRAIN] Epoch: 7, Iter: 570, Loss: 4.45083\n",
      "== [TRAIN] Epoch: 7, Perplexity: 96.787 ==>\n",
      "[VAL] Epoch: 7, Iter: 0, Loss: 4.85595\n",
      "[VAL] Epoch: 7, Iter: 10, Loss: 5.07426\n",
      "[VAL] Epoch: 7, Iter: 20, Loss: 5.18572\n",
      "[VAL] Epoch: 7, Iter: 30, Loss: 5.22050\n",
      "[VAL] Epoch: 7, Iter: 40, Loss: 4.91287\n",
      "[VAL] Epoch: 7, Iter: 50, Loss: 4.80469\n",
      "=== [VAL] Epoch: 7, Iter: 59, Perplexity: 148.767 ===>\n",
      "====== Epoch 8 ======>\n",
      "[TRAIN] Epoch: 8, Iter: 0, Loss: 4.62631\n",
      "[TRAIN] Epoch: 8, Iter: 10, Loss: 4.38671\n",
      "[TRAIN] Epoch: 8, Iter: 20, Loss: 4.48997\n",
      "[TRAIN] Epoch: 8, Iter: 30, Loss: 4.47780\n",
      "[TRAIN] Epoch: 8, Iter: 40, Loss: 4.31423\n",
      "[TRAIN] Epoch: 8, Iter: 50, Loss: 4.55385\n",
      "[TRAIN] Epoch: 8, Iter: 60, Loss: 4.43052\n",
      "[TRAIN] Epoch: 8, Iter: 70, Loss: 4.35813\n",
      "[TRAIN] Epoch: 8, Iter: 80, Loss: 4.56869\n",
      "[TRAIN] Epoch: 8, Iter: 90, Loss: 4.50333\n",
      "[TRAIN] Epoch: 8, Iter: 100, Loss: 4.42400\n",
      "[TRAIN] Epoch: 8, Iter: 110, Loss: 4.55681\n",
      "[TRAIN] Epoch: 8, Iter: 120, Loss: 4.33893\n",
      "[TRAIN] Epoch: 8, Iter: 130, Loss: 4.55517\n",
      "[TRAIN] Epoch: 8, Iter: 140, Loss: 4.59935\n",
      "[TRAIN] Epoch: 8, Iter: 150, Loss: 4.51468\n",
      "[TRAIN] Epoch: 8, Iter: 160, Loss: 4.56390\n",
      "[TRAIN] Epoch: 8, Iter: 170, Loss: 4.52424\n",
      "[TRAIN] Epoch: 8, Iter: 180, Loss: 4.49440\n",
      "[TRAIN] Epoch: 8, Iter: 190, Loss: 4.68931\n",
      "[TRAIN] Epoch: 8, Iter: 200, Loss: 4.46514\n",
      "[TRAIN] Epoch: 8, Iter: 210, Loss: 4.68242\n",
      "[TRAIN] Epoch: 8, Iter: 220, Loss: 4.58055\n",
      "[TRAIN] Epoch: 8, Iter: 230, Loss: 4.36293\n",
      "[TRAIN] Epoch: 8, Iter: 240, Loss: 4.50722\n",
      "[TRAIN] Epoch: 8, Iter: 250, Loss: 4.49931\n",
      "[TRAIN] Epoch: 8, Iter: 260, Loss: 4.28106\n",
      "[TRAIN] Epoch: 8, Iter: 270, Loss: 4.42846\n",
      "[TRAIN] Epoch: 8, Iter: 280, Loss: 4.63607\n",
      "[TRAIN] Epoch: 8, Iter: 290, Loss: 4.53053\n",
      "[TRAIN] Epoch: 8, Iter: 300, Loss: 4.63540\n",
      "[TRAIN] Epoch: 8, Iter: 310, Loss: 4.50868\n",
      "[TRAIN] Epoch: 8, Iter: 320, Loss: 4.43818\n",
      "[TRAIN] Epoch: 8, Iter: 330, Loss: 4.48473\n",
      "[TRAIN] Epoch: 8, Iter: 340, Loss: 4.43982\n",
      "[TRAIN] Epoch: 8, Iter: 350, Loss: 4.54485\n",
      "[TRAIN] Epoch: 8, Iter: 360, Loss: 4.39256\n",
      "[TRAIN] Epoch: 8, Iter: 370, Loss: 4.47111\n",
      "[TRAIN] Epoch: 8, Iter: 380, Loss: 4.57340\n",
      "[TRAIN] Epoch: 8, Iter: 390, Loss: 4.38525\n",
      "[TRAIN] Epoch: 8, Iter: 400, Loss: 4.53626\n",
      "[TRAIN] Epoch: 8, Iter: 410, Loss: 4.49528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch: 8, Iter: 420, Loss: 4.44021\n",
      "[TRAIN] Epoch: 8, Iter: 430, Loss: 4.35516\n",
      "[TRAIN] Epoch: 8, Iter: 440, Loss: 4.57577\n",
      "[TRAIN] Epoch: 8, Iter: 450, Loss: 4.53196\n",
      "[TRAIN] Epoch: 8, Iter: 460, Loss: 4.54669\n",
      "[TRAIN] Epoch: 8, Iter: 470, Loss: 4.55893\n",
      "[TRAIN] Epoch: 8, Iter: 480, Loss: 4.63953\n",
      "[TRAIN] Epoch: 8, Iter: 490, Loss: 4.43696\n",
      "[TRAIN] Epoch: 8, Iter: 500, Loss: 4.44419\n",
      "[TRAIN] Epoch: 8, Iter: 510, Loss: 4.62342\n",
      "[TRAIN] Epoch: 8, Iter: 520, Loss: 4.46780\n",
      "[TRAIN] Epoch: 8, Iter: 530, Loss: 4.53557\n",
      "[TRAIN] Epoch: 8, Iter: 540, Loss: 4.52821\n",
      "[TRAIN] Epoch: 8, Iter: 550, Loss: 4.56924\n",
      "[TRAIN] Epoch: 8, Iter: 560, Loss: 4.40738\n",
      "[TRAIN] Epoch: 8, Iter: 570, Loss: 4.51618\n",
      "== [TRAIN] Epoch: 8, Perplexity: 88.479 ==>\n",
      "[VAL] Epoch: 8, Iter: 0, Loss: 4.82449\n",
      "[VAL] Epoch: 8, Iter: 10, Loss: 5.04453\n",
      "[VAL] Epoch: 8, Iter: 20, Loss: 5.14719\n",
      "[VAL] Epoch: 8, Iter: 30, Loss: 5.21139\n",
      "[VAL] Epoch: 8, Iter: 40, Loss: 4.90471\n",
      "[VAL] Epoch: 8, Iter: 50, Loss: 4.79869\n",
      "=== [VAL] Epoch: 8, Iter: 59, Perplexity: 145.896 ===>\n",
      "====== Epoch 9 ======>\n",
      "[TRAIN] Epoch: 9, Iter: 0, Loss: 4.23625\n",
      "[TRAIN] Epoch: 9, Iter: 10, Loss: 4.42194\n",
      "[TRAIN] Epoch: 9, Iter: 20, Loss: 4.22409\n",
      "[TRAIN] Epoch: 9, Iter: 30, Loss: 4.39581\n",
      "[TRAIN] Epoch: 9, Iter: 40, Loss: 4.49606\n",
      "[TRAIN] Epoch: 9, Iter: 50, Loss: 4.23168\n",
      "[TRAIN] Epoch: 9, Iter: 60, Loss: 4.39912\n",
      "[TRAIN] Epoch: 9, Iter: 70, Loss: 4.16843\n",
      "[TRAIN] Epoch: 9, Iter: 80, Loss: 4.14663\n",
      "[TRAIN] Epoch: 9, Iter: 90, Loss: 4.45764\n",
      "[TRAIN] Epoch: 9, Iter: 100, Loss: 4.44318\n",
      "[TRAIN] Epoch: 9, Iter: 110, Loss: 4.28863\n",
      "[TRAIN] Epoch: 9, Iter: 120, Loss: 4.44494\n",
      "[TRAIN] Epoch: 9, Iter: 130, Loss: 4.20372\n",
      "[TRAIN] Epoch: 9, Iter: 140, Loss: 4.44699\n",
      "[TRAIN] Epoch: 9, Iter: 150, Loss: 4.29847\n",
      "[TRAIN] Epoch: 9, Iter: 160, Loss: 4.53741\n",
      "[TRAIN] Epoch: 9, Iter: 170, Loss: 4.32713\n",
      "[TRAIN] Epoch: 9, Iter: 180, Loss: 4.44258\n",
      "[TRAIN] Epoch: 9, Iter: 190, Loss: 4.43362\n",
      "[TRAIN] Epoch: 9, Iter: 200, Loss: 4.62923\n",
      "[TRAIN] Epoch: 9, Iter: 210, Loss: 4.40208\n",
      "[TRAIN] Epoch: 9, Iter: 220, Loss: 4.59375\n",
      "[TRAIN] Epoch: 9, Iter: 230, Loss: 4.24688\n",
      "[TRAIN] Epoch: 9, Iter: 240, Loss: 4.32737\n",
      "[TRAIN] Epoch: 9, Iter: 250, Loss: 4.43571\n",
      "[TRAIN] Epoch: 9, Iter: 260, Loss: 4.37005\n",
      "[TRAIN] Epoch: 9, Iter: 270, Loss: 4.44878\n",
      "[TRAIN] Epoch: 9, Iter: 280, Loss: 4.57065\n",
      "[TRAIN] Epoch: 9, Iter: 290, Loss: 4.43090\n",
      "[TRAIN] Epoch: 9, Iter: 300, Loss: 4.41648\n",
      "[TRAIN] Epoch: 9, Iter: 310, Loss: 4.35992\n",
      "[TRAIN] Epoch: 9, Iter: 320, Loss: 4.49960\n",
      "[TRAIN] Epoch: 9, Iter: 330, Loss: 4.48763\n",
      "[TRAIN] Epoch: 9, Iter: 340, Loss: 4.38317\n",
      "[TRAIN] Epoch: 9, Iter: 350, Loss: 4.60334\n",
      "[TRAIN] Epoch: 9, Iter: 360, Loss: 4.25416\n",
      "[TRAIN] Epoch: 9, Iter: 370, Loss: 4.30750\n",
      "[TRAIN] Epoch: 9, Iter: 380, Loss: 4.30810\n",
      "[TRAIN] Epoch: 9, Iter: 390, Loss: 4.42258\n",
      "[TRAIN] Epoch: 9, Iter: 400, Loss: 4.22772\n",
      "[TRAIN] Epoch: 9, Iter: 410, Loss: 4.30079\n",
      "[TRAIN] Epoch: 9, Iter: 420, Loss: 4.47272\n",
      "[TRAIN] Epoch: 9, Iter: 430, Loss: 4.43638\n",
      "[TRAIN] Epoch: 9, Iter: 440, Loss: 4.45365\n",
      "[TRAIN] Epoch: 9, Iter: 450, Loss: 4.43580\n",
      "[TRAIN] Epoch: 9, Iter: 460, Loss: 4.41667\n",
      "[TRAIN] Epoch: 9, Iter: 470, Loss: 4.24711\n",
      "[TRAIN] Epoch: 9, Iter: 480, Loss: 4.28494\n",
      "[TRAIN] Epoch: 9, Iter: 490, Loss: 4.26464\n",
      "[TRAIN] Epoch: 9, Iter: 500, Loss: 4.40315\n",
      "[TRAIN] Epoch: 9, Iter: 510, Loss: 4.60994\n",
      "[TRAIN] Epoch: 9, Iter: 520, Loss: 4.63943\n",
      "[TRAIN] Epoch: 9, Iter: 530, Loss: 4.37681\n",
      "[TRAIN] Epoch: 9, Iter: 540, Loss: 4.39805\n",
      "[TRAIN] Epoch: 9, Iter: 550, Loss: 4.45440\n",
      "[TRAIN] Epoch: 9, Iter: 560, Loss: 4.37379\n",
      "[TRAIN] Epoch: 9, Iter: 570, Loss: 4.29124\n",
      "== [TRAIN] Epoch: 9, Perplexity: 81.856 ==>\n",
      "[VAL] Epoch: 9, Iter: 0, Loss: 4.80189\n",
      "[VAL] Epoch: 9, Iter: 10, Loss: 5.05275\n",
      "[VAL] Epoch: 9, Iter: 20, Loss: 5.16114\n",
      "[VAL] Epoch: 9, Iter: 30, Loss: 5.23056\n",
      "[VAL] Epoch: 9, Iter: 40, Loss: 4.90189\n",
      "[VAL] Epoch: 9, Iter: 50, Loss: 4.80107\n",
      "=== [VAL] Epoch: 9, Iter: 59, Perplexity: 145.811 ===>\n",
      "[TEST] Epoch: 9, Iter: 0, Loss: 5.06444\n",
      "[TEST] Epoch: 9, Iter: 10, Loss: 5.01358\n",
      "[TEST] Epoch: 9, Iter: 20, Loss: 5.37964\n",
      "[TEST] Epoch: 9, Iter: 30, Loss: 5.30972\n",
      "[TEST] Epoch: 9, Iter: 40, Loss: 5.01746\n",
      "[TEST] Epoch: 9, Iter: 50, Loss: 5.09687\n",
      "[TEST] Epoch: 9, Iter: 60, Loss: 4.87445\n",
      "=== [TEST] Epoch: 9, Iter: 68, Perplexity: 148.223 ===>\n",
      "===== Best validation perplexity: 145.811 =====>\n"
     ]
    }
   ],
   "source": [
    "args = configs[1]  # Run the first configuration\n",
    "logs = main(args)\n",
    "if args.log:\n",
    "  save_logs(args, *logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized GPT1 model with 38372352 total parameters, of which 7087872 are learnable.args are: Namespace(batch_size=16, data_folder='./data', device='cuda', embeddings='./data/embeddings.npz', epochs=10, exp_id='debug', layers=1, log=False, log_dir='logs', lr=0.001, model='gpt1', momentum=0.9, num_workers=2, optimizer='adamw', print_every=10, progress_bar=False, seed=1023, weight_decay=0.0005)\n",
      "====== Epoch 0 ======>\n",
      "[TRAIN] Epoch: 0, Iter: 0, Loss: 46.82186\n",
      "[TRAIN] Epoch: 0, Iter: 10, Loss: 8.78794\n",
      "[TRAIN] Epoch: 0, Iter: 20, Loss: 8.34682\n",
      "[TRAIN] Epoch: 0, Iter: 30, Loss: 8.05178\n",
      "[TRAIN] Epoch: 0, Iter: 40, Loss: 7.87844\n",
      "[TRAIN] Epoch: 0, Iter: 50, Loss: 7.76828\n",
      "[TRAIN] Epoch: 0, Iter: 60, Loss: 7.75323\n",
      "[TRAIN] Epoch: 0, Iter: 70, Loss: 7.56756\n",
      "[TRAIN] Epoch: 0, Iter: 80, Loss: 7.78600\n",
      "[TRAIN] Epoch: 0, Iter: 90, Loss: 7.54513\n",
      "[TRAIN] Epoch: 0, Iter: 100, Loss: 7.61290\n",
      "[TRAIN] Epoch: 0, Iter: 110, Loss: 7.33569\n",
      "[TRAIN] Epoch: 0, Iter: 120, Loss: 7.25536\n",
      "[TRAIN] Epoch: 0, Iter: 130, Loss: 7.24319\n",
      "[TRAIN] Epoch: 0, Iter: 140, Loss: 7.06206\n",
      "[TRAIN] Epoch: 0, Iter: 150, Loss: 7.21514\n",
      "[TRAIN] Epoch: 0, Iter: 160, Loss: 6.93330\n",
      "[TRAIN] Epoch: 0, Iter: 170, Loss: 6.64881\n",
      "[TRAIN] Epoch: 0, Iter: 180, Loss: 6.71370\n",
      "[TRAIN] Epoch: 0, Iter: 190, Loss: 6.62701\n",
      "[TRAIN] Epoch: 0, Iter: 200, Loss: 6.54863\n",
      "[TRAIN] Epoch: 0, Iter: 210, Loss: 6.70941\n",
      "[TRAIN] Epoch: 0, Iter: 220, Loss: 6.52972\n",
      "[TRAIN] Epoch: 0, Iter: 230, Loss: 6.61636\n",
      "[TRAIN] Epoch: 0, Iter: 240, Loss: 6.37059\n",
      "[TRAIN] Epoch: 0, Iter: 250, Loss: 6.44946\n",
      "[TRAIN] Epoch: 0, Iter: 260, Loss: 6.38830\n",
      "[TRAIN] Epoch: 0, Iter: 270, Loss: 6.38882\n",
      "[TRAIN] Epoch: 0, Iter: 280, Loss: 6.31153\n",
      "[TRAIN] Epoch: 0, Iter: 290, Loss: 6.36443\n",
      "[TRAIN] Epoch: 0, Iter: 300, Loss: 6.26532\n",
      "[TRAIN] Epoch: 0, Iter: 310, Loss: 6.18342\n",
      "[TRAIN] Epoch: 0, Iter: 320, Loss: 6.23982\n",
      "[TRAIN] Epoch: 0, Iter: 330, Loss: 6.23908\n",
      "[TRAIN] Epoch: 0, Iter: 340, Loss: 6.19217\n",
      "[TRAIN] Epoch: 0, Iter: 350, Loss: 6.27170\n",
      "[TRAIN] Epoch: 0, Iter: 360, Loss: 6.10968\n",
      "[TRAIN] Epoch: 0, Iter: 370, Loss: 6.17785\n",
      "[TRAIN] Epoch: 0, Iter: 380, Loss: 6.08554\n",
      "[TRAIN] Epoch: 0, Iter: 390, Loss: 6.19931\n",
      "[TRAIN] Epoch: 0, Iter: 400, Loss: 5.98812\n",
      "[TRAIN] Epoch: 0, Iter: 410, Loss: 6.02644\n",
      "[TRAIN] Epoch: 0, Iter: 420, Loss: 6.07836\n",
      "[TRAIN] Epoch: 0, Iter: 430, Loss: 6.13077\n",
      "[TRAIN] Epoch: 0, Iter: 440, Loss: 6.07543\n",
      "[TRAIN] Epoch: 0, Iter: 450, Loss: 5.95756\n",
      "[TRAIN] Epoch: 0, Iter: 460, Loss: 6.07755\n",
      "[TRAIN] Epoch: 0, Iter: 470, Loss: 5.86869\n",
      "[TRAIN] Epoch: 0, Iter: 480, Loss: 5.99230\n",
      "[TRAIN] Epoch: 0, Iter: 490, Loss: 5.91248\n",
      "[TRAIN] Epoch: 0, Iter: 500, Loss: 6.01126\n",
      "[TRAIN] Epoch: 0, Iter: 510, Loss: 5.83385\n",
      "[TRAIN] Epoch: 0, Iter: 520, Loss: 5.76757\n",
      "[TRAIN] Epoch: 0, Iter: 530, Loss: 5.84863\n",
      "[TRAIN] Epoch: 0, Iter: 540, Loss: 5.73761\n",
      "[TRAIN] Epoch: 0, Iter: 550, Loss: 5.99111\n",
      "[TRAIN] Epoch: 0, Iter: 560, Loss: 5.90046\n",
      "[TRAIN] Epoch: 0, Iter: 570, Loss: 5.98504\n",
      "== [TRAIN] Epoch: 0, Perplexity: 849.466 ==>\n",
      "Before scheduler loss is: 6.7446078071124145\n",
      "[VAL] Epoch: 0, Iter: 0, Loss: 5.87334\n",
      "[VAL] Epoch: 0, Iter: 10, Loss: 5.89646\n",
      "[VAL] Epoch: 0, Iter: 20, Loss: 6.01139\n",
      "[VAL] Epoch: 0, Iter: 30, Loss: 5.93930\n",
      "[VAL] Epoch: 0, Iter: 40, Loss: 5.79664\n",
      "[VAL] Epoch: 0, Iter: 50, Loss: 5.65094\n",
      "=== [VAL] Epoch: 0, Iter: 59, Perplexity: 337.860 ===>\n",
      "====== Epoch 1 ======>\n",
      "[TRAIN] Epoch: 1, Iter: 0, Loss: 5.79334\n",
      "[TRAIN] Epoch: 1, Iter: 10, Loss: 5.79375\n",
      "[TRAIN] Epoch: 1, Iter: 20, Loss: 5.71797\n",
      "[TRAIN] Epoch: 1, Iter: 30, Loss: 5.60255\n",
      "[TRAIN] Epoch: 1, Iter: 40, Loss: 5.90785\n",
      "[TRAIN] Epoch: 1, Iter: 50, Loss: 5.61587\n",
      "[TRAIN] Epoch: 1, Iter: 60, Loss: 5.78202\n",
      "[TRAIN] Epoch: 1, Iter: 70, Loss: 5.72439\n",
      "[TRAIN] Epoch: 1, Iter: 80, Loss: 5.82229\n",
      "[TRAIN] Epoch: 1, Iter: 90, Loss: 5.54153\n",
      "[TRAIN] Epoch: 1, Iter: 100, Loss: 5.42161\n",
      "[TRAIN] Epoch: 1, Iter: 110, Loss: 5.57354\n",
      "[TRAIN] Epoch: 1, Iter: 120, Loss: 5.66494\n",
      "[TRAIN] Epoch: 1, Iter: 130, Loss: 5.41869\n",
      "[TRAIN] Epoch: 1, Iter: 140, Loss: 5.56310\n",
      "[TRAIN] Epoch: 1, Iter: 150, Loss: 5.64287\n",
      "[TRAIN] Epoch: 1, Iter: 160, Loss: 5.67595\n",
      "[TRAIN] Epoch: 1, Iter: 170, Loss: 5.40392\n",
      "[TRAIN] Epoch: 1, Iter: 180, Loss: 5.36493\n",
      "[TRAIN] Epoch: 1, Iter: 190, Loss: 5.47565\n",
      "[TRAIN] Epoch: 1, Iter: 200, Loss: 5.56161\n",
      "[TRAIN] Epoch: 1, Iter: 210, Loss: 5.37687\n",
      "[TRAIN] Epoch: 1, Iter: 220, Loss: 5.54720\n",
      "[TRAIN] Epoch: 1, Iter: 230, Loss: 5.43295\n",
      "[TRAIN] Epoch: 1, Iter: 240, Loss: 5.44590\n",
      "[TRAIN] Epoch: 1, Iter: 250, Loss: 5.38217\n",
      "[TRAIN] Epoch: 1, Iter: 260, Loss: 5.60837\n",
      "[TRAIN] Epoch: 1, Iter: 270, Loss: 5.31254\n",
      "[TRAIN] Epoch: 1, Iter: 280, Loss: 5.45549\n",
      "[TRAIN] Epoch: 1, Iter: 290, Loss: 5.47603\n",
      "[TRAIN] Epoch: 1, Iter: 300, Loss: 5.37613\n",
      "[TRAIN] Epoch: 1, Iter: 310, Loss: 5.44354\n",
      "[TRAIN] Epoch: 1, Iter: 320, Loss: 5.57619\n",
      "[TRAIN] Epoch: 1, Iter: 330, Loss: 5.59625\n",
      "[TRAIN] Epoch: 1, Iter: 340, Loss: 5.43914\n",
      "[TRAIN] Epoch: 1, Iter: 350, Loss: 5.42649\n",
      "[TRAIN] Epoch: 1, Iter: 360, Loss: 5.38653\n",
      "[TRAIN] Epoch: 1, Iter: 370, Loss: 5.27523\n",
      "[TRAIN] Epoch: 1, Iter: 380, Loss: 5.23371\n",
      "[TRAIN] Epoch: 1, Iter: 390, Loss: 5.33405\n",
      "[TRAIN] Epoch: 1, Iter: 400, Loss: 5.33131\n",
      "[TRAIN] Epoch: 1, Iter: 410, Loss: 5.34790\n",
      "[TRAIN] Epoch: 1, Iter: 420, Loss: 5.30135\n",
      "[TRAIN] Epoch: 1, Iter: 430, Loss: 5.45385\n",
      "[TRAIN] Epoch: 1, Iter: 440, Loss: 5.28167\n",
      "[TRAIN] Epoch: 1, Iter: 450, Loss: 5.34714\n",
      "[TRAIN] Epoch: 1, Iter: 460, Loss: 5.24180\n",
      "[TRAIN] Epoch: 1, Iter: 470, Loss: 5.26460\n",
      "[TRAIN] Epoch: 1, Iter: 480, Loss: 5.25216\n",
      "[TRAIN] Epoch: 1, Iter: 490, Loss: 5.27341\n",
      "[TRAIN] Epoch: 1, Iter: 500, Loss: 5.34917\n",
      "[TRAIN] Epoch: 1, Iter: 510, Loss: 5.04123\n",
      "[TRAIN] Epoch: 1, Iter: 520, Loss: 5.31728\n",
      "[TRAIN] Epoch: 1, Iter: 530, Loss: 5.11593\n",
      "[TRAIN] Epoch: 1, Iter: 540, Loss: 5.13989\n",
      "[TRAIN] Epoch: 1, Iter: 550, Loss: 5.09331\n",
      "[TRAIN] Epoch: 1, Iter: 560, Loss: 5.10976\n",
      "[TRAIN] Epoch: 1, Iter: 570, Loss: 5.10196\n",
      "== [TRAIN] Epoch: 1, Perplexity: 229.944 ==>\n",
      "Before scheduler loss is: 5.437837164448865\n",
      "[VAL] Epoch: 1, Iter: 0, Loss: 5.27073\n",
      "[VAL] Epoch: 1, Iter: 10, Loss: 5.31924\n",
      "[VAL] Epoch: 1, Iter: 20, Loss: 5.50054\n",
      "[VAL] Epoch: 1, Iter: 30, Loss: 5.45657\n",
      "[VAL] Epoch: 1, Iter: 40, Loss: 5.24608\n",
      "[VAL] Epoch: 1, Iter: 50, Loss: 5.17568\n",
      "=== [VAL] Epoch: 1, Iter: 59, Perplexity: 202.680 ===>\n",
      "====== Epoch 2 ======>\n",
      "[TRAIN] Epoch: 2, Iter: 0, Loss: 5.07825\n",
      "[TRAIN] Epoch: 2, Iter: 10, Loss: 5.03044\n",
      "[TRAIN] Epoch: 2, Iter: 20, Loss: 5.11752\n",
      "[TRAIN] Epoch: 2, Iter: 30, Loss: 5.09395\n",
      "[TRAIN] Epoch: 2, Iter: 40, Loss: 5.04159\n",
      "[TRAIN] Epoch: 2, Iter: 50, Loss: 4.95264\n",
      "[TRAIN] Epoch: 2, Iter: 60, Loss: 4.94723\n",
      "[TRAIN] Epoch: 2, Iter: 70, Loss: 4.88855\n",
      "[TRAIN] Epoch: 2, Iter: 80, Loss: 5.01500\n",
      "[TRAIN] Epoch: 2, Iter: 90, Loss: 5.06151\n",
      "[TRAIN] Epoch: 2, Iter: 100, Loss: 5.10354\n",
      "[TRAIN] Epoch: 2, Iter: 110, Loss: 5.04681\n",
      "[TRAIN] Epoch: 2, Iter: 120, Loss: 5.07910\n",
      "[TRAIN] Epoch: 2, Iter: 130, Loss: 4.93063\n",
      "[TRAIN] Epoch: 2, Iter: 140, Loss: 5.16090\n",
      "[TRAIN] Epoch: 2, Iter: 150, Loss: 4.97429\n",
      "[TRAIN] Epoch: 2, Iter: 160, Loss: 5.09518\n",
      "[TRAIN] Epoch: 2, Iter: 170, Loss: 5.12782\n",
      "[TRAIN] Epoch: 2, Iter: 180, Loss: 5.02111\n",
      "[TRAIN] Epoch: 2, Iter: 190, Loss: 4.94766\n",
      "[TRAIN] Epoch: 2, Iter: 200, Loss: 5.13520\n",
      "[TRAIN] Epoch: 2, Iter: 210, Loss: 5.05441\n",
      "[TRAIN] Epoch: 2, Iter: 220, Loss: 5.09229\n",
      "[TRAIN] Epoch: 2, Iter: 230, Loss: 4.83740\n",
      "[TRAIN] Epoch: 2, Iter: 240, Loss: 4.88343\n",
      "[TRAIN] Epoch: 2, Iter: 250, Loss: 5.08477\n",
      "[TRAIN] Epoch: 2, Iter: 260, Loss: 4.98680\n",
      "[TRAIN] Epoch: 2, Iter: 270, Loss: 4.90536\n",
      "[TRAIN] Epoch: 2, Iter: 280, Loss: 4.99689\n",
      "[TRAIN] Epoch: 2, Iter: 290, Loss: 4.89478\n",
      "[TRAIN] Epoch: 2, Iter: 300, Loss: 4.92551\n",
      "[TRAIN] Epoch: 2, Iter: 310, Loss: 4.91630\n",
      "[TRAIN] Epoch: 2, Iter: 320, Loss: 5.14917\n",
      "[TRAIN] Epoch: 2, Iter: 330, Loss: 4.84187\n",
      "[TRAIN] Epoch: 2, Iter: 340, Loss: 4.87858\n",
      "[TRAIN] Epoch: 2, Iter: 350, Loss: 4.92904\n",
      "[TRAIN] Epoch: 2, Iter: 360, Loss: 4.81221\n",
      "[TRAIN] Epoch: 2, Iter: 370, Loss: 5.10259\n",
      "[TRAIN] Epoch: 2, Iter: 380, Loss: 4.85946\n",
      "[TRAIN] Epoch: 2, Iter: 390, Loss: 5.11414\n",
      "[TRAIN] Epoch: 2, Iter: 400, Loss: 4.98878\n",
      "[TRAIN] Epoch: 2, Iter: 410, Loss: 4.80472\n",
      "[TRAIN] Epoch: 2, Iter: 420, Loss: 5.02487\n",
      "[TRAIN] Epoch: 2, Iter: 430, Loss: 4.75182\n",
      "[TRAIN] Epoch: 2, Iter: 440, Loss: 5.00405\n",
      "[TRAIN] Epoch: 2, Iter: 450, Loss: 5.03545\n",
      "[TRAIN] Epoch: 2, Iter: 460, Loss: 4.96495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch: 2, Iter: 470, Loss: 4.67787\n",
      "[TRAIN] Epoch: 2, Iter: 480, Loss: 4.86989\n",
      "[TRAIN] Epoch: 2, Iter: 490, Loss: 4.72952\n",
      "[TRAIN] Epoch: 2, Iter: 500, Loss: 4.88216\n",
      "[TRAIN] Epoch: 2, Iter: 510, Loss: 4.95346\n",
      "[TRAIN] Epoch: 2, Iter: 520, Loss: 4.97153\n",
      "[TRAIN] Epoch: 2, Iter: 530, Loss: 4.98050\n",
      "[TRAIN] Epoch: 2, Iter: 540, Loss: 4.76043\n",
      "[TRAIN] Epoch: 2, Iter: 550, Loss: 4.77585\n",
      "[TRAIN] Epoch: 2, Iter: 560, Loss: 4.96940\n",
      "[TRAIN] Epoch: 2, Iter: 570, Loss: 4.87598\n",
      "== [TRAIN] Epoch: 2, Perplexity: 141.035 ==>\n",
      "Before scheduler loss is: 4.949008449869224\n",
      "[VAL] Epoch: 2, Iter: 0, Loss: 5.01061\n",
      "[VAL] Epoch: 2, Iter: 10, Loss: 5.11378\n",
      "[VAL] Epoch: 2, Iter: 20, Loss: 5.25649\n",
      "[VAL] Epoch: 2, Iter: 30, Loss: 5.29789\n",
      "[VAL] Epoch: 2, Iter: 40, Loss: 5.04418\n",
      "[VAL] Epoch: 2, Iter: 50, Loss: 4.92253\n",
      "=== [VAL] Epoch: 2, Iter: 59, Perplexity: 163.483 ===>\n",
      "====== Epoch 3 ======>\n",
      "[TRAIN] Epoch: 3, Iter: 0, Loss: 4.70530\n",
      "[TRAIN] Epoch: 3, Iter: 10, Loss: 4.83419\n",
      "[TRAIN] Epoch: 3, Iter: 20, Loss: 4.78206\n",
      "[TRAIN] Epoch: 3, Iter: 30, Loss: 4.61156\n",
      "[TRAIN] Epoch: 3, Iter: 40, Loss: 4.66620\n",
      "[TRAIN] Epoch: 3, Iter: 50, Loss: 4.84098\n",
      "[TRAIN] Epoch: 3, Iter: 60, Loss: 4.48417\n",
      "[TRAIN] Epoch: 3, Iter: 70, Loss: 4.68841\n",
      "[TRAIN] Epoch: 3, Iter: 80, Loss: 4.83582\n",
      "[TRAIN] Epoch: 3, Iter: 90, Loss: 4.59215\n",
      "[TRAIN] Epoch: 3, Iter: 100, Loss: 4.71530\n",
      "[TRAIN] Epoch: 3, Iter: 110, Loss: 4.53742\n",
      "[TRAIN] Epoch: 3, Iter: 120, Loss: 4.78557\n",
      "[TRAIN] Epoch: 3, Iter: 130, Loss: 4.59795\n",
      "[TRAIN] Epoch: 3, Iter: 140, Loss: 4.52230\n",
      "[TRAIN] Epoch: 3, Iter: 150, Loss: 4.78400\n",
      "[TRAIN] Epoch: 3, Iter: 160, Loss: 4.68036\n",
      "[TRAIN] Epoch: 3, Iter: 170, Loss: 4.69660\n",
      "[TRAIN] Epoch: 3, Iter: 180, Loss: 4.70525\n",
      "[TRAIN] Epoch: 3, Iter: 190, Loss: 4.58177\n",
      "[TRAIN] Epoch: 3, Iter: 200, Loss: 4.61006\n",
      "[TRAIN] Epoch: 3, Iter: 210, Loss: 4.71638\n",
      "[TRAIN] Epoch: 3, Iter: 220, Loss: 4.52785\n",
      "[TRAIN] Epoch: 3, Iter: 230, Loss: 4.74863\n",
      "[TRAIN] Epoch: 3, Iter: 240, Loss: 4.78847\n",
      "[TRAIN] Epoch: 3, Iter: 250, Loss: 4.61246\n",
      "[TRAIN] Epoch: 3, Iter: 260, Loss: 4.80002\n",
      "[TRAIN] Epoch: 3, Iter: 270, Loss: 4.55502\n",
      "[TRAIN] Epoch: 3, Iter: 280, Loss: 4.59434\n",
      "[TRAIN] Epoch: 3, Iter: 290, Loss: 4.53351\n",
      "[TRAIN] Epoch: 3, Iter: 300, Loss: 4.71986\n",
      "[TRAIN] Epoch: 3, Iter: 310, Loss: 4.75130\n",
      "[TRAIN] Epoch: 3, Iter: 320, Loss: 4.60564\n",
      "[TRAIN] Epoch: 3, Iter: 330, Loss: 4.83782\n",
      "[TRAIN] Epoch: 3, Iter: 340, Loss: 4.72532\n",
      "[TRAIN] Epoch: 3, Iter: 350, Loss: 4.54273\n",
      "[TRAIN] Epoch: 3, Iter: 360, Loss: 4.69123\n",
      "[TRAIN] Epoch: 3, Iter: 370, Loss: 4.64605\n",
      "[TRAIN] Epoch: 3, Iter: 380, Loss: 4.67991\n",
      "[TRAIN] Epoch: 3, Iter: 390, Loss: 4.50588\n",
      "[TRAIN] Epoch: 3, Iter: 400, Loss: 4.71463\n",
      "[TRAIN] Epoch: 3, Iter: 410, Loss: 4.48830\n",
      "[TRAIN] Epoch: 3, Iter: 420, Loss: 4.64133\n",
      "[TRAIN] Epoch: 3, Iter: 430, Loss: 4.81181\n",
      "[TRAIN] Epoch: 3, Iter: 440, Loss: 4.65498\n",
      "[TRAIN] Epoch: 3, Iter: 450, Loss: 4.56106\n",
      "[TRAIN] Epoch: 3, Iter: 460, Loss: 4.63665\n",
      "[TRAIN] Epoch: 3, Iter: 470, Loss: 4.70084\n",
      "[TRAIN] Epoch: 3, Iter: 480, Loss: 4.55837\n",
      "[TRAIN] Epoch: 3, Iter: 490, Loss: 4.64235\n",
      "[TRAIN] Epoch: 3, Iter: 500, Loss: 4.54547\n",
      "[TRAIN] Epoch: 3, Iter: 510, Loss: 4.69316\n",
      "[TRAIN] Epoch: 3, Iter: 520, Loss: 4.72748\n",
      "[TRAIN] Epoch: 3, Iter: 530, Loss: 4.65788\n",
      "[TRAIN] Epoch: 3, Iter: 540, Loss: 4.54059\n",
      "[TRAIN] Epoch: 3, Iter: 550, Loss: 4.82478\n",
      "[TRAIN] Epoch: 3, Iter: 560, Loss: 4.61793\n",
      "[TRAIN] Epoch: 3, Iter: 570, Loss: 4.63954\n",
      "== [TRAIN] Epoch: 3, Perplexity: 104.736 ==>\n",
      "Before scheduler loss is: 4.651439087303718\n",
      "[VAL] Epoch: 3, Iter: 0, Loss: 4.85583\n",
      "[VAL] Epoch: 3, Iter: 10, Loss: 5.07559\n",
      "[VAL] Epoch: 3, Iter: 20, Loss: 5.21368\n",
      "[VAL] Epoch: 3, Iter: 30, Loss: 5.22548\n",
      "[VAL] Epoch: 3, Iter: 40, Loss: 4.97284\n",
      "[VAL] Epoch: 3, Iter: 50, Loss: 4.82915\n",
      "=== [VAL] Epoch: 3, Iter: 59, Perplexity: 151.440 ===>\n",
      "====== Epoch 4 ======>\n",
      "[TRAIN] Epoch: 4, Iter: 0, Loss: 4.40672\n",
      "[TRAIN] Epoch: 4, Iter: 10, Loss: 4.15543\n",
      "[TRAIN] Epoch: 4, Iter: 20, Loss: 4.32496\n",
      "[TRAIN] Epoch: 4, Iter: 30, Loss: 4.13788\n",
      "[TRAIN] Epoch: 4, Iter: 40, Loss: 4.07516\n",
      "[TRAIN] Epoch: 4, Iter: 50, Loss: 4.57699\n",
      "[TRAIN] Epoch: 4, Iter: 60, Loss: 4.45476\n",
      "[TRAIN] Epoch: 4, Iter: 70, Loss: 4.73432\n",
      "[TRAIN] Epoch: 4, Iter: 80, Loss: 4.32835\n",
      "[TRAIN] Epoch: 4, Iter: 90, Loss: 4.36023\n",
      "[TRAIN] Epoch: 4, Iter: 100, Loss: 4.45005\n",
      "[TRAIN] Epoch: 4, Iter: 110, Loss: 4.34412\n",
      "[TRAIN] Epoch: 4, Iter: 120, Loss: 4.34437\n",
      "[TRAIN] Epoch: 4, Iter: 130, Loss: 4.17969\n",
      "[TRAIN] Epoch: 4, Iter: 140, Loss: 4.50339\n",
      "[TRAIN] Epoch: 4, Iter: 150, Loss: 4.44541\n",
      "[TRAIN] Epoch: 4, Iter: 160, Loss: 4.22379\n",
      "[TRAIN] Epoch: 4, Iter: 170, Loss: 4.52331\n",
      "[TRAIN] Epoch: 4, Iter: 180, Loss: 4.61148\n",
      "[TRAIN] Epoch: 4, Iter: 190, Loss: 4.72969\n",
      "[TRAIN] Epoch: 4, Iter: 200, Loss: 4.39585\n",
      "[TRAIN] Epoch: 4, Iter: 210, Loss: 4.46413\n",
      "[TRAIN] Epoch: 4, Iter: 220, Loss: 4.17836\n",
      "[TRAIN] Epoch: 4, Iter: 230, Loss: 4.46232\n",
      "[TRAIN] Epoch: 4, Iter: 240, Loss: 4.31759\n",
      "[TRAIN] Epoch: 4, Iter: 250, Loss: 4.36742\n",
      "[TRAIN] Epoch: 4, Iter: 260, Loss: 4.36564\n",
      "[TRAIN] Epoch: 4, Iter: 270, Loss: 4.27092\n",
      "[TRAIN] Epoch: 4, Iter: 280, Loss: 4.38780\n",
      "[TRAIN] Epoch: 4, Iter: 290, Loss: 4.38742\n",
      "[TRAIN] Epoch: 4, Iter: 300, Loss: 4.38562\n",
      "[TRAIN] Epoch: 4, Iter: 310, Loss: 4.42238\n",
      "[TRAIN] Epoch: 4, Iter: 320, Loss: 4.58076\n",
      "[TRAIN] Epoch: 4, Iter: 330, Loss: 4.40668\n",
      "[TRAIN] Epoch: 4, Iter: 340, Loss: 4.45996\n",
      "[TRAIN] Epoch: 4, Iter: 350, Loss: 4.29375\n",
      "[TRAIN] Epoch: 4, Iter: 360, Loss: 4.42447\n",
      "[TRAIN] Epoch: 4, Iter: 370, Loss: 4.37601\n",
      "[TRAIN] Epoch: 4, Iter: 380, Loss: 4.43813\n",
      "[TRAIN] Epoch: 4, Iter: 390, Loss: 4.52119\n",
      "[TRAIN] Epoch: 4, Iter: 400, Loss: 4.38841\n",
      "[TRAIN] Epoch: 4, Iter: 410, Loss: 4.49870\n",
      "[TRAIN] Epoch: 4, Iter: 420, Loss: 4.27887\n",
      "[TRAIN] Epoch: 4, Iter: 430, Loss: 4.26784\n",
      "[TRAIN] Epoch: 4, Iter: 440, Loss: 4.21842\n",
      "[TRAIN] Epoch: 4, Iter: 450, Loss: 4.39845\n",
      "[TRAIN] Epoch: 4, Iter: 460, Loss: 4.46294\n",
      "[TRAIN] Epoch: 4, Iter: 470, Loss: 4.26323\n",
      "[TRAIN] Epoch: 4, Iter: 480, Loss: 4.59938\n",
      "[TRAIN] Epoch: 4, Iter: 490, Loss: 4.43779\n",
      "[TRAIN] Epoch: 4, Iter: 500, Loss: 4.31336\n",
      "[TRAIN] Epoch: 4, Iter: 510, Loss: 4.43990\n",
      "[TRAIN] Epoch: 4, Iter: 520, Loss: 4.44584\n",
      "[TRAIN] Epoch: 4, Iter: 530, Loss: 4.58761\n",
      "[TRAIN] Epoch: 4, Iter: 540, Loss: 4.30950\n",
      "[TRAIN] Epoch: 4, Iter: 550, Loss: 4.60613\n",
      "[TRAIN] Epoch: 4, Iter: 560, Loss: 4.54145\n",
      "[TRAIN] Epoch: 4, Iter: 570, Loss: 4.26651\n",
      "== [TRAIN] Epoch: 4, Perplexity: 83.927 ==>\n",
      "Before scheduler loss is: 4.429949203855358\n",
      "[VAL] Epoch: 4, Iter: 0, Loss: 4.79090\n",
      "[VAL] Epoch: 4, Iter: 10, Loss: 5.00666\n",
      "[VAL] Epoch: 4, Iter: 20, Loss: 5.16809\n",
      "[VAL] Epoch: 4, Iter: 30, Loss: 5.22032\n",
      "[VAL] Epoch: 4, Iter: 40, Loss: 4.94004\n",
      "[VAL] Epoch: 4, Iter: 50, Loss: 4.79677\n",
      "=== [VAL] Epoch: 4, Iter: 59, Perplexity: 145.700 ===>\n",
      "====== Epoch 5 ======>\n",
      "[TRAIN] Epoch: 5, Iter: 0, Loss: 4.28570\n",
      "[TRAIN] Epoch: 5, Iter: 10, Loss: 4.35028\n",
      "[TRAIN] Epoch: 5, Iter: 20, Loss: 4.05125\n",
      "[TRAIN] Epoch: 5, Iter: 30, Loss: 4.11061\n",
      "[TRAIN] Epoch: 5, Iter: 40, Loss: 4.23974\n",
      "[TRAIN] Epoch: 5, Iter: 50, Loss: 4.19375\n",
      "[TRAIN] Epoch: 5, Iter: 60, Loss: 3.88773\n",
      "[TRAIN] Epoch: 5, Iter: 70, Loss: 4.14906\n",
      "[TRAIN] Epoch: 5, Iter: 80, Loss: 4.16723\n",
      "[TRAIN] Epoch: 5, Iter: 90, Loss: 4.38779\n",
      "[TRAIN] Epoch: 5, Iter: 100, Loss: 4.29058\n",
      "[TRAIN] Epoch: 5, Iter: 110, Loss: 4.11819\n",
      "[TRAIN] Epoch: 5, Iter: 120, Loss: 4.43600\n",
      "[TRAIN] Epoch: 5, Iter: 130, Loss: 4.28621\n",
      "[TRAIN] Epoch: 5, Iter: 140, Loss: 4.36233\n",
      "[TRAIN] Epoch: 5, Iter: 150, Loss: 4.18898\n",
      "[TRAIN] Epoch: 5, Iter: 160, Loss: 4.35773\n",
      "[TRAIN] Epoch: 5, Iter: 170, Loss: 4.36600\n",
      "[TRAIN] Epoch: 5, Iter: 180, Loss: 4.26814\n",
      "[TRAIN] Epoch: 5, Iter: 190, Loss: 4.06679\n",
      "[TRAIN] Epoch: 5, Iter: 200, Loss: 4.37861\n",
      "[TRAIN] Epoch: 5, Iter: 210, Loss: 4.33853\n",
      "[TRAIN] Epoch: 5, Iter: 220, Loss: 4.30978\n",
      "[TRAIN] Epoch: 5, Iter: 230, Loss: 4.31101\n",
      "[TRAIN] Epoch: 5, Iter: 240, Loss: 4.31041\n",
      "[TRAIN] Epoch: 5, Iter: 250, Loss: 4.27328\n",
      "[TRAIN] Epoch: 5, Iter: 260, Loss: 4.25533\n",
      "[TRAIN] Epoch: 5, Iter: 270, Loss: 4.26790\n",
      "[TRAIN] Epoch: 5, Iter: 280, Loss: 4.15718\n",
      "[TRAIN] Epoch: 5, Iter: 290, Loss: 4.33510\n",
      "[TRAIN] Epoch: 5, Iter: 300, Loss: 4.18854\n",
      "[TRAIN] Epoch: 5, Iter: 310, Loss: 4.23657\n",
      "[TRAIN] Epoch: 5, Iter: 320, Loss: 4.41034\n",
      "[TRAIN] Epoch: 5, Iter: 330, Loss: 4.32394\n",
      "[TRAIN] Epoch: 5, Iter: 340, Loss: 4.31582\n",
      "[TRAIN] Epoch: 5, Iter: 350, Loss: 4.11480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch: 5, Iter: 360, Loss: 4.25611\n",
      "[TRAIN] Epoch: 5, Iter: 370, Loss: 4.19754\n",
      "[TRAIN] Epoch: 5, Iter: 380, Loss: 4.14839\n",
      "[TRAIN] Epoch: 5, Iter: 390, Loss: 4.41251\n",
      "[TRAIN] Epoch: 5, Iter: 400, Loss: 4.35064\n",
      "[TRAIN] Epoch: 5, Iter: 410, Loss: 4.14501\n",
      "[TRAIN] Epoch: 5, Iter: 420, Loss: 4.20295\n",
      "[TRAIN] Epoch: 5, Iter: 430, Loss: 4.07626\n",
      "[TRAIN] Epoch: 5, Iter: 440, Loss: 4.44517\n",
      "[TRAIN] Epoch: 5, Iter: 450, Loss: 4.41573\n",
      "[TRAIN] Epoch: 5, Iter: 460, Loss: 4.28294\n",
      "[TRAIN] Epoch: 5, Iter: 470, Loss: 4.23762\n",
      "[TRAIN] Epoch: 5, Iter: 480, Loss: 4.57286\n",
      "[TRAIN] Epoch: 5, Iter: 490, Loss: 4.28980\n",
      "[TRAIN] Epoch: 5, Iter: 500, Loss: 4.18241\n",
      "[TRAIN] Epoch: 5, Iter: 510, Loss: 4.13809\n",
      "[TRAIN] Epoch: 5, Iter: 520, Loss: 4.18911\n",
      "[TRAIN] Epoch: 5, Iter: 530, Loss: 4.07259\n",
      "[TRAIN] Epoch: 5, Iter: 540, Loss: 4.40731\n",
      "[TRAIN] Epoch: 5, Iter: 550, Loss: 4.33334\n",
      "[TRAIN] Epoch: 5, Iter: 560, Loss: 4.40086\n",
      "[TRAIN] Epoch: 5, Iter: 570, Loss: 4.49303\n",
      "== [TRAIN] Epoch: 5, Perplexity: 69.748 ==>\n",
      "Before scheduler loss is: 4.24488851337325\n",
      "[VAL] Epoch: 5, Iter: 0, Loss: 4.75523\n",
      "[VAL] Epoch: 5, Iter: 10, Loss: 5.04846\n",
      "[VAL] Epoch: 5, Iter: 20, Loss: 5.19498\n",
      "[VAL] Epoch: 5, Iter: 30, Loss: 5.20551\n",
      "[VAL] Epoch: 5, Iter: 40, Loss: 4.93825\n",
      "[VAL] Epoch: 5, Iter: 50, Loss: 4.75933\n",
      "=== [VAL] Epoch: 5, Iter: 59, Perplexity: 147.626 ===>\n",
      "====== Epoch 6 ======>\n",
      "[TRAIN] Epoch: 6, Iter: 0, Loss: 3.88328\n",
      "[TRAIN] Epoch: 6, Iter: 10, Loss: 3.96074\n",
      "[TRAIN] Epoch: 6, Iter: 20, Loss: 4.26462\n",
      "[TRAIN] Epoch: 6, Iter: 30, Loss: 3.95384\n",
      "[TRAIN] Epoch: 6, Iter: 40, Loss: 3.96050\n",
      "[TRAIN] Epoch: 6, Iter: 50, Loss: 4.13528\n",
      "[TRAIN] Epoch: 6, Iter: 60, Loss: 3.94956\n",
      "[TRAIN] Epoch: 6, Iter: 70, Loss: 3.92456\n",
      "[TRAIN] Epoch: 6, Iter: 80, Loss: 3.71060\n",
      "[TRAIN] Epoch: 6, Iter: 90, Loss: 4.00204\n",
      "[TRAIN] Epoch: 6, Iter: 100, Loss: 3.78641\n",
      "[TRAIN] Epoch: 6, Iter: 110, Loss: 4.20440\n",
      "[TRAIN] Epoch: 6, Iter: 120, Loss: 4.16113\n",
      "[TRAIN] Epoch: 6, Iter: 130, Loss: 4.07810\n",
      "[TRAIN] Epoch: 6, Iter: 140, Loss: 3.95658\n",
      "[TRAIN] Epoch: 6, Iter: 150, Loss: 4.20421\n",
      "[TRAIN] Epoch: 6, Iter: 160, Loss: 4.14744\n",
      "[TRAIN] Epoch: 6, Iter: 170, Loss: 4.02817\n",
      "[TRAIN] Epoch: 6, Iter: 180, Loss: 4.09212\n",
      "[TRAIN] Epoch: 6, Iter: 190, Loss: 4.06845\n",
      "[TRAIN] Epoch: 6, Iter: 200, Loss: 4.23024\n",
      "[TRAIN] Epoch: 6, Iter: 210, Loss: 3.98525\n",
      "[TRAIN] Epoch: 6, Iter: 220, Loss: 3.95453\n",
      "[TRAIN] Epoch: 6, Iter: 230, Loss: 3.96796\n",
      "[TRAIN] Epoch: 6, Iter: 240, Loss: 4.05041\n",
      "[TRAIN] Epoch: 6, Iter: 250, Loss: 4.12105\n",
      "[TRAIN] Epoch: 6, Iter: 260, Loss: 4.16786\n",
      "[TRAIN] Epoch: 6, Iter: 270, Loss: 4.24792\n",
      "[TRAIN] Epoch: 6, Iter: 280, Loss: 4.18578\n",
      "[TRAIN] Epoch: 6, Iter: 290, Loss: 4.10470\n",
      "[TRAIN] Epoch: 6, Iter: 300, Loss: 4.16395\n",
      "[TRAIN] Epoch: 6, Iter: 310, Loss: 4.07728\n",
      "[TRAIN] Epoch: 6, Iter: 320, Loss: 4.02819\n",
      "[TRAIN] Epoch: 6, Iter: 330, Loss: 4.00357\n",
      "[TRAIN] Epoch: 6, Iter: 340, Loss: 4.20872\n",
      "[TRAIN] Epoch: 6, Iter: 350, Loss: 4.23704\n",
      "[TRAIN] Epoch: 6, Iter: 360, Loss: 3.93996\n",
      "[TRAIN] Epoch: 6, Iter: 370, Loss: 4.08934\n",
      "[TRAIN] Epoch: 6, Iter: 380, Loss: 4.16164\n",
      "[TRAIN] Epoch: 6, Iter: 390, Loss: 4.04071\n",
      "[TRAIN] Epoch: 6, Iter: 400, Loss: 4.34467\n",
      "[TRAIN] Epoch: 6, Iter: 410, Loss: 4.10692\n",
      "[TRAIN] Epoch: 6, Iter: 420, Loss: 4.16256\n",
      "[TRAIN] Epoch: 6, Iter: 430, Loss: 4.19569\n",
      "[TRAIN] Epoch: 6, Iter: 440, Loss: 4.18133\n",
      "[TRAIN] Epoch: 6, Iter: 450, Loss: 4.17943\n",
      "[TRAIN] Epoch: 6, Iter: 460, Loss: 4.21153\n",
      "[TRAIN] Epoch: 6, Iter: 470, Loss: 4.03355\n",
      "[TRAIN] Epoch: 6, Iter: 480, Loss: 4.31343\n",
      "[TRAIN] Epoch: 6, Iter: 490, Loss: 4.18223\n",
      "[TRAIN] Epoch: 6, Iter: 500, Loss: 4.07663\n",
      "[TRAIN] Epoch: 6, Iter: 510, Loss: 4.20761\n",
      "[TRAIN] Epoch: 6, Iter: 520, Loss: 3.80793\n",
      "[TRAIN] Epoch: 6, Iter: 530, Loss: 4.02393\n",
      "[TRAIN] Epoch: 6, Iter: 540, Loss: 4.23720\n",
      "[TRAIN] Epoch: 6, Iter: 550, Loss: 4.11869\n",
      "[TRAIN] Epoch: 6, Iter: 560, Loss: 4.30629\n",
      "[TRAIN] Epoch: 6, Iter: 570, Loss: 4.05967\n",
      "== [TRAIN] Epoch: 6, Perplexity: 59.402 ==>\n",
      "Before scheduler loss is: 4.08433040700038\n",
      "[VAL] Epoch: 6, Iter: 0, Loss: 4.78017\n",
      "[VAL] Epoch: 6, Iter: 10, Loss: 5.05470\n",
      "[VAL] Epoch: 6, Iter: 20, Loss: 5.22207\n",
      "[VAL] Epoch: 6, Iter: 30, Loss: 5.25937\n",
      "[VAL] Epoch: 6, Iter: 40, Loss: 4.95667\n",
      "[VAL] Epoch: 6, Iter: 50, Loss: 4.75381\n",
      "=== [VAL] Epoch: 6, Iter: 59, Perplexity: 150.251 ===>\n",
      "====== Epoch 7 ======>\n",
      "[TRAIN] Epoch: 7, Iter: 0, Loss: 3.65584\n",
      "[TRAIN] Epoch: 7, Iter: 10, Loss: 3.87841\n",
      "[TRAIN] Epoch: 7, Iter: 20, Loss: 3.76743\n",
      "[TRAIN] Epoch: 7, Iter: 30, Loss: 3.97370\n",
      "[TRAIN] Epoch: 7, Iter: 40, Loss: 3.88719\n",
      "[TRAIN] Epoch: 7, Iter: 50, Loss: 3.82482\n",
      "[TRAIN] Epoch: 7, Iter: 60, Loss: 4.02337\n",
      "[TRAIN] Epoch: 7, Iter: 70, Loss: 3.98814\n",
      "[TRAIN] Epoch: 7, Iter: 80, Loss: 3.80859\n",
      "[TRAIN] Epoch: 7, Iter: 90, Loss: 3.84441\n",
      "[TRAIN] Epoch: 7, Iter: 100, Loss: 3.86951\n",
      "[TRAIN] Epoch: 7, Iter: 110, Loss: 3.75351\n",
      "[TRAIN] Epoch: 7, Iter: 120, Loss: 3.98476\n",
      "[TRAIN] Epoch: 7, Iter: 130, Loss: 4.02518\n",
      "[TRAIN] Epoch: 7, Iter: 140, Loss: 3.98849\n",
      "[TRAIN] Epoch: 7, Iter: 150, Loss: 3.89760\n",
      "[TRAIN] Epoch: 7, Iter: 160, Loss: 3.78809\n",
      "[TRAIN] Epoch: 7, Iter: 170, Loss: 4.08731\n",
      "[TRAIN] Epoch: 7, Iter: 180, Loss: 3.87722\n",
      "[TRAIN] Epoch: 7, Iter: 190, Loss: 3.89822\n",
      "[TRAIN] Epoch: 7, Iter: 200, Loss: 3.76543\n",
      "[TRAIN] Epoch: 7, Iter: 210, Loss: 3.87623\n",
      "[TRAIN] Epoch: 7, Iter: 220, Loss: 3.95650\n",
      "[TRAIN] Epoch: 7, Iter: 230, Loss: 3.87802\n",
      "[TRAIN] Epoch: 7, Iter: 240, Loss: 4.04650\n",
      "[TRAIN] Epoch: 7, Iter: 250, Loss: 3.88375\n",
      "[TRAIN] Epoch: 7, Iter: 260, Loss: 4.13601\n",
      "[TRAIN] Epoch: 7, Iter: 270, Loss: 3.97683\n",
      "[TRAIN] Epoch: 7, Iter: 280, Loss: 3.93891\n",
      "[TRAIN] Epoch: 7, Iter: 290, Loss: 4.01871\n",
      "[TRAIN] Epoch: 7, Iter: 300, Loss: 4.00579\n",
      "[TRAIN] Epoch: 7, Iter: 310, Loss: 3.90727\n",
      "[TRAIN] Epoch: 7, Iter: 320, Loss: 4.02421\n",
      "[TRAIN] Epoch: 7, Iter: 330, Loss: 4.00941\n",
      "[TRAIN] Epoch: 7, Iter: 340, Loss: 3.77082\n",
      "[TRAIN] Epoch: 7, Iter: 350, Loss: 3.93449\n",
      "[TRAIN] Epoch: 7, Iter: 360, Loss: 3.98558\n",
      "[TRAIN] Epoch: 7, Iter: 370, Loss: 3.93820\n",
      "[TRAIN] Epoch: 7, Iter: 380, Loss: 3.94717\n",
      "[TRAIN] Epoch: 7, Iter: 390, Loss: 4.07234\n",
      "[TRAIN] Epoch: 7, Iter: 400, Loss: 3.94330\n",
      "[TRAIN] Epoch: 7, Iter: 410, Loss: 4.02748\n",
      "[TRAIN] Epoch: 7, Iter: 420, Loss: 3.88050\n",
      "[TRAIN] Epoch: 7, Iter: 430, Loss: 4.00642\n",
      "[TRAIN] Epoch: 7, Iter: 440, Loss: 3.96327\n",
      "[TRAIN] Epoch: 7, Iter: 450, Loss: 3.98005\n",
      "[TRAIN] Epoch: 7, Iter: 460, Loss: 3.90009\n",
      "[TRAIN] Epoch: 7, Iter: 470, Loss: 4.08314\n",
      "[TRAIN] Epoch: 7, Iter: 480, Loss: 4.11223\n",
      "[TRAIN] Epoch: 7, Iter: 490, Loss: 3.89404\n",
      "[TRAIN] Epoch: 7, Iter: 500, Loss: 3.99392\n",
      "[TRAIN] Epoch: 7, Iter: 510, Loss: 3.98502\n",
      "[TRAIN] Epoch: 7, Iter: 520, Loss: 3.99259\n",
      "[TRAIN] Epoch: 7, Iter: 530, Loss: 4.00967\n",
      "[TRAIN] Epoch: 7, Iter: 540, Loss: 4.06415\n",
      "[TRAIN] Epoch: 7, Iter: 550, Loss: 4.10791\n",
      "[TRAIN] Epoch: 7, Iter: 560, Loss: 4.08929\n",
      "[TRAIN] Epoch: 7, Iter: 570, Loss: 3.99869\n",
      "== [TRAIN] Epoch: 7, Perplexity: 51.351 ==>\n",
      "Before scheduler loss is: 3.9386812126601094\n",
      "[VAL] Epoch: 7, Iter: 0, Loss: 4.77371\n",
      "[VAL] Epoch: 7, Iter: 10, Loss: 5.10716\n",
      "[VAL] Epoch: 7, Iter: 20, Loss: 5.26794\n",
      "[VAL] Epoch: 7, Iter: 30, Loss: 5.36997\n",
      "[VAL] Epoch: 7, Iter: 40, Loss: 4.99856\n",
      "[VAL] Epoch: 7, Iter: 50, Loss: 4.76164\n",
      "=== [VAL] Epoch: 7, Iter: 59, Perplexity: 157.386 ===>\n",
      "====== Epoch 8 ======>\n",
      "[TRAIN] Epoch: 8, Iter: 0, Loss: 3.84856\n",
      "[TRAIN] Epoch: 8, Iter: 10, Loss: 3.66365\n",
      "[TRAIN] Epoch: 8, Iter: 20, Loss: 3.67869\n",
      "[TRAIN] Epoch: 8, Iter: 30, Loss: 3.53072\n",
      "[TRAIN] Epoch: 8, Iter: 40, Loss: 3.60926\n",
      "[TRAIN] Epoch: 8, Iter: 50, Loss: 3.76834\n",
      "[TRAIN] Epoch: 8, Iter: 60, Loss: 3.60337\n",
      "[TRAIN] Epoch: 8, Iter: 70, Loss: 3.86582\n",
      "[TRAIN] Epoch: 8, Iter: 80, Loss: 3.85359\n",
      "[TRAIN] Epoch: 8, Iter: 90, Loss: 3.86503\n",
      "[TRAIN] Epoch: 8, Iter: 100, Loss: 3.51161\n",
      "[TRAIN] Epoch: 8, Iter: 110, Loss: 3.67797\n",
      "[TRAIN] Epoch: 8, Iter: 120, Loss: 3.82125\n",
      "[TRAIN] Epoch: 8, Iter: 130, Loss: 3.60178\n",
      "[TRAIN] Epoch: 8, Iter: 140, Loss: 3.77722\n",
      "[TRAIN] Epoch: 8, Iter: 150, Loss: 3.86148\n",
      "[TRAIN] Epoch: 8, Iter: 160, Loss: 3.79653\n",
      "[TRAIN] Epoch: 8, Iter: 170, Loss: 3.76698\n",
      "[TRAIN] Epoch: 8, Iter: 180, Loss: 3.85639\n",
      "[TRAIN] Epoch: 8, Iter: 190, Loss: 3.73228\n",
      "[TRAIN] Epoch: 8, Iter: 200, Loss: 3.73262\n",
      "[TRAIN] Epoch: 8, Iter: 210, Loss: 4.01239\n",
      "[TRAIN] Epoch: 8, Iter: 220, Loss: 3.88437\n",
      "[TRAIN] Epoch: 8, Iter: 230, Loss: 3.60564\n",
      "[TRAIN] Epoch: 8, Iter: 240, Loss: 3.69463\n",
      "[TRAIN] Epoch: 8, Iter: 250, Loss: 3.91902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch: 8, Iter: 260, Loss: 3.84803\n",
      "[TRAIN] Epoch: 8, Iter: 270, Loss: 4.10501\n",
      "[TRAIN] Epoch: 8, Iter: 280, Loss: 3.93836\n",
      "[TRAIN] Epoch: 8, Iter: 290, Loss: 3.88387\n",
      "[TRAIN] Epoch: 8, Iter: 300, Loss: 3.41988\n",
      "[TRAIN] Epoch: 8, Iter: 310, Loss: 3.77794\n",
      "[TRAIN] Epoch: 8, Iter: 320, Loss: 3.96793\n",
      "[TRAIN] Epoch: 8, Iter: 330, Loss: 4.02576\n",
      "[TRAIN] Epoch: 8, Iter: 340, Loss: 3.75260\n",
      "[TRAIN] Epoch: 8, Iter: 350, Loss: 3.72587\n",
      "[TRAIN] Epoch: 8, Iter: 360, Loss: 3.92819\n",
      "[TRAIN] Epoch: 8, Iter: 370, Loss: 3.75709\n",
      "[TRAIN] Epoch: 8, Iter: 380, Loss: 3.87826\n",
      "[TRAIN] Epoch: 8, Iter: 390, Loss: 3.78302\n",
      "[TRAIN] Epoch: 8, Iter: 400, Loss: 3.75932\n",
      "[TRAIN] Epoch: 8, Iter: 410, Loss: 3.76144\n",
      "[TRAIN] Epoch: 8, Iter: 420, Loss: 3.93945\n",
      "[TRAIN] Epoch: 8, Iter: 430, Loss: 4.01685\n",
      "[TRAIN] Epoch: 8, Iter: 440, Loss: 4.08608\n",
      "[TRAIN] Epoch: 8, Iter: 450, Loss: 3.91574\n",
      "[TRAIN] Epoch: 8, Iter: 460, Loss: 3.97182\n",
      "[TRAIN] Epoch: 8, Iter: 470, Loss: 3.59409\n",
      "[TRAIN] Epoch: 8, Iter: 480, Loss: 3.90689\n",
      "[TRAIN] Epoch: 8, Iter: 490, Loss: 3.93640\n",
      "[TRAIN] Epoch: 8, Iter: 500, Loss: 3.91878\n",
      "[TRAIN] Epoch: 8, Iter: 510, Loss: 4.03950\n",
      "[TRAIN] Epoch: 8, Iter: 520, Loss: 4.18865\n",
      "[TRAIN] Epoch: 8, Iter: 530, Loss: 3.78697\n",
      "[TRAIN] Epoch: 8, Iter: 540, Loss: 4.08470\n",
      "[TRAIN] Epoch: 8, Iter: 550, Loss: 3.84604\n",
      "[TRAIN] Epoch: 8, Iter: 560, Loss: 3.77048\n",
      "[TRAIN] Epoch: 8, Iter: 570, Loss: 3.78090\n",
      "== [TRAIN] Epoch: 8, Perplexity: 45.020 ==>\n",
      "Before scheduler loss is: 3.8071120692168026\n",
      "[VAL] Epoch: 8, Iter: 0, Loss: 4.82598\n",
      "[VAL] Epoch: 8, Iter: 10, Loss: 5.11901\n",
      "[VAL] Epoch: 8, Iter: 20, Loss: 5.36648\n",
      "[VAL] Epoch: 8, Iter: 30, Loss: 5.38095\n",
      "[VAL] Epoch: 8, Iter: 40, Loss: 5.03178\n",
      "[VAL] Epoch: 8, Iter: 50, Loss: 4.81572\n",
      "=== [VAL] Epoch: 8, Iter: 59, Perplexity: 164.621 ===>\n",
      "====== Epoch 9 ======>\n",
      "[TRAIN] Epoch: 9, Iter: 0, Loss: 3.47354\n",
      "[TRAIN] Epoch: 9, Iter: 10, Loss: 3.56088\n",
      "[TRAIN] Epoch: 9, Iter: 20, Loss: 3.57781\n",
      "[TRAIN] Epoch: 9, Iter: 30, Loss: 3.51715\n",
      "[TRAIN] Epoch: 9, Iter: 40, Loss: 3.36950\n",
      "[TRAIN] Epoch: 9, Iter: 50, Loss: 3.49563\n",
      "[TRAIN] Epoch: 9, Iter: 60, Loss: 3.68476\n",
      "[TRAIN] Epoch: 9, Iter: 70, Loss: 3.36927\n",
      "[TRAIN] Epoch: 9, Iter: 80, Loss: 3.52315\n",
      "[TRAIN] Epoch: 9, Iter: 90, Loss: 3.48726\n",
      "[TRAIN] Epoch: 9, Iter: 100, Loss: 3.56285\n",
      "[TRAIN] Epoch: 9, Iter: 110, Loss: 3.44037\n",
      "[TRAIN] Epoch: 9, Iter: 120, Loss: 3.64931\n",
      "[TRAIN] Epoch: 9, Iter: 130, Loss: 3.61801\n",
      "[TRAIN] Epoch: 9, Iter: 140, Loss: 3.65098\n",
      "[TRAIN] Epoch: 9, Iter: 150, Loss: 3.57719\n",
      "[TRAIN] Epoch: 9, Iter: 160, Loss: 3.69507\n",
      "[TRAIN] Epoch: 9, Iter: 170, Loss: 3.77317\n",
      "[TRAIN] Epoch: 9, Iter: 180, Loss: 3.71020\n",
      "[TRAIN] Epoch: 9, Iter: 190, Loss: 3.89028\n",
      "[TRAIN] Epoch: 9, Iter: 200, Loss: 3.71848\n",
      "[TRAIN] Epoch: 9, Iter: 210, Loss: 3.60942\n",
      "[TRAIN] Epoch: 9, Iter: 220, Loss: 3.56277\n",
      "[TRAIN] Epoch: 9, Iter: 230, Loss: 3.66326\n",
      "[TRAIN] Epoch: 9, Iter: 240, Loss: 3.45992\n",
      "[TRAIN] Epoch: 9, Iter: 250, Loss: 3.67669\n",
      "[TRAIN] Epoch: 9, Iter: 260, Loss: 3.60411\n",
      "[TRAIN] Epoch: 9, Iter: 270, Loss: 3.67837\n",
      "[TRAIN] Epoch: 9, Iter: 280, Loss: 3.83519\n",
      "[TRAIN] Epoch: 9, Iter: 290, Loss: 3.60605\n",
      "[TRAIN] Epoch: 9, Iter: 300, Loss: 3.54924\n",
      "[TRAIN] Epoch: 9, Iter: 310, Loss: 3.82114\n",
      "[TRAIN] Epoch: 9, Iter: 320, Loss: 3.61797\n",
      "[TRAIN] Epoch: 9, Iter: 330, Loss: 3.72730\n",
      "[TRAIN] Epoch: 9, Iter: 340, Loss: 3.82812\n",
      "[TRAIN] Epoch: 9, Iter: 350, Loss: 3.79242\n",
      "[TRAIN] Epoch: 9, Iter: 360, Loss: 3.60270\n",
      "[TRAIN] Epoch: 9, Iter: 370, Loss: 3.70080\n",
      "[TRAIN] Epoch: 9, Iter: 380, Loss: 3.68438\n",
      "[TRAIN] Epoch: 9, Iter: 390, Loss: 3.71954\n",
      "[TRAIN] Epoch: 9, Iter: 400, Loss: 3.74170\n",
      "[TRAIN] Epoch: 9, Iter: 410, Loss: 3.70781\n",
      "[TRAIN] Epoch: 9, Iter: 420, Loss: 3.93133\n",
      "[TRAIN] Epoch: 9, Iter: 430, Loss: 3.69193\n",
      "[TRAIN] Epoch: 9, Iter: 440, Loss: 3.78778\n",
      "[TRAIN] Epoch: 9, Iter: 450, Loss: 3.73638\n",
      "[TRAIN] Epoch: 9, Iter: 460, Loss: 3.68017\n",
      "[TRAIN] Epoch: 9, Iter: 470, Loss: 3.81056\n",
      "[TRAIN] Epoch: 9, Iter: 480, Loss: 3.73219\n",
      "[TRAIN] Epoch: 9, Iter: 490, Loss: 3.74862\n",
      "[TRAIN] Epoch: 9, Iter: 500, Loss: 3.94827\n",
      "[TRAIN] Epoch: 9, Iter: 510, Loss: 3.62836\n",
      "[TRAIN] Epoch: 9, Iter: 520, Loss: 3.91542\n",
      "[TRAIN] Epoch: 9, Iter: 530, Loss: 3.88632\n",
      "[TRAIN] Epoch: 9, Iter: 540, Loss: 3.75409\n",
      "[TRAIN] Epoch: 9, Iter: 550, Loss: 3.95922\n",
      "[TRAIN] Epoch: 9, Iter: 560, Loss: 3.92255\n",
      "[TRAIN] Epoch: 9, Iter: 570, Loss: 4.04132\n",
      "== [TRAIN] Epoch: 9, Perplexity: 39.892 ==>\n",
      "Before scheduler loss is: 3.686170181627353\n",
      "[VAL] Epoch: 9, Iter: 0, Loss: 4.87152\n",
      "[VAL] Epoch: 9, Iter: 10, Loss: 5.18167\n",
      "[VAL] Epoch: 9, Iter: 20, Loss: 5.41628\n",
      "[VAL] Epoch: 9, Iter: 30, Loss: 5.50203\n",
      "[VAL] Epoch: 9, Iter: 40, Loss: 5.08788\n",
      "[VAL] Epoch: 9, Iter: 50, Loss: 4.84422\n",
      "=== [VAL] Epoch: 9, Iter: 59, Perplexity: 176.825 ===>\n",
      "[TEST] Epoch: 9, Iter: 0, Loss: 5.32966\n",
      "[TEST] Epoch: 9, Iter: 10, Loss: 5.13401\n",
      "[TEST] Epoch: 9, Iter: 20, Loss: 5.64205\n",
      "[TEST] Epoch: 9, Iter: 30, Loss: 5.35577\n",
      "[TEST] Epoch: 9, Iter: 40, Loss: 5.24610\n",
      "[TEST] Epoch: 9, Iter: 50, Loss: 5.36921\n",
      "[TEST] Epoch: 9, Iter: 60, Loss: 5.04679\n",
      "=== [TEST] Epoch: 9, Iter: 68, Perplexity: 179.890 ===>\n",
      "===== Best validation perplexity: 145.700 =====>\n"
     ]
    }
   ],
   "source": [
    "!python run_exp.py --model='gpt1' --layers=1 --batch_size=16 --epochs=10 --optimizer='adamw' --exp_id='debug' --seed=1023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized GPT1 model with 38372352 total parameters, of which 7087872 are learnable.args are: Namespace(batch_size=16, data_folder='./data', device='cuda', embeddings='./data/embeddings.npz', epochs=10, exp_id='14', layers=1, log=False, log_dir='logs', lr=0.001, model='gpt1', momentum=0.9, num_workers=2, optimizer='adamw', print_every=10, progress_bar=False, seed=1023, weight_decay=0.0005)\n",
      "====== Epoch 0 ======>\n",
      "[TRAIN] Epoch: 0, Iter: 0, Loss: 46.82186\n",
      "[TRAIN] Epoch: 0, Iter: 10, Loss: 8.78794\n",
      "[TRAIN] Epoch: 0, Iter: 20, Loss: 8.34682\n",
      "[TRAIN] Epoch: 0, Iter: 30, Loss: 8.05178\n",
      "[TRAIN] Epoch: 0, Iter: 40, Loss: 7.87844\n",
      "[TRAIN] Epoch: 0, Iter: 50, Loss: 7.76828\n",
      "[TRAIN] Epoch: 0, Iter: 60, Loss: 7.75323\n",
      "[TRAIN] Epoch: 0, Iter: 70, Loss: 7.56756\n",
      "[TRAIN] Epoch: 0, Iter: 80, Loss: 7.78600\n",
      "[TRAIN] Epoch: 0, Iter: 90, Loss: 7.54513\n",
      "[TRAIN] Epoch: 0, Iter: 100, Loss: 7.61290\n",
      "[TRAIN] Epoch: 0, Iter: 110, Loss: 7.33569\n",
      "[TRAIN] Epoch: 0, Iter: 120, Loss: 7.25536\n",
      "[TRAIN] Epoch: 0, Iter: 130, Loss: 7.24319\n",
      "[TRAIN] Epoch: 0, Iter: 140, Loss: 7.06206\n",
      "[TRAIN] Epoch: 0, Iter: 150, Loss: 7.21514\n",
      "[TRAIN] Epoch: 0, Iter: 160, Loss: 6.93330\n",
      "[TRAIN] Epoch: 0, Iter: 170, Loss: 6.64881\n",
      "[TRAIN] Epoch: 0, Iter: 180, Loss: 6.71370\n",
      "[TRAIN] Epoch: 0, Iter: 190, Loss: 6.62701\n",
      "[TRAIN] Epoch: 0, Iter: 200, Loss: 6.54863\n",
      "[TRAIN] Epoch: 0, Iter: 210, Loss: 6.70941\n",
      "[TRAIN] Epoch: 0, Iter: 220, Loss: 6.52972\n",
      "[TRAIN] Epoch: 0, Iter: 230, Loss: 6.61636\n",
      "[TRAIN] Epoch: 0, Iter: 240, Loss: 6.37059\n",
      "[TRAIN] Epoch: 0, Iter: 250, Loss: 6.44946\n",
      "[TRAIN] Epoch: 0, Iter: 260, Loss: 6.38830\n",
      "[TRAIN] Epoch: 0, Iter: 270, Loss: 6.38882\n",
      "[TRAIN] Epoch: 0, Iter: 280, Loss: 6.31153\n",
      "[TRAIN] Epoch: 0, Iter: 290, Loss: 6.36443\n",
      "[TRAIN] Epoch: 0, Iter: 300, Loss: 6.26532\n",
      "[TRAIN] Epoch: 0, Iter: 310, Loss: 6.18342\n",
      "[TRAIN] Epoch: 0, Iter: 320, Loss: 6.23982\n",
      "[TRAIN] Epoch: 0, Iter: 330, Loss: 6.23908\n",
      "[TRAIN] Epoch: 0, Iter: 340, Loss: 6.19217\n",
      "[TRAIN] Epoch: 0, Iter: 350, Loss: 6.27170\n",
      "[TRAIN] Epoch: 0, Iter: 360, Loss: 6.10968\n",
      "[TRAIN] Epoch: 0, Iter: 370, Loss: 6.17785\n",
      "[TRAIN] Epoch: 0, Iter: 380, Loss: 6.08554\n",
      "[TRAIN] Epoch: 0, Iter: 390, Loss: 6.19931\n",
      "[TRAIN] Epoch: 0, Iter: 400, Loss: 5.98812\n",
      "[TRAIN] Epoch: 0, Iter: 410, Loss: 6.02644\n",
      "[TRAIN] Epoch: 0, Iter: 420, Loss: 6.07836\n",
      "[TRAIN] Epoch: 0, Iter: 430, Loss: 6.13077\n",
      "[TRAIN] Epoch: 0, Iter: 440, Loss: 6.07543\n",
      "[TRAIN] Epoch: 0, Iter: 450, Loss: 5.95756\n",
      "[TRAIN] Epoch: 0, Iter: 460, Loss: 6.07755\n",
      "[TRAIN] Epoch: 0, Iter: 470, Loss: 5.86869\n",
      "[TRAIN] Epoch: 0, Iter: 480, Loss: 5.99230\n",
      "[TRAIN] Epoch: 0, Iter: 490, Loss: 5.91248\n",
      "[TRAIN] Epoch: 0, Iter: 500, Loss: 6.01126\n",
      "[TRAIN] Epoch: 0, Iter: 510, Loss: 5.83385\n",
      "[TRAIN] Epoch: 0, Iter: 520, Loss: 5.76757\n",
      "[TRAIN] Epoch: 0, Iter: 530, Loss: 5.84863\n",
      "[TRAIN] Epoch: 0, Iter: 540, Loss: 5.73761\n",
      "[TRAIN] Epoch: 0, Iter: 550, Loss: 5.99111\n",
      "[TRAIN] Epoch: 0, Iter: 560, Loss: 5.90046\n",
      "[TRAIN] Epoch: 0, Iter: 570, Loss: 5.98504\n",
      "== [TRAIN] Epoch: 0, Perplexity: 849.466 ==>\n",
      "Before scheduler loss is: 6.7446078071124145\n",
      "[VAL] Epoch: 0, Iter: 0, Loss: 5.87334\n",
      "[VAL] Epoch: 0, Iter: 10, Loss: 5.89646\n",
      "[VAL] Epoch: 0, Iter: 20, Loss: 6.01139\n",
      "[VAL] Epoch: 0, Iter: 30, Loss: 5.93930\n",
      "[VAL] Epoch: 0, Iter: 40, Loss: 5.79664\n",
      "[VAL] Epoch: 0, Iter: 50, Loss: 5.65094\n",
      "=== [VAL] Epoch: 0, Iter: 59, Perplexity: 337.860 ===>\n",
      "====== Epoch 1 ======>\n",
      "[TRAIN] Epoch: 1, Iter: 0, Loss: 5.79334\n",
      "[TRAIN] Epoch: 1, Iter: 10, Loss: 5.79375\n",
      "[TRAIN] Epoch: 1, Iter: 20, Loss: 5.71797\n",
      "[TRAIN] Epoch: 1, Iter: 30, Loss: 5.60255\n",
      "[TRAIN] Epoch: 1, Iter: 40, Loss: 5.90785\n",
      "[TRAIN] Epoch: 1, Iter: 50, Loss: 5.61587\n",
      "[TRAIN] Epoch: 1, Iter: 60, Loss: 5.78202\n",
      "[TRAIN] Epoch: 1, Iter: 70, Loss: 5.72439\n",
      "[TRAIN] Epoch: 1, Iter: 80, Loss: 5.82229\n",
      "[TRAIN] Epoch: 1, Iter: 90, Loss: 5.54153\n",
      "[TRAIN] Epoch: 1, Iter: 100, Loss: 5.42161\n",
      "[TRAIN] Epoch: 1, Iter: 110, Loss: 5.57354\n",
      "[TRAIN] Epoch: 1, Iter: 120, Loss: 5.66494\n",
      "[TRAIN] Epoch: 1, Iter: 130, Loss: 5.41869\n",
      "[TRAIN] Epoch: 1, Iter: 140, Loss: 5.56310\n",
      "[TRAIN] Epoch: 1, Iter: 150, Loss: 5.64287\n",
      "[TRAIN] Epoch: 1, Iter: 160, Loss: 5.67595\n",
      "[TRAIN] Epoch: 1, Iter: 170, Loss: 5.40392\n",
      "[TRAIN] Epoch: 1, Iter: 180, Loss: 5.36493\n",
      "[TRAIN] Epoch: 1, Iter: 190, Loss: 5.47565\n",
      "[TRAIN] Epoch: 1, Iter: 200, Loss: 5.56161\n",
      "[TRAIN] Epoch: 1, Iter: 210, Loss: 5.37687\n",
      "[TRAIN] Epoch: 1, Iter: 220, Loss: 5.54720\n",
      "[TRAIN] Epoch: 1, Iter: 230, Loss: 5.43295\n",
      "[TRAIN] Epoch: 1, Iter: 240, Loss: 5.44590\n",
      "[TRAIN] Epoch: 1, Iter: 250, Loss: 5.38217\n",
      "[TRAIN] Epoch: 1, Iter: 260, Loss: 5.60837\n",
      "[TRAIN] Epoch: 1, Iter: 270, Loss: 5.31254\n",
      "[TRAIN] Epoch: 1, Iter: 280, Loss: 5.45549\n",
      "[TRAIN] Epoch: 1, Iter: 290, Loss: 5.47603\n",
      "[TRAIN] Epoch: 1, Iter: 300, Loss: 5.37613\n",
      "[TRAIN] Epoch: 1, Iter: 310, Loss: 5.44354\n",
      "[TRAIN] Epoch: 1, Iter: 320, Loss: 5.57619\n",
      "[TRAIN] Epoch: 1, Iter: 330, Loss: 5.59625\n",
      "[TRAIN] Epoch: 1, Iter: 340, Loss: 5.43914\n",
      "[TRAIN] Epoch: 1, Iter: 350, Loss: 5.42649\n",
      "[TRAIN] Epoch: 1, Iter: 360, Loss: 5.38653\n",
      "[TRAIN] Epoch: 1, Iter: 370, Loss: 5.27523\n",
      "[TRAIN] Epoch: 1, Iter: 380, Loss: 5.23371\n",
      "[TRAIN] Epoch: 1, Iter: 390, Loss: 5.33405\n",
      "[TRAIN] Epoch: 1, Iter: 400, Loss: 5.33131\n",
      "[TRAIN] Epoch: 1, Iter: 410, Loss: 5.34790\n",
      "[TRAIN] Epoch: 1, Iter: 420, Loss: 5.30135\n",
      "[TRAIN] Epoch: 1, Iter: 430, Loss: 5.45385\n",
      "[TRAIN] Epoch: 1, Iter: 440, Loss: 5.28167\n",
      "[TRAIN] Epoch: 1, Iter: 450, Loss: 5.34714\n",
      "[TRAIN] Epoch: 1, Iter: 460, Loss: 5.24180\n",
      "[TRAIN] Epoch: 1, Iter: 470, Loss: 5.26460\n",
      "[TRAIN] Epoch: 1, Iter: 480, Loss: 5.25216\n",
      "[TRAIN] Epoch: 1, Iter: 490, Loss: 5.27341\n",
      "[TRAIN] Epoch: 1, Iter: 500, Loss: 5.34917\n",
      "[TRAIN] Epoch: 1, Iter: 510, Loss: 5.04123\n",
      "[TRAIN] Epoch: 1, Iter: 520, Loss: 5.31728\n",
      "[TRAIN] Epoch: 1, Iter: 530, Loss: 5.11593\n",
      "[TRAIN] Epoch: 1, Iter: 540, Loss: 5.13989\n",
      "[TRAIN] Epoch: 1, Iter: 550, Loss: 5.09331\n",
      "[TRAIN] Epoch: 1, Iter: 560, Loss: 5.10976\n",
      "[TRAIN] Epoch: 1, Iter: 570, Loss: 5.10196\n",
      "== [TRAIN] Epoch: 1, Perplexity: 229.944 ==>\n",
      "Before scheduler loss is: 5.437837164448865\n",
      "[VAL] Epoch: 1, Iter: 0, Loss: 5.27073\n",
      "[VAL] Epoch: 1, Iter: 10, Loss: 5.31924\n",
      "[VAL] Epoch: 1, Iter: 20, Loss: 5.50054\n",
      "[VAL] Epoch: 1, Iter: 30, Loss: 5.45657\n",
      "[VAL] Epoch: 1, Iter: 40, Loss: 5.24608\n",
      "[VAL] Epoch: 1, Iter: 50, Loss: 5.17568\n",
      "=== [VAL] Epoch: 1, Iter: 59, Perplexity: 202.680 ===>\n",
      "====== Epoch 2 ======>\n",
      "[TRAIN] Epoch: 2, Iter: 0, Loss: 5.07825\n",
      "[TRAIN] Epoch: 2, Iter: 10, Loss: 5.03044\n",
      "[TRAIN] Epoch: 2, Iter: 20, Loss: 5.11752\n",
      "[TRAIN] Epoch: 2, Iter: 30, Loss: 5.09395\n",
      "[TRAIN] Epoch: 2, Iter: 40, Loss: 5.04159\n",
      "[TRAIN] Epoch: 2, Iter: 50, Loss: 4.95264\n",
      "[TRAIN] Epoch: 2, Iter: 60, Loss: 4.94723\n",
      "[TRAIN] Epoch: 2, Iter: 70, Loss: 4.88855\n",
      "[TRAIN] Epoch: 2, Iter: 80, Loss: 5.01500\n",
      "[TRAIN] Epoch: 2, Iter: 90, Loss: 5.06151\n",
      "[TRAIN] Epoch: 2, Iter: 100, Loss: 5.10354\n",
      "[TRAIN] Epoch: 2, Iter: 110, Loss: 5.04681\n",
      "[TRAIN] Epoch: 2, Iter: 120, Loss: 5.07910\n",
      "[TRAIN] Epoch: 2, Iter: 130, Loss: 4.93063\n",
      "[TRAIN] Epoch: 2, Iter: 140, Loss: 5.16090\n",
      "[TRAIN] Epoch: 2, Iter: 150, Loss: 4.97429\n",
      "[TRAIN] Epoch: 2, Iter: 160, Loss: 5.09518\n",
      "[TRAIN] Epoch: 2, Iter: 170, Loss: 5.12782\n",
      "[TRAIN] Epoch: 2, Iter: 180, Loss: 5.02111\n",
      "[TRAIN] Epoch: 2, Iter: 190, Loss: 4.94766\n",
      "[TRAIN] Epoch: 2, Iter: 200, Loss: 5.13520\n",
      "[TRAIN] Epoch: 2, Iter: 210, Loss: 5.05441\n",
      "[TRAIN] Epoch: 2, Iter: 220, Loss: 5.09229\n",
      "[TRAIN] Epoch: 2, Iter: 230, Loss: 4.83740\n",
      "[TRAIN] Epoch: 2, Iter: 240, Loss: 4.88343\n",
      "[TRAIN] Epoch: 2, Iter: 250, Loss: 5.08477\n",
      "[TRAIN] Epoch: 2, Iter: 260, Loss: 4.98680\n",
      "[TRAIN] Epoch: 2, Iter: 270, Loss: 4.90536\n",
      "[TRAIN] Epoch: 2, Iter: 280, Loss: 4.99689\n",
      "[TRAIN] Epoch: 2, Iter: 290, Loss: 4.89478\n",
      "[TRAIN] Epoch: 2, Iter: 300, Loss: 4.92551\n",
      "[TRAIN] Epoch: 2, Iter: 310, Loss: 4.91630\n",
      "[TRAIN] Epoch: 2, Iter: 320, Loss: 5.14917\n",
      "[TRAIN] Epoch: 2, Iter: 330, Loss: 4.84187\n",
      "[TRAIN] Epoch: 2, Iter: 340, Loss: 4.87858\n",
      "[TRAIN] Epoch: 2, Iter: 350, Loss: 4.92904\n",
      "[TRAIN] Epoch: 2, Iter: 360, Loss: 4.81221\n",
      "[TRAIN] Epoch: 2, Iter: 370, Loss: 5.10259\n",
      "[TRAIN] Epoch: 2, Iter: 380, Loss: 4.85946\n",
      "[TRAIN] Epoch: 2, Iter: 390, Loss: 5.11414\n",
      "[TRAIN] Epoch: 2, Iter: 400, Loss: 4.98878\n",
      "[TRAIN] Epoch: 2, Iter: 410, Loss: 4.80472\n",
      "[TRAIN] Epoch: 2, Iter: 420, Loss: 5.02487\n",
      "[TRAIN] Epoch: 2, Iter: 430, Loss: 4.75182\n",
      "[TRAIN] Epoch: 2, Iter: 440, Loss: 5.00405\n",
      "[TRAIN] Epoch: 2, Iter: 450, Loss: 5.03545\n",
      "[TRAIN] Epoch: 2, Iter: 460, Loss: 4.96495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch: 2, Iter: 470, Loss: 4.67787\n",
      "[TRAIN] Epoch: 2, Iter: 480, Loss: 4.86989\n",
      "[TRAIN] Epoch: 2, Iter: 490, Loss: 4.72952\n",
      "[TRAIN] Epoch: 2, Iter: 500, Loss: 4.88216\n",
      "[TRAIN] Epoch: 2, Iter: 510, Loss: 4.95346\n",
      "[TRAIN] Epoch: 2, Iter: 520, Loss: 4.97153\n",
      "[TRAIN] Epoch: 2, Iter: 530, Loss: 4.98050\n",
      "[TRAIN] Epoch: 2, Iter: 540, Loss: 4.76043\n",
      "[TRAIN] Epoch: 2, Iter: 550, Loss: 4.77585\n",
      "[TRAIN] Epoch: 2, Iter: 560, Loss: 4.96940\n",
      "[TRAIN] Epoch: 2, Iter: 570, Loss: 4.87598\n",
      "== [TRAIN] Epoch: 2, Perplexity: 141.035 ==>\n",
      "Before scheduler loss is: 4.949008449869224\n",
      "[VAL] Epoch: 2, Iter: 0, Loss: 5.01061\n",
      "[VAL] Epoch: 2, Iter: 10, Loss: 5.11378\n",
      "[VAL] Epoch: 2, Iter: 20, Loss: 5.25649\n",
      "[VAL] Epoch: 2, Iter: 30, Loss: 5.29789\n",
      "[VAL] Epoch: 2, Iter: 40, Loss: 5.04418\n",
      "[VAL] Epoch: 2, Iter: 50, Loss: 4.92253\n",
      "=== [VAL] Epoch: 2, Iter: 59, Perplexity: 163.483 ===>\n",
      "====== Epoch 3 ======>\n",
      "[TRAIN] Epoch: 3, Iter: 0, Loss: 4.70530\n",
      "[TRAIN] Epoch: 3, Iter: 10, Loss: 4.83419\n",
      "[TRAIN] Epoch: 3, Iter: 20, Loss: 4.78206\n",
      "[TRAIN] Epoch: 3, Iter: 30, Loss: 4.61156\n",
      "[TRAIN] Epoch: 3, Iter: 40, Loss: 4.66620\n",
      "[TRAIN] Epoch: 3, Iter: 50, Loss: 4.84098\n",
      "[TRAIN] Epoch: 3, Iter: 60, Loss: 4.48417\n",
      "[TRAIN] Epoch: 3, Iter: 70, Loss: 4.68841\n",
      "[TRAIN] Epoch: 3, Iter: 80, Loss: 4.83582\n",
      "[TRAIN] Epoch: 3, Iter: 90, Loss: 4.59215\n",
      "[TRAIN] Epoch: 3, Iter: 100, Loss: 4.71530\n",
      "[TRAIN] Epoch: 3, Iter: 110, Loss: 4.53742\n",
      "[TRAIN] Epoch: 3, Iter: 120, Loss: 4.78557\n",
      "[TRAIN] Epoch: 3, Iter: 130, Loss: 4.59795\n",
      "[TRAIN] Epoch: 3, Iter: 140, Loss: 4.52230\n",
      "[TRAIN] Epoch: 3, Iter: 150, Loss: 4.78400\n",
      "[TRAIN] Epoch: 3, Iter: 160, Loss: 4.68036\n",
      "[TRAIN] Epoch: 3, Iter: 170, Loss: 4.69660\n",
      "[TRAIN] Epoch: 3, Iter: 180, Loss: 4.70525\n",
      "[TRAIN] Epoch: 3, Iter: 190, Loss: 4.58177\n",
      "[TRAIN] Epoch: 3, Iter: 200, Loss: 4.61006\n",
      "[TRAIN] Epoch: 3, Iter: 210, Loss: 4.71638\n",
      "[TRAIN] Epoch: 3, Iter: 220, Loss: 4.52785\n",
      "[TRAIN] Epoch: 3, Iter: 230, Loss: 4.74863\n",
      "[TRAIN] Epoch: 3, Iter: 240, Loss: 4.78847\n",
      "[TRAIN] Epoch: 3, Iter: 250, Loss: 4.61246\n",
      "[TRAIN] Epoch: 3, Iter: 260, Loss: 4.80002\n",
      "[TRAIN] Epoch: 3, Iter: 270, Loss: 4.55502\n",
      "[TRAIN] Epoch: 3, Iter: 280, Loss: 4.59434\n",
      "[TRAIN] Epoch: 3, Iter: 290, Loss: 4.53351\n",
      "[TRAIN] Epoch: 3, Iter: 300, Loss: 4.71986\n",
      "[TRAIN] Epoch: 3, Iter: 310, Loss: 4.75130\n",
      "[TRAIN] Epoch: 3, Iter: 320, Loss: 4.60564\n",
      "[TRAIN] Epoch: 3, Iter: 330, Loss: 4.83782\n",
      "[TRAIN] Epoch: 3, Iter: 340, Loss: 4.72532\n",
      "[TRAIN] Epoch: 3, Iter: 350, Loss: 4.54273\n",
      "[TRAIN] Epoch: 3, Iter: 360, Loss: 4.69123\n",
      "[TRAIN] Epoch: 3, Iter: 370, Loss: 4.64605\n",
      "[TRAIN] Epoch: 3, Iter: 380, Loss: 4.67991\n",
      "[TRAIN] Epoch: 3, Iter: 390, Loss: 4.50588\n",
      "[TRAIN] Epoch: 3, Iter: 400, Loss: 4.71463\n",
      "[TRAIN] Epoch: 3, Iter: 410, Loss: 4.48830\n",
      "[TRAIN] Epoch: 3, Iter: 420, Loss: 4.64133\n",
      "[TRAIN] Epoch: 3, Iter: 430, Loss: 4.81181\n",
      "[TRAIN] Epoch: 3, Iter: 440, Loss: 4.65498\n",
      "[TRAIN] Epoch: 3, Iter: 450, Loss: 4.56106\n",
      "[TRAIN] Epoch: 3, Iter: 460, Loss: 4.63665\n",
      "[TRAIN] Epoch: 3, Iter: 470, Loss: 4.70084\n",
      "[TRAIN] Epoch: 3, Iter: 480, Loss: 4.55837\n",
      "[TRAIN] Epoch: 3, Iter: 490, Loss: 4.64235\n",
      "[TRAIN] Epoch: 3, Iter: 500, Loss: 4.54547\n",
      "[TRAIN] Epoch: 3, Iter: 510, Loss: 4.69316\n",
      "[TRAIN] Epoch: 3, Iter: 520, Loss: 4.72748\n",
      "[TRAIN] Epoch: 3, Iter: 530, Loss: 4.65788\n",
      "[TRAIN] Epoch: 3, Iter: 540, Loss: 4.54059\n",
      "[TRAIN] Epoch: 3, Iter: 550, Loss: 4.82478\n",
      "[TRAIN] Epoch: 3, Iter: 560, Loss: 4.61793\n",
      "[TRAIN] Epoch: 3, Iter: 570, Loss: 4.63954\n",
      "== [TRAIN] Epoch: 3, Perplexity: 104.736 ==>\n",
      "Before scheduler loss is: 4.651439087303718\n",
      "[VAL] Epoch: 3, Iter: 0, Loss: 4.85583\n",
      "[VAL] Epoch: 3, Iter: 10, Loss: 5.07559\n",
      "[VAL] Epoch: 3, Iter: 20, Loss: 5.21368\n",
      "[VAL] Epoch: 3, Iter: 30, Loss: 5.22548\n",
      "[VAL] Epoch: 3, Iter: 40, Loss: 4.97284\n",
      "[VAL] Epoch: 3, Iter: 50, Loss: 4.82915\n",
      "=== [VAL] Epoch: 3, Iter: 59, Perplexity: 151.440 ===>\n",
      "====== Epoch 4 ======>\n",
      "[TRAIN] Epoch: 4, Iter: 0, Loss: 4.40672\n",
      "[TRAIN] Epoch: 4, Iter: 10, Loss: 4.15543\n",
      "[TRAIN] Epoch: 4, Iter: 20, Loss: 4.32496\n",
      "[TRAIN] Epoch: 4, Iter: 30, Loss: 4.13788\n",
      "[TRAIN] Epoch: 4, Iter: 40, Loss: 4.07516\n",
      "[TRAIN] Epoch: 4, Iter: 50, Loss: 4.57699\n",
      "[TRAIN] Epoch: 4, Iter: 60, Loss: 4.45476\n",
      "[TRAIN] Epoch: 4, Iter: 70, Loss: 4.73432\n",
      "[TRAIN] Epoch: 4, Iter: 80, Loss: 4.32835\n",
      "[TRAIN] Epoch: 4, Iter: 90, Loss: 4.36023\n",
      "[TRAIN] Epoch: 4, Iter: 100, Loss: 4.45005\n",
      "[TRAIN] Epoch: 4, Iter: 110, Loss: 4.34412\n",
      "[TRAIN] Epoch: 4, Iter: 120, Loss: 4.34437\n",
      "[TRAIN] Epoch: 4, Iter: 130, Loss: 4.17969\n",
      "[TRAIN] Epoch: 4, Iter: 140, Loss: 4.50339\n",
      "[TRAIN] Epoch: 4, Iter: 150, Loss: 4.44541\n",
      "[TRAIN] Epoch: 4, Iter: 160, Loss: 4.22379\n",
      "[TRAIN] Epoch: 4, Iter: 170, Loss: 4.52331\n",
      "[TRAIN] Epoch: 4, Iter: 180, Loss: 4.61148\n",
      "[TRAIN] Epoch: 4, Iter: 190, Loss: 4.72969\n",
      "[TRAIN] Epoch: 4, Iter: 200, Loss: 4.39585\n",
      "[TRAIN] Epoch: 4, Iter: 210, Loss: 4.46413\n",
      "[TRAIN] Epoch: 4, Iter: 220, Loss: 4.17836\n",
      "[TRAIN] Epoch: 4, Iter: 230, Loss: 4.46232\n",
      "[TRAIN] Epoch: 4, Iter: 240, Loss: 4.31759\n",
      "[TRAIN] Epoch: 4, Iter: 250, Loss: 4.36742\n",
      "[TRAIN] Epoch: 4, Iter: 260, Loss: 4.36564\n",
      "[TRAIN] Epoch: 4, Iter: 270, Loss: 4.27092\n",
      "[TRAIN] Epoch: 4, Iter: 280, Loss: 4.38780\n",
      "[TRAIN] Epoch: 4, Iter: 290, Loss: 4.38742\n",
      "[TRAIN] Epoch: 4, Iter: 300, Loss: 4.38562\n",
      "[TRAIN] Epoch: 4, Iter: 310, Loss: 4.42238\n",
      "[TRAIN] Epoch: 4, Iter: 320, Loss: 4.58076\n",
      "[TRAIN] Epoch: 4, Iter: 330, Loss: 4.40668\n",
      "[TRAIN] Epoch: 4, Iter: 340, Loss: 4.45996\n",
      "[TRAIN] Epoch: 4, Iter: 350, Loss: 4.29375\n",
      "[TRAIN] Epoch: 4, Iter: 360, Loss: 4.42447\n",
      "[TRAIN] Epoch: 4, Iter: 370, Loss: 4.37601\n",
      "[TRAIN] Epoch: 4, Iter: 380, Loss: 4.43813\n",
      "[TRAIN] Epoch: 4, Iter: 390, Loss: 4.52119\n",
      "[TRAIN] Epoch: 4, Iter: 400, Loss: 4.38841\n",
      "[TRAIN] Epoch: 4, Iter: 410, Loss: 4.49870\n",
      "[TRAIN] Epoch: 4, Iter: 420, Loss: 4.27887\n",
      "[TRAIN] Epoch: 4, Iter: 430, Loss: 4.26784\n",
      "[TRAIN] Epoch: 4, Iter: 440, Loss: 4.21842\n",
      "[TRAIN] Epoch: 4, Iter: 450, Loss: 4.39845\n",
      "[TRAIN] Epoch: 4, Iter: 460, Loss: 4.46294\n",
      "[TRAIN] Epoch: 4, Iter: 470, Loss: 4.26323\n",
      "[TRAIN] Epoch: 4, Iter: 480, Loss: 4.59938\n",
      "[TRAIN] Epoch: 4, Iter: 490, Loss: 4.43779\n",
      "[TRAIN] Epoch: 4, Iter: 500, Loss: 4.31336\n",
      "[TRAIN] Epoch: 4, Iter: 510, Loss: 4.43990\n",
      "[TRAIN] Epoch: 4, Iter: 520, Loss: 4.44584\n",
      "[TRAIN] Epoch: 4, Iter: 530, Loss: 4.58761\n",
      "[TRAIN] Epoch: 4, Iter: 540, Loss: 4.30950\n",
      "[TRAIN] Epoch: 4, Iter: 550, Loss: 4.60613\n",
      "[TRAIN] Epoch: 4, Iter: 560, Loss: 4.54145\n",
      "[TRAIN] Epoch: 4, Iter: 570, Loss: 4.26651\n",
      "== [TRAIN] Epoch: 4, Perplexity: 83.927 ==>\n",
      "Before scheduler loss is: 4.429949203855358\n",
      "[VAL] Epoch: 4, Iter: 0, Loss: 4.79090\n",
      "[VAL] Epoch: 4, Iter: 10, Loss: 5.00666\n",
      "[VAL] Epoch: 4, Iter: 20, Loss: 5.16809\n",
      "[VAL] Epoch: 4, Iter: 30, Loss: 5.22032\n",
      "[VAL] Epoch: 4, Iter: 40, Loss: 4.94004\n",
      "[VAL] Epoch: 4, Iter: 50, Loss: 4.79677\n",
      "=== [VAL] Epoch: 4, Iter: 59, Perplexity: 145.700 ===>\n",
      "====== Epoch 5 ======>\n",
      "[TRAIN] Epoch: 5, Iter: 0, Loss: 4.28570\n",
      "[TRAIN] Epoch: 5, Iter: 10, Loss: 4.32023\n",
      "[TRAIN] Epoch: 5, Iter: 20, Loss: 3.98745\n",
      "[TRAIN] Epoch: 5, Iter: 30, Loss: 4.05052\n",
      "[TRAIN] Epoch: 5, Iter: 40, Loss: 4.14994\n",
      "[TRAIN] Epoch: 5, Iter: 50, Loss: 4.11552\n",
      "[TRAIN] Epoch: 5, Iter: 60, Loss: 3.79329\n",
      "[TRAIN] Epoch: 5, Iter: 70, Loss: 4.06198\n",
      "[TRAIN] Epoch: 5, Iter: 80, Loss: 4.05920\n",
      "[TRAIN] Epoch: 5, Iter: 90, Loss: 4.28689\n",
      "[TRAIN] Epoch: 5, Iter: 100, Loss: 4.17482\n",
      "[TRAIN] Epoch: 5, Iter: 110, Loss: 3.96723\n",
      "[TRAIN] Epoch: 5, Iter: 120, Loss: 4.30948\n",
      "[TRAIN] Epoch: 5, Iter: 130, Loss: 4.15419\n",
      "[TRAIN] Epoch: 5, Iter: 140, Loss: 4.22486\n",
      "[TRAIN] Epoch: 5, Iter: 150, Loss: 4.04429\n",
      "[TRAIN] Epoch: 5, Iter: 160, Loss: 4.21376\n",
      "[TRAIN] Epoch: 5, Iter: 170, Loss: 4.22249\n",
      "[TRAIN] Epoch: 5, Iter: 180, Loss: 4.11764\n",
      "[TRAIN] Epoch: 5, Iter: 190, Loss: 3.90250\n",
      "[TRAIN] Epoch: 5, Iter: 200, Loss: 4.21706\n",
      "[TRAIN] Epoch: 5, Iter: 210, Loss: 4.18662\n",
      "[TRAIN] Epoch: 5, Iter: 220, Loss: 4.16118\n",
      "[TRAIN] Epoch: 5, Iter: 230, Loss: 4.15621\n",
      "[TRAIN] Epoch: 5, Iter: 240, Loss: 4.13932\n",
      "[TRAIN] Epoch: 5, Iter: 250, Loss: 4.11816\n",
      "[TRAIN] Epoch: 5, Iter: 260, Loss: 4.09745\n",
      "[TRAIN] Epoch: 5, Iter: 270, Loss: 4.10403\n",
      "[TRAIN] Epoch: 5, Iter: 280, Loss: 3.99012\n",
      "[TRAIN] Epoch: 5, Iter: 290, Loss: 4.14421\n",
      "[TRAIN] Epoch: 5, Iter: 300, Loss: 4.02530\n",
      "[TRAIN] Epoch: 5, Iter: 310, Loss: 4.08598\n",
      "[TRAIN] Epoch: 5, Iter: 320, Loss: 4.26337\n",
      "[TRAIN] Epoch: 5, Iter: 330, Loss: 4.16179\n",
      "[TRAIN] Epoch: 5, Iter: 340, Loss: 4.16199\n",
      "[TRAIN] Epoch: 5, Iter: 350, Loss: 3.94060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch: 5, Iter: 360, Loss: 4.08648\n",
      "[TRAIN] Epoch: 5, Iter: 370, Loss: 4.02147\n",
      "[TRAIN] Epoch: 5, Iter: 380, Loss: 3.99231\n",
      "[TRAIN] Epoch: 5, Iter: 390, Loss: 4.25779\n",
      "[TRAIN] Epoch: 5, Iter: 400, Loss: 4.16451\n",
      "[TRAIN] Epoch: 5, Iter: 410, Loss: 3.97354\n",
      "[TRAIN] Epoch: 5, Iter: 420, Loss: 4.05477\n",
      "[TRAIN] Epoch: 5, Iter: 430, Loss: 3.91704\n",
      "[TRAIN] Epoch: 5, Iter: 440, Loss: 4.28636\n",
      "[TRAIN] Epoch: 5, Iter: 450, Loss: 4.27324\n",
      "[TRAIN] Epoch: 5, Iter: 460, Loss: 4.12977\n",
      "[TRAIN] Epoch: 5, Iter: 470, Loss: 4.07615\n",
      "[TRAIN] Epoch: 5, Iter: 480, Loss: 4.43358\n",
      "[TRAIN] Epoch: 5, Iter: 490, Loss: 4.13068\n",
      "[TRAIN] Epoch: 5, Iter: 500, Loss: 4.01960\n",
      "[TRAIN] Epoch: 5, Iter: 510, Loss: 3.98169\n",
      "[TRAIN] Epoch: 5, Iter: 520, Loss: 4.00735\n",
      "[TRAIN] Epoch: 5, Iter: 530, Loss: 3.91017\n",
      "[TRAIN] Epoch: 5, Iter: 540, Loss: 4.24141\n",
      "[TRAIN] Epoch: 5, Iter: 550, Loss: 4.17427\n",
      "[TRAIN] Epoch: 5, Iter: 560, Loss: 4.23285\n",
      "[TRAIN] Epoch: 5, Iter: 570, Loss: 4.33557\n",
      "== [TRAIN] Epoch: 5, Perplexity: 60.502 ==>\n",
      "Before scheduler loss is: 4.102673836479274\n",
      "[VAL] Epoch: 5, Iter: 0, Loss: 4.71910\n",
      "[VAL] Epoch: 5, Iter: 10, Loss: 5.03132\n",
      "[VAL] Epoch: 5, Iter: 20, Loss: 5.18255\n",
      "[VAL] Epoch: 5, Iter: 30, Loss: 5.20762\n",
      "[VAL] Epoch: 5, Iter: 40, Loss: 4.91872\n",
      "[VAL] Epoch: 5, Iter: 50, Loss: 4.74017\n",
      "=== [VAL] Epoch: 5, Iter: 59, Perplexity: 145.288 ===>\n",
      "====== Epoch 6 ======>\n",
      "[TRAIN] Epoch: 6, Iter: 0, Loss: 3.80320\n",
      "[TRAIN] Epoch: 6, Iter: 10, Loss: 3.86450\n",
      "[TRAIN] Epoch: 6, Iter: 20, Loss: 4.18727\n",
      "[TRAIN] Epoch: 6, Iter: 30, Loss: 3.86550\n",
      "[TRAIN] Epoch: 6, Iter: 40, Loss: 3.86631\n",
      "[TRAIN] Epoch: 6, Iter: 50, Loss: 4.03062\n",
      "[TRAIN] Epoch: 6, Iter: 60, Loss: 3.84879\n",
      "[TRAIN] Epoch: 6, Iter: 70, Loss: 3.80974\n",
      "[TRAIN] Epoch: 6, Iter: 80, Loss: 3.59257\n",
      "[TRAIN] Epoch: 6, Iter: 90, Loss: 3.88944\n",
      "[TRAIN] Epoch: 6, Iter: 100, Loss: 3.66780\n",
      "[TRAIN] Epoch: 6, Iter: 110, Loss: 4.07003\n",
      "[TRAIN] Epoch: 6, Iter: 120, Loss: 4.03861\n",
      "[TRAIN] Epoch: 6, Iter: 130, Loss: 3.94564\n",
      "[TRAIN] Epoch: 6, Iter: 140, Loss: 3.82981\n",
      "[TRAIN] Epoch: 6, Iter: 150, Loss: 4.08695\n",
      "[TRAIN] Epoch: 6, Iter: 160, Loss: 4.01659\n",
      "[TRAIN] Epoch: 6, Iter: 170, Loss: 3.91710\n",
      "[TRAIN] Epoch: 6, Iter: 180, Loss: 3.98697\n",
      "[TRAIN] Epoch: 6, Iter: 190, Loss: 3.94452\n",
      "[TRAIN] Epoch: 6, Iter: 200, Loss: 4.12175\n",
      "[TRAIN] Epoch: 6, Iter: 210, Loss: 3.86389\n",
      "[TRAIN] Epoch: 6, Iter: 220, Loss: 3.83400\n",
      "[TRAIN] Epoch: 6, Iter: 230, Loss: 3.83606\n",
      "[TRAIN] Epoch: 6, Iter: 240, Loss: 3.91917\n",
      "[TRAIN] Epoch: 6, Iter: 250, Loss: 3.99164\n",
      "[TRAIN] Epoch: 6, Iter: 260, Loss: 4.04350\n",
      "[TRAIN] Epoch: 6, Iter: 270, Loss: 4.13049\n",
      "[TRAIN] Epoch: 6, Iter: 280, Loss: 4.03480\n",
      "[TRAIN] Epoch: 6, Iter: 290, Loss: 3.94771\n",
      "[TRAIN] Epoch: 6, Iter: 300, Loss: 4.02716\n",
      "[TRAIN] Epoch: 6, Iter: 310, Loss: 3.94559\n",
      "[TRAIN] Epoch: 6, Iter: 320, Loss: 3.89935\n",
      "[TRAIN] Epoch: 6, Iter: 330, Loss: 3.87094\n",
      "[TRAIN] Epoch: 6, Iter: 340, Loss: 4.09939\n",
      "[TRAIN] Epoch: 6, Iter: 350, Loss: 4.09603\n",
      "[TRAIN] Epoch: 6, Iter: 360, Loss: 3.81576\n",
      "[TRAIN] Epoch: 6, Iter: 370, Loss: 3.94747\n",
      "[TRAIN] Epoch: 6, Iter: 380, Loss: 4.03044\n",
      "[TRAIN] Epoch: 6, Iter: 390, Loss: 3.92071\n",
      "[TRAIN] Epoch: 6, Iter: 400, Loss: 4.22037\n",
      "[TRAIN] Epoch: 6, Iter: 410, Loss: 3.98051\n",
      "[TRAIN] Epoch: 6, Iter: 420, Loss: 4.00975\n",
      "[TRAIN] Epoch: 6, Iter: 430, Loss: 4.07427\n",
      "[TRAIN] Epoch: 6, Iter: 440, Loss: 4.04634\n",
      "[TRAIN] Epoch: 6, Iter: 450, Loss: 4.07287\n",
      "[TRAIN] Epoch: 6, Iter: 460, Loss: 4.06697\n",
      "[TRAIN] Epoch: 6, Iter: 470, Loss: 3.88697\n",
      "[TRAIN] Epoch: 6, Iter: 480, Loss: 4.19290\n",
      "[TRAIN] Epoch: 6, Iter: 490, Loss: 4.04767\n",
      "[TRAIN] Epoch: 6, Iter: 500, Loss: 3.94193\n",
      "[TRAIN] Epoch: 6, Iter: 510, Loss: 4.09201\n",
      "[TRAIN] Epoch: 6, Iter: 520, Loss: 3.67394\n",
      "[TRAIN] Epoch: 6, Iter: 530, Loss: 3.90509\n",
      "[TRAIN] Epoch: 6, Iter: 540, Loss: 4.11998\n",
      "[TRAIN] Epoch: 6, Iter: 550, Loss: 3.97583\n",
      "[TRAIN] Epoch: 6, Iter: 560, Loss: 4.18111\n",
      "[TRAIN] Epoch: 6, Iter: 570, Loss: 3.91365\n",
      "== [TRAIN] Epoch: 6, Perplexity: 52.505 ==>\n",
      "Before scheduler loss is: 3.960906152098687\n",
      "[VAL] Epoch: 6, Iter: 0, Loss: 4.76623\n",
      "[VAL] Epoch: 6, Iter: 10, Loss: 5.06090\n",
      "[VAL] Epoch: 6, Iter: 20, Loss: 5.21464\n",
      "[VAL] Epoch: 6, Iter: 30, Loss: 5.26664\n",
      "[VAL] Epoch: 6, Iter: 40, Loss: 4.97372\n",
      "[VAL] Epoch: 6, Iter: 50, Loss: 4.76035\n",
      "=== [VAL] Epoch: 6, Iter: 59, Perplexity: 150.887 ===>\n",
      "====== Epoch 7 ======>\n",
      "[TRAIN] Epoch: 7, Iter: 0, Loss: 3.56285\n",
      "[TRAIN] Epoch: 7, Iter: 10, Loss: 3.78945\n",
      "[TRAIN] Epoch: 7, Iter: 20, Loss: 3.68714\n",
      "[TRAIN] Epoch: 7, Iter: 30, Loss: 3.84653\n",
      "[TRAIN] Epoch: 7, Iter: 40, Loss: 3.78237\n",
      "[TRAIN] Epoch: 7, Iter: 50, Loss: 3.69786\n",
      "[TRAIN] Epoch: 7, Iter: 60, Loss: 3.89196\n",
      "[TRAIN] Epoch: 7, Iter: 70, Loss: 3.85847\n",
      "[TRAIN] Epoch: 7, Iter: 80, Loss: 3.68245\n",
      "[TRAIN] Epoch: 7, Iter: 90, Loss: 3.69306\n",
      "[TRAIN] Epoch: 7, Iter: 100, Loss: 3.71952\n",
      "[TRAIN] Epoch: 7, Iter: 110, Loss: 3.56900\n",
      "[TRAIN] Epoch: 7, Iter: 120, Loss: 3.79444\n",
      "[TRAIN] Epoch: 7, Iter: 130, Loss: 3.84930\n",
      "[TRAIN] Epoch: 7, Iter: 140, Loss: 3.79938\n",
      "[TRAIN] Epoch: 7, Iter: 150, Loss: 3.68990\n",
      "[TRAIN] Epoch: 7, Iter: 160, Loss: 3.58861\n",
      "[TRAIN] Epoch: 7, Iter: 170, Loss: 3.87878\n",
      "[TRAIN] Epoch: 7, Iter: 180, Loss: 3.67864\n",
      "[TRAIN] Epoch: 7, Iter: 190, Loss: 3.68560\n",
      "[TRAIN] Epoch: 7, Iter: 200, Loss: 3.52466\n",
      "[TRAIN] Epoch: 7, Iter: 210, Loss: 3.66913\n",
      "[TRAIN] Epoch: 7, Iter: 220, Loss: 3.72372\n",
      "[TRAIN] Epoch: 7, Iter: 230, Loss: 3.63671\n",
      "[TRAIN] Epoch: 7, Iter: 240, Loss: 3.83502\n",
      "[TRAIN] Epoch: 7, Iter: 250, Loss: 3.67770\n",
      "[TRAIN] Epoch: 7, Iter: 260, Loss: 3.91639\n",
      "[TRAIN] Epoch: 7, Iter: 270, Loss: 3.71318\n",
      "[TRAIN] Epoch: 7, Iter: 280, Loss: 3.72937\n",
      "[TRAIN] Epoch: 7, Iter: 290, Loss: 3.79709\n",
      "[TRAIN] Epoch: 7, Iter: 300, Loss: 3.79507\n",
      "[TRAIN] Epoch: 7, Iter: 310, Loss: 3.67394\n",
      "[TRAIN] Epoch: 7, Iter: 320, Loss: 3.79514\n",
      "[TRAIN] Epoch: 7, Iter: 330, Loss: 3.78188\n",
      "[TRAIN] Epoch: 7, Iter: 340, Loss: 3.51773\n",
      "[TRAIN] Epoch: 7, Iter: 350, Loss: 3.70147\n",
      "[TRAIN] Epoch: 7, Iter: 360, Loss: 3.75360\n",
      "[TRAIN] Epoch: 7, Iter: 370, Loss: 3.71769\n",
      "[TRAIN] Epoch: 7, Iter: 380, Loss: 3.70999\n",
      "[TRAIN] Epoch: 7, Iter: 390, Loss: 3.82424\n",
      "[TRAIN] Epoch: 7, Iter: 400, Loss: 3.68496\n",
      "[TRAIN] Epoch: 7, Iter: 410, Loss: 3.77433\n",
      "[TRAIN] Epoch: 7, Iter: 420, Loss: 3.62530\n",
      "[TRAIN] Epoch: 7, Iter: 430, Loss: 3.75275\n",
      "[TRAIN] Epoch: 7, Iter: 440, Loss: 3.69782\n",
      "[TRAIN] Epoch: 7, Iter: 450, Loss: 3.74528\n",
      "[TRAIN] Epoch: 7, Iter: 460, Loss: 3.64509\n",
      "[TRAIN] Epoch: 7, Iter: 470, Loss: 3.82936\n",
      "[TRAIN] Epoch: 7, Iter: 480, Loss: 3.86515\n",
      "[TRAIN] Epoch: 7, Iter: 490, Loss: 3.63790\n",
      "[TRAIN] Epoch: 7, Iter: 500, Loss: 3.70413\n",
      "[TRAIN] Epoch: 7, Iter: 510, Loss: 3.71159\n",
      "[TRAIN] Epoch: 7, Iter: 520, Loss: 3.74108\n",
      "[TRAIN] Epoch: 7, Iter: 530, Loss: 3.74646\n",
      "[TRAIN] Epoch: 7, Iter: 540, Loss: 3.77533\n",
      "[TRAIN] Epoch: 7, Iter: 550, Loss: 3.86462\n",
      "[TRAIN] Epoch: 7, Iter: 560, Loss: 3.83009\n",
      "[TRAIN] Epoch: 7, Iter: 570, Loss: 3.74133\n",
      "== [TRAIN] Epoch: 7, Perplexity: 41.686 ==>\n",
      "Before scheduler loss is: 3.7301596614298536\n",
      "[VAL] Epoch: 7, Iter: 0, Loss: 4.76285\n",
      "[VAL] Epoch: 7, Iter: 10, Loss: 5.09755\n",
      "[VAL] Epoch: 7, Iter: 20, Loss: 5.27010\n",
      "[VAL] Epoch: 7, Iter: 30, Loss: 5.35411\n",
      "[VAL] Epoch: 7, Iter: 40, Loss: 5.00557\n",
      "[VAL] Epoch: 7, Iter: 50, Loss: 4.78695\n",
      "=== [VAL] Epoch: 7, Iter: 59, Perplexity: 158.738 ===>\n",
      "====== Epoch 8 ======>\n",
      "[TRAIN] Epoch: 8, Iter: 0, Loss: 3.72411\n",
      "[TRAIN] Epoch: 8, Iter: 10, Loss: 3.56720\n",
      "[TRAIN] Epoch: 8, Iter: 20, Loss: 3.60036\n",
      "[TRAIN] Epoch: 8, Iter: 30, Loss: 3.45287\n",
      "[TRAIN] Epoch: 8, Iter: 40, Loss: 3.53913\n",
      "[TRAIN] Epoch: 8, Iter: 50, Loss: 3.67037\n",
      "[TRAIN] Epoch: 8, Iter: 60, Loss: 3.50911\n",
      "[TRAIN] Epoch: 8, Iter: 70, Loss: 3.75125\n",
      "[TRAIN] Epoch: 8, Iter: 80, Loss: 3.76492\n",
      "[TRAIN] Epoch: 8, Iter: 90, Loss: 3.74226\n",
      "[TRAIN] Epoch: 8, Iter: 100, Loss: 3.40543\n",
      "[TRAIN] Epoch: 8, Iter: 110, Loss: 3.56145\n",
      "[TRAIN] Epoch: 8, Iter: 120, Loss: 3.69565\n",
      "[TRAIN] Epoch: 8, Iter: 130, Loss: 3.46207\n",
      "[TRAIN] Epoch: 8, Iter: 140, Loss: 3.61458\n",
      "[TRAIN] Epoch: 8, Iter: 150, Loss: 3.72828\n",
      "[TRAIN] Epoch: 8, Iter: 160, Loss: 3.66014\n",
      "[TRAIN] Epoch: 8, Iter: 170, Loss: 3.59480\n",
      "[TRAIN] Epoch: 8, Iter: 180, Loss: 3.70564\n",
      "[TRAIN] Epoch: 8, Iter: 190, Loss: 3.57943\n",
      "[TRAIN] Epoch: 8, Iter: 200, Loss: 3.58619\n",
      "[TRAIN] Epoch: 8, Iter: 210, Loss: 3.82848\n",
      "[TRAIN] Epoch: 8, Iter: 220, Loss: 3.72685\n",
      "[TRAIN] Epoch: 8, Iter: 230, Loss: 3.45079\n",
      "[TRAIN] Epoch: 8, Iter: 240, Loss: 3.54238\n",
      "[TRAIN] Epoch: 8, Iter: 250, Loss: 3.76768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch: 8, Iter: 260, Loss: 3.67517\n",
      "[TRAIN] Epoch: 8, Iter: 270, Loss: 3.91416\n",
      "[TRAIN] Epoch: 8, Iter: 280, Loss: 3.76780\n",
      "[TRAIN] Epoch: 8, Iter: 290, Loss: 3.68484\n",
      "[TRAIN] Epoch: 8, Iter: 300, Loss: 3.25367\n",
      "[TRAIN] Epoch: 8, Iter: 310, Loss: 3.61306\n",
      "[TRAIN] Epoch: 8, Iter: 320, Loss: 3.75710\n",
      "[TRAIN] Epoch: 8, Iter: 330, Loss: 3.83169\n",
      "[TRAIN] Epoch: 8, Iter: 340, Loss: 3.57013\n",
      "[TRAIN] Epoch: 8, Iter: 350, Loss: 3.55956\n",
      "[TRAIN] Epoch: 8, Iter: 360, Loss: 3.75187\n",
      "[TRAIN] Epoch: 8, Iter: 370, Loss: 3.59154\n",
      "[TRAIN] Epoch: 8, Iter: 380, Loss: 3.64999\n",
      "[TRAIN] Epoch: 8, Iter: 390, Loss: 3.59570\n",
      "[TRAIN] Epoch: 8, Iter: 400, Loss: 3.57535\n",
      "[TRAIN] Epoch: 8, Iter: 410, Loss: 3.59383\n",
      "[TRAIN] Epoch: 8, Iter: 420, Loss: 3.76861\n",
      "[TRAIN] Epoch: 8, Iter: 430, Loss: 3.82177\n",
      "[TRAIN] Epoch: 8, Iter: 440, Loss: 3.89195\n",
      "[TRAIN] Epoch: 8, Iter: 450, Loss: 3.70080\n",
      "[TRAIN] Epoch: 8, Iter: 460, Loss: 3.75740\n",
      "[TRAIN] Epoch: 8, Iter: 470, Loss: 3.39137\n",
      "[TRAIN] Epoch: 8, Iter: 480, Loss: 3.69711\n",
      "[TRAIN] Epoch: 8, Iter: 490, Loss: 3.73389\n",
      "[TRAIN] Epoch: 8, Iter: 500, Loss: 3.71588\n",
      "[TRAIN] Epoch: 8, Iter: 510, Loss: 3.81869\n",
      "[TRAIN] Epoch: 8, Iter: 520, Loss: 3.94462\n",
      "[TRAIN] Epoch: 8, Iter: 530, Loss: 3.56569\n",
      "[TRAIN] Epoch: 8, Iter: 540, Loss: 3.89896\n",
      "[TRAIN] Epoch: 8, Iter: 550, Loss: 3.62859\n",
      "[TRAIN] Epoch: 8, Iter: 560, Loss: 3.57396\n",
      "[TRAIN] Epoch: 8, Iter: 570, Loss: 3.55816\n",
      "== [TRAIN] Epoch: 8, Perplexity: 38.164 ==>\n",
      "Before scheduler loss is: 3.6418796256863666\n",
      "[VAL] Epoch: 8, Iter: 0, Loss: 4.78931\n",
      "[VAL] Epoch: 8, Iter: 10, Loss: 5.11731\n",
      "[VAL] Epoch: 8, Iter: 20, Loss: 5.32748\n",
      "[VAL] Epoch: 8, Iter: 30, Loss: 5.39126\n",
      "[VAL] Epoch: 8, Iter: 40, Loss: 5.03681\n",
      "[VAL] Epoch: 8, Iter: 50, Loss: 4.82223\n",
      "=== [VAL] Epoch: 8, Iter: 59, Perplexity: 165.012 ===>\n",
      "====== Epoch 9 ======>\n",
      "[TRAIN] Epoch: 9, Iter: 0, Loss: 3.43972\n",
      "[TRAIN] Epoch: 9, Iter: 10, Loss: 3.48065\n",
      "[TRAIN] Epoch: 9, Iter: 20, Loss: 3.58247\n",
      "[TRAIN] Epoch: 9, Iter: 30, Loss: 3.48324\n",
      "[TRAIN] Epoch: 9, Iter: 40, Loss: 3.31642\n",
      "[TRAIN] Epoch: 9, Iter: 50, Loss: 3.39743\n",
      "[TRAIN] Epoch: 9, Iter: 60, Loss: 3.65016\n",
      "[TRAIN] Epoch: 9, Iter: 70, Loss: 3.29014\n",
      "[TRAIN] Epoch: 9, Iter: 80, Loss: 3.44359\n",
      "[TRAIN] Epoch: 9, Iter: 90, Loss: 3.36339\n",
      "[TRAIN] Epoch: 9, Iter: 100, Loss: 3.47645\n",
      "[TRAIN] Epoch: 9, Iter: 110, Loss: 3.29498\n",
      "[TRAIN] Epoch: 9, Iter: 120, Loss: 3.53294\n",
      "[TRAIN] Epoch: 9, Iter: 130, Loss: 3.45319\n",
      "[TRAIN] Epoch: 9, Iter: 140, Loss: 3.49056\n",
      "[TRAIN] Epoch: 9, Iter: 150, Loss: 3.42488\n",
      "[TRAIN] Epoch: 9, Iter: 160, Loss: 3.53687\n",
      "[TRAIN] Epoch: 9, Iter: 170, Loss: 3.62129\n",
      "[TRAIN] Epoch: 9, Iter: 180, Loss: 3.57140\n",
      "[TRAIN] Epoch: 9, Iter: 190, Loss: 3.71873\n",
      "[TRAIN] Epoch: 9, Iter: 200, Loss: 3.52821\n",
      "[TRAIN] Epoch: 9, Iter: 210, Loss: 3.42707\n",
      "[TRAIN] Epoch: 9, Iter: 220, Loss: 3.38567\n",
      "[TRAIN] Epoch: 9, Iter: 230, Loss: 3.46646\n",
      "[TRAIN] Epoch: 9, Iter: 240, Loss: 3.27235\n",
      "[TRAIN] Epoch: 9, Iter: 250, Loss: 3.45520\n",
      "[TRAIN] Epoch: 9, Iter: 260, Loss: 3.40159\n",
      "[TRAIN] Epoch: 9, Iter: 270, Loss: 3.48300\n",
      "[TRAIN] Epoch: 9, Iter: 280, Loss: 3.63433\n",
      "[TRAIN] Epoch: 9, Iter: 290, Loss: 3.38125\n",
      "[TRAIN] Epoch: 9, Iter: 300, Loss: 3.32344\n",
      "[TRAIN] Epoch: 9, Iter: 310, Loss: 3.56914\n",
      "[TRAIN] Epoch: 9, Iter: 320, Loss: 3.38797\n",
      "[TRAIN] Epoch: 9, Iter: 330, Loss: 3.53556\n",
      "[TRAIN] Epoch: 9, Iter: 340, Loss: 3.62262\n",
      "[TRAIN] Epoch: 9, Iter: 350, Loss: 3.56265\n",
      "[TRAIN] Epoch: 9, Iter: 360, Loss: 3.36073\n",
      "[TRAIN] Epoch: 9, Iter: 370, Loss: 3.46722\n",
      "[TRAIN] Epoch: 9, Iter: 380, Loss: 3.45497\n",
      "[TRAIN] Epoch: 9, Iter: 390, Loss: 3.47115\n",
      "[TRAIN] Epoch: 9, Iter: 400, Loss: 3.51754\n",
      "[TRAIN] Epoch: 9, Iter: 410, Loss: 3.46190\n",
      "[TRAIN] Epoch: 9, Iter: 420, Loss: 3.70846\n",
      "[TRAIN] Epoch: 9, Iter: 430, Loss: 3.42931\n",
      "[TRAIN] Epoch: 9, Iter: 440, Loss: 3.56631\n",
      "[TRAIN] Epoch: 9, Iter: 450, Loss: 3.50877\n",
      "[TRAIN] Epoch: 9, Iter: 460, Loss: 3.46155\n",
      "[TRAIN] Epoch: 9, Iter: 470, Loss: 3.55784\n",
      "[TRAIN] Epoch: 9, Iter: 480, Loss: 3.50399\n",
      "[TRAIN] Epoch: 9, Iter: 490, Loss: 3.49587\n",
      "[TRAIN] Epoch: 9, Iter: 500, Loss: 3.69123\n",
      "[TRAIN] Epoch: 9, Iter: 510, Loss: 3.32261\n",
      "[TRAIN] Epoch: 9, Iter: 520, Loss: 3.66472\n",
      "[TRAIN] Epoch: 9, Iter: 530, Loss: 3.62425\n",
      "[TRAIN] Epoch: 9, Iter: 540, Loss: 3.51376\n",
      "[TRAIN] Epoch: 9, Iter: 550, Loss: 3.69032\n",
      "[TRAIN] Epoch: 9, Iter: 560, Loss: 3.67218\n",
      "[TRAIN] Epoch: 9, Iter: 570, Loss: 3.80574\n",
      "== [TRAIN] Epoch: 9, Perplexity: 33.189 ==>\n",
      "Before scheduler loss is: 3.5022275589193064\n",
      "[VAL] Epoch: 9, Iter: 0, Loss: 4.83414\n",
      "[VAL] Epoch: 9, Iter: 10, Loss: 5.18162\n",
      "[VAL] Epoch: 9, Iter: 20, Loss: 5.38275\n",
      "[VAL] Epoch: 9, Iter: 30, Loss: 5.45851\n",
      "[VAL] Epoch: 9, Iter: 40, Loss: 5.08526\n",
      "[VAL] Epoch: 9, Iter: 50, Loss: 4.85223\n",
      "=== [VAL] Epoch: 9, Iter: 59, Perplexity: 173.371 ===>\n",
      "[TEST] Epoch: 9, Iter: 0, Loss: 5.32575\n",
      "[TEST] Epoch: 9, Iter: 10, Loss: 5.11864\n",
      "[TEST] Epoch: 9, Iter: 20, Loss: 5.65286\n",
      "[TEST] Epoch: 9, Iter: 30, Loss: 5.33500\n",
      "[TEST] Epoch: 9, Iter: 40, Loss: 5.20766\n",
      "[TEST] Epoch: 9, Iter: 50, Loss: 5.31762\n",
      "[TEST] Epoch: 9, Iter: 60, Loss: 4.99805\n",
      "=== [TEST] Epoch: 9, Iter: 68, Perplexity: 176.128 ===>\n",
      "===== Best validation perplexity: 145.288 =====>\n"
     ]
    }
   ],
   "source": [
    "!python run_exp.py --model='gpt1' --layers=1 --batch_size=16 --epochs=10 --optimizer='adamw' --exp_id='14' --seed=1023"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
