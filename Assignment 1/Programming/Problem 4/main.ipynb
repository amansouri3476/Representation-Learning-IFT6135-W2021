{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "dt3NTvpsy4Oc"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTv0D26B9W2h"
      },
      "source": [
        "# Assignment 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9VX-OHxC1FM"
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFHMMDtSwuW4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "2e502916-d258-4509-f788-006f6c5e48c5"
      },
      "source": [
        "#@title Mount your Google Drive\n",
        "%matplotlib inline\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oODLwt1QzgGa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "0de18d7f-b25c-4f92-c7c7-20d8de5f70d3"
      },
      "source": [
        "#@title Link your assignment folder & install requirements\n",
        "#@markdown Enter the path to the assignment folder in your Google Drive\n",
        "import sys\n",
        "import os\n",
        "import shutil\n",
        "import warnings\n",
        "\n",
        "folder = \"content/assignment\" #@param {type:\"string\"}\n",
        "!ln -Ts $folder /content/assignment 2> /dev/null\n",
        "\n",
        "# Add the assignment folder to Python path\n",
        "if '/content/assignment' not in sys.path:\n",
        "  sys.path.insert(0, '/content/assignment')\n",
        "\n",
        "# Install requirements\n",
        "!pip install -qr /content/assignment/requirements.txt\n",
        "\n",
        "# Check if CUDA is available\n",
        "import torch\n",
        "if not torch.cuda.is_available():\n",
        "  warnings.warn('CUDA is not available.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 776.8MB 22kB/s \n",
            "\u001b[K     |████████████████████████████████| 11.8MB 22.5MB/s \n",
            "\u001b[?25h  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: UserWarning: CUDA is not available.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "dt3NTvpsy4Oc"
      },
      "source": [
        "## Running on GPU\n",
        "In Google Colab, you can run your code on GPU. This will be particularly important in CNN part of the assignment. To make sure the notebook is running on GPU, you can change the notebook settings with\n",
        "* (EN) `Edit > Notebook Settings`\n",
        "* (FR) `Modifier > Paramètres du notebook`\n",
        "\n",
        "Be mindful not to use the GPU if your code does not need to run on GPU.\n",
        "\n",
        "Of course, your code written in NumPy (e.g. your `solution.py`) cannot be ran on GPU, only your code written in PyTorch can."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2SPOy6yCU_S"
      },
      "source": [
        "## Data utilities (do not modify)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xC-KePrx_J0L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a730f4c5-9023-4594-bea6-9cfa7f5212ab"
      },
      "source": [
        "from solution import load_cifar10\n",
        "data = load_cifar10('/tmp/data', flatten=True)  # can use flatten=False to get the image shape.\n",
        "train_data, valid_data, test_data = data\n",
        "image, label = train_data[0][0], train_data[1][0]\n",
        "image.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3072,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBV2sLsnGcyO"
      },
      "source": [
        "def load_cifar10(root, flatten=False):\r\n",
        "    \"\"\"\r\n",
        "    Usage example:\r\n",
        "    > train_data, valid_data, test_data = load_cifar10(\"/data\", flatten=True)\r\n",
        "    > train_x, train_y = train_data\r\n",
        "    where both train_x and train_y are numpy arrays\r\n",
        "    train_x.shape == (40000, 3072) or train_x.shape == (40000, 3, 32, 32)\r\n",
        "    train_y.shape == (40000, 10), one-hot format\r\n",
        "    :param root: path where the cifar10 dataset will be downloaded, e.g. \"/tmp/data/\"\r\n",
        "    :param flatten: When True, dataset is reshaped to (num_examples, 3072), otherwise shape is (num_examples, 3, 32, 32)\r\n",
        "    :return: train, valid and test set in numpy arrays\r\n",
        "    \"\"\"\r\n",
        "    transform = torchvision.transforms.ToTensor()\r\n",
        "\r\n",
        "    train_dataset = torchvision.datasets.CIFAR10(root, train=True, transform=transform, download=True)\r\n",
        "    test_dataset = torchvision.datasets.CIFAR10(root, train=False, transform=transform, download=True)\r\n",
        "\r\n",
        "    # randomly split train into train/valid\r\n",
        "    perm = np.random.RandomState(seed=1).permutation(\r\n",
        "        range(len(train_dataset)))  # fix seed to have same split every time.\r\n",
        "    x = [train_dataset[i][0] for i in perm]  # train_dataset.data[perm]\r\n",
        "    y = [one_hot(train_dataset[i][1]) for i in perm]\r\n",
        "    train_x, train_y = x[:40000], y[:40000]\r\n",
        "    valid_x, valid_y = x[40000:], y[40000:]\r\n",
        "    test_x = [test_dataset[i][0] for i in range(len(test_dataset))]\r\n",
        "    test_y = [one_hot(test_dataset[i][1]) for i in range(len(test_dataset))]\r\n",
        "\r\n",
        "    # convert to numpy arrays after stacking\r\n",
        "    train_x = torch.stack(train_x).cpu().numpy()\r\n",
        "    train_y = np.stack(train_y)\r\n",
        "    valid_x = torch.stack(valid_x).cpu().numpy()\r\n",
        "    valid_y = np.stack(valid_y)\r\n",
        "    test_x = torch.stack(test_x).cpu().numpy()\r\n",
        "    test_y = np.stack(test_y)\r\n",
        "\r\n",
        "    if flatten:\r\n",
        "        train_x = train_x.reshape(-1, 32 * 32 * 3)\r\n",
        "        valid_x = valid_x.reshape(-1, 32 * 32 * 3)\r\n",
        "        test_x = test_x.reshape(-1, 32 * 32 * 3)\r\n",
        "\r\n",
        "    # Package everything\r\n",
        "    train_data = train_x, train_y\r\n",
        "    valid_data = valid_x, valid_y\r\n",
        "    test_data = test_x, test_y\r\n",
        "\r\n",
        "    return train_data, valid_data, test_data\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZqQ4QbYy4On"
      },
      "source": [
        "## Load the `NN` class from your `solution.py`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CX-48u0QNVVm"
      },
      "source": [
        "import numpy as np\r\n",
        "import torch\r\n",
        "import torchvision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYVpHngKeIpR"
      },
      "source": [
        "import numpy as np\r\n",
        "import torch\r\n",
        "import torchvision\r\n",
        "\r\n",
        "\r\n",
        "def one_hot(y, n_classes=10):\r\n",
        "    return np.eye(n_classes)[y]\r\n",
        "\r\n",
        "\r\n",
        "def load_cifar10(root, flatten=False):\r\n",
        "    \"\"\"\r\n",
        "    Usage example:\r\n",
        "    > train_data, valid_data, test_data = load_cifar10(\"/data\", flatten=True)\r\n",
        "    > train_x, train_y = train_data\r\n",
        "    where both train_x and train_y are numpy arrays\r\n",
        "    train_x.shape == (40000, 3072) or train_x.shape == (40000, 3, 32, 32)\r\n",
        "    train_y.shape == (40000, 10), one-hot format\r\n",
        "    :param root: path where the cifar10 dataset will be downloaded, e.g. \"/tmp/data/\"\r\n",
        "    :param flatten: When True, dataset is reshaped to (num_examples, 3072), otherwise shape is (num_examples, 3, 32, 32)\r\n",
        "    :return: train, valid and test set in numpy arrays\r\n",
        "    \"\"\"\r\n",
        "    transform = torchvision.transforms.ToTensor()\r\n",
        "\r\n",
        "    train_dataset = torchvision.datasets.CIFAR10(root, train=True, transform=transform, download=True)\r\n",
        "    test_dataset = torchvision.datasets.CIFAR10(root, train=False, transform=transform, download=True)\r\n",
        "\r\n",
        "    # randomly split train into train/valid\r\n",
        "    perm = np.random.RandomState(seed=1).permutation(\r\n",
        "        range(len(train_dataset)))  # fix seed to have same split every time.\r\n",
        "    x = [train_dataset[i][0] for i in perm]  # train_dataset.data[perm]\r\n",
        "    y = [one_hot(train_dataset[i][1]) for i in perm]\r\n",
        "    train_x, train_y = x[:40000], y[:40000]\r\n",
        "    valid_x, valid_y = x[40000:], y[40000:]\r\n",
        "    test_x = [test_dataset[i][0] for i in range(len(test_dataset))]\r\n",
        "    test_y = [one_hot(test_dataset[i][1]) for i in range(len(test_dataset))]\r\n",
        "\r\n",
        "    # convert to numpy arrays after stacking\r\n",
        "    train_x = torch.stack(train_x).cpu().numpy()\r\n",
        "    train_y = np.stack(train_y)\r\n",
        "    valid_x = torch.stack(valid_x).cpu().numpy()\r\n",
        "    valid_y = np.stack(valid_y)\r\n",
        "    test_x = torch.stack(test_x).cpu().numpy()\r\n",
        "    test_y = np.stack(test_y)\r\n",
        "\r\n",
        "    if flatten:\r\n",
        "        train_x = train_x.reshape(-1, 32 * 32 * 3)\r\n",
        "        valid_x = valid_x.reshape(-1, 32 * 32 * 3)\r\n",
        "        test_x = test_x.reshape(-1, 32 * 32 * 3)\r\n",
        "\r\n",
        "    # Package everything\r\n",
        "    train_data = train_x, train_y\r\n",
        "    valid_data = valid_x, valid_y\r\n",
        "    test_data = test_x, test_y\r\n",
        "\r\n",
        "    return train_data, valid_data, test_data\r\n",
        "\r\n",
        "\r\n",
        "class NN(object):\r\n",
        "    def __init__(self,\r\n",
        "                 hidden_dims=(1024, 512, 64, 64),\r\n",
        "                 epsilon=1e-6,\r\n",
        "                 lr=0.01,\r\n",
        "                 batch_size=64,\r\n",
        "                 seed=1,\r\n",
        "                 activation=\"relu\",\r\n",
        "                 data=None\r\n",
        "                 ):\r\n",
        "\r\n",
        "        self.hidden_dims = hidden_dims\r\n",
        "        self.n_hidden = len(hidden_dims)\r\n",
        "        self.lr = lr\r\n",
        "        self.batch_size = batch_size\r\n",
        "        self.seed = seed\r\n",
        "        self.activation_str = activation\r\n",
        "        self.epsilon = epsilon\r\n",
        "\r\n",
        "        self.train_logs = {'train_accuracy': [], 'validation_accuracy': [], 'train_loss': [], 'validation_loss': []}\r\n",
        "\r\n",
        "        if data is None:\r\n",
        "            # for testing, do NOT remove or modify\r\n",
        "            self.train, self.valid, self.test = (\r\n",
        "                (np.random.rand(400, 3072), one_hot(np.random.randint(0, 10, 400))),\r\n",
        "                (np.random.rand(400, 3072), one_hot(np.random.randint(0, 10, 400))),\r\n",
        "                (np.random.rand(400, 3072), one_hot(np.random.randint(0, 10, 400)))\r\n",
        "        )\r\n",
        "        else:\r\n",
        "            self.train, self.valid, self.test = data\r\n",
        "\r\n",
        "\r\n",
        "    def initialize_weights(self, dims):        \r\n",
        "        if self.seed is not None:\r\n",
        "            np.random.seed(self.seed)\r\n",
        "\r\n",
        "        self.weights = {}\r\n",
        "        # self.weights is a dictionnary with keys W1, b1, W2, b2, ..., Wm, Bm where m - 1 is the number of hidden layers\r\n",
        "        all_dims = [dims[0]] + list(self.hidden_dims) + [dims[1]]\r\n",
        "        for layer_n in range(1, self.n_hidden + 2):\r\n",
        "            # WRITE CODE HERE\r\n",
        "\r\n",
        "            # self.n_hidden + 2, 2 is due to the input and output layers\r\n",
        "            # dims[0] is the dimension of the flattened input, dims[1] is the dimension of the output\r\n",
        "            # i.e. the number of classes.\r\n",
        "\r\n",
        "            # biases are initialized to zero\r\n",
        "            self.weights[f\"b{layer_n}\"] = np.zeros((1, all_dims[layer_n]))\r\n",
        "            \r\n",
        "            # weights are initialized according to the Glorot method\r\n",
        "            \r\n",
        "            # uniform distribution range: d_l\r\n",
        "            d_l = np.sqrt(6/(all_dims[layer_n-1]+all_dims[layer_n]))\r\n",
        "            self.weights[f\"W{layer_n}\"] = np.random.uniform(-d_l,d_l,(all_dims[layer_n-1], all_dims[layer_n]))\r\n",
        "            \r\n",
        "            # weights are initialized according to the Normal Distribution\r\n",
        "            # self.weights[f\"W{layer_n}\"] = np.random.normal(0,np.sqrt(0.1),(all_dims[layer_n-1], all_dims[layer_n]))\r\n",
        "\r\n",
        "\r\n",
        "    def relu(self, x, grad=False):\r\n",
        "        if grad:\r\n",
        "            # WRITE CODE HERE\r\n",
        "            return 1.0 * (x > 0)\r\n",
        "        # WRITE CODE HERE\r\n",
        "        return x * (x > 0)\r\n",
        "\r\n",
        "\r\n",
        "    def sigmoid(self, x, grad=False):\r\n",
        "        if grad:\r\n",
        "            # WRITE CODE HERE\r\n",
        "            return self.sigmoid(x,grad=False)*(1-self.sigmoid(x,grad=False))\r\n",
        "        # WRITE CODE HERE\r\n",
        "        return (1+np.exp(-x))**(-1)\r\n",
        "\r\n",
        "\r\n",
        "    def tanh(self, x, grad=False):\r\n",
        "        if grad:\r\n",
        "            # WRITE CODE HERE\r\n",
        "            return 1-self.tanh(x,grad=False)**2\r\n",
        "        # WRITE CODE HERE\r\n",
        "        return np.tanh(x)\r\n",
        "\r\n",
        "\r\n",
        "    def activation(self, x, grad=False):\r\n",
        "        if self.activation_str == \"relu\":\r\n",
        "            # WRITE CODE HERE\r\n",
        "            return self.relu(x, grad)\r\n",
        "        elif self.activation_str == \"sigmoid\":\r\n",
        "            # WRITE CODE HERE\r\n",
        "            return self.sigmoid(x, grad)\r\n",
        "        elif self.activation_str == \"tanh\":\r\n",
        "            # WRITE CODE HERE\r\n",
        "            return self.tanh(x, grad)\r\n",
        "        else:\r\n",
        "            raise Exception(\"invalid\")\r\n",
        "\r\n",
        "    def softmax(self, x):\r\n",
        "        # Remember that softmax(x-C) = softmax(x) when C is a constant.\r\n",
        "        # WRITE CODE HERE\r\n",
        "        \r\n",
        "        # batch_size = x.shape[0]\r\n",
        "        # normalizers = np.reshape(np.sum(np.exp(x),axis=1),(batch_size,1))\r\n",
        "        # return np.exp(x)/normalizers\r\n",
        "        x = x-np.max(x,axis=1,keepdims=True)\r\n",
        "        normalizers = np.sum(np.exp(x),axis=len(x.shape)-1, keepdims=True)\r\n",
        "        # print(normalizers.shape)\r\n",
        "        return np.exp(x)/normalizers\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        cache = {\"Z0\": x}\r\n",
        "        # cache is a dictionnary with keys Z0, A1, Z1, ..., Am, Zm where m - 1 is the number of hidden layers\r\n",
        "        # Ai corresponds to the preactivation at layer i, Zi corresponds to the activation at layer i\r\n",
        "        # WRITE CODE HERE\r\n",
        "        for layer_n in range(1,self.n_hidden+1): # Last layer's activation should be softmax, that's why we differentiate it with the rest\r\n",
        "            cache[f\"A{layer_n}\"] = cache[f\"Z{layer_n-1}\"]@self.weights[f\"W{layer_n}\"]+self.weights[f\"b{layer_n}\"]\r\n",
        "            cache[f\"Z{layer_n}\"] = self.activation(cache[f\"A{layer_n}\"], grad=False)\r\n",
        "        \r\n",
        "        cache[f\"A{layer_n+1}\"] = cache[f\"Z{layer_n}\"]@self.weights[f\"W{layer_n+1}\"]+self.weights[f\"b{layer_n+1}\"]\r\n",
        "        cache[f\"Z{layer_n+1}\"] = self.softmax(cache[f\"A{layer_n+1}\"])\r\n",
        "        return cache\r\n",
        "    \r\n",
        "    def backward(self, cache, labels):\r\n",
        "\r\n",
        "        output = cache[f\"Z{self.n_hidden + 1}\"]\r\n",
        "        grads = {}\r\n",
        "        # grads is a dictionnary with keys dAm, dWm, dbm, dZ(m-1), dA(m-1), ..., dW1, db1\r\n",
        "        # WRITE CODE HERE\r\n",
        "        \r\n",
        "        # Recall that cross entropy and softmax play well together!\r\n",
        "\r\n",
        "        # Gradients in a batch should be averaged along the batch dimension, but\r\n",
        "        # not until all gradients are computed! Until then, the gradient for each\r\n",
        "        # sample should be kept alive, and when backprop is complete, then all grads\r\n",
        "        # can be averaged along the batch dimension to yield a single gradient direction.\r\n",
        "\r\n",
        "        batch_size = output.shape[0]\r\n",
        "\r\n",
        "\r\n",
        "        # Now this gradient would be batch_size x 10, in the end I'll take the mean.\r\n",
        "        # labels are already one-hotted\r\n",
        "        grads[f\"dA{self.n_hidden+1}\"] = -(labels-output)\r\n",
        "        \r\n",
        "        \r\n",
        "        # Gradients for post-activations and pre-activations, weights and biases\r\n",
        "        for layer_n in range(self.n_hidden+1,0,-1):\r\n",
        "        \r\n",
        "            grads[f\"dW{layer_n}\"] = (cache[f\"Z{layer_n-1}\"].T)@(grads[f\"dA{layer_n}\"])/batch_size\r\n",
        "            # grads[f\"dW{layer_n}\"] = (np.expand_dims(grads[f\"dA{layer_n}\"],-1))@(np.expand_dims(cache[f\"Z{layer_n-1}\"],1))\r\n",
        "            # dims = grads[f\"dW{layer_n}\"].shape\r\n",
        "            # grads[f\"dW{layer_n}\"] = np.reshape(grads[f\"dW{layer_n}\"],(dims[0],dims[2],dims[1]))\r\n",
        "            \r\n",
        "            # grads[f\"dW{layer_n}\"] = np.reshape(grads[f\"dW{layer_n}\"],(1,dims[0],dims[1]))\r\n",
        "\r\n",
        "            grads[f\"db{layer_n}\"] = np.mean(grads[f\"dA{layer_n}\"],axis=0, keepdims=True)\r\n",
        "            \r\n",
        "            if (layer_n != 1):\r\n",
        "                grads[f\"dZ{layer_n-1}\"] = ((self.weights[f\"W{layer_n}\"])@(grads[f\"dA{layer_n}\"].T)).T\r\n",
        "                grads[f\"dA{layer_n-1}\"] = grads[f\"dZ{layer_n-1}\"]*self.activation(cache[f\"A{layer_n-1}\"],grad=True)\r\n",
        "                \r\n",
        "        # Now we should take the average along the batch dimension\r\n",
        "        # for param in grads.keys():\r\n",
        "            # grads[param] = np.mean(grads[param], axis=0)\r\n",
        "\r\n",
        "\r\n",
        "        return grads\r\n",
        "\r\n",
        "    def update(self, grads):\r\n",
        "        for layer in range(1, self.n_hidden + 2):\r\n",
        "            # WRITE CODE HERE\r\n",
        "\r\n",
        "            # updating weights W\r\n",
        "            self.weights[f\"W{layer}\"] = self.weights[f\"W{layer}\"] - self.lr*grads[f\"dW{layer}\"]\r\n",
        "\r\n",
        "            # updating biases b\r\n",
        "            self.weights[f\"b{layer}\"] = self.weights[f\"b{layer}\"] - self.lr*grads[f\"db{layer}\"]\r\n",
        "\r\n",
        "    def one_hot(self, y, n_classes=None):\r\n",
        "        n_classes = n_classes or self.n_classes\r\n",
        "        return np.eye(n_classes)[y]\r\n",
        "\r\n",
        "    def loss(self, prediction, labels):\r\n",
        "        prediction[np.where(prediction < self.epsilon)] = self.epsilon\r\n",
        "        prediction[np.where(prediction > 1 - self.epsilon)] = 1 - self.epsilon\r\n",
        "        # WRITE CODE HERE\r\n",
        "        # labels are one-hot\r\n",
        "        sample_losses = [-np.log(prediction[m,np.argmax(labels,axis=1)[m]]) for m in range(len(prediction))]\r\n",
        "        return np.mean(sample_losses)\r\n",
        "\r\n",
        "    def compute_loss_and_accuracy(self, X, y):\r\n",
        "        one_y = y\r\n",
        "        y = np.argmax(y, axis=1)  # Change y to integers\r\n",
        "        cache = self.forward(X)\r\n",
        "        predictions = np.argmax(cache[f\"Z{self.n_hidden + 1}\"], axis=1)\r\n",
        "        accuracy = np.mean(y == predictions)\r\n",
        "        loss = self.loss(cache[f\"Z{self.n_hidden + 1}\"], one_y)\r\n",
        "        return loss, accuracy, predictions\r\n",
        "\r\n",
        "    def train_loop(self, n_epochs):\r\n",
        "        X_train, y_train = self.train\r\n",
        "        y_onehot = y_train\r\n",
        "        dims = [X_train.shape[1], y_onehot.shape[1]]\r\n",
        "        self.initialize_weights(dims)\r\n",
        "\r\n",
        "        n_batches = int(np.ceil(X_train.shape[0] / self.batch_size))\r\n",
        "\r\n",
        "        for epoch in range(n_epochs):\r\n",
        "            for batch in range(n_batches):\r\n",
        "                minibatchX = X_train[self.batch_size * batch:self.batch_size * (batch + 1), :]\r\n",
        "                minibatchY = y_onehot[self.batch_size * batch:self.batch_size * (batch + 1), :]\r\n",
        "                # WRITE CODE HERE\r\n",
        "                cache = self.forward(minibatchX)\r\n",
        "                gradients = self.backward(cache,minibatchY)\r\n",
        "                self.update(gradients)\r\n",
        "                \r\n",
        "                if(np.mod(batch,100)==0):\r\n",
        "                    train_loss, train_accuracy, _ = self.compute_loss_and_accuracy(minibatchX, minibatchY)\r\n",
        "                    print(f\"epoch {epoch}, batch id:{batch}, train_loss={train_loss}, train_accuracy={train_accuracy}\")\r\n",
        "\r\n",
        "\r\n",
        "            X_train, y_train = self.train\r\n",
        "            train_loss, train_accuracy, _ = self.compute_loss_and_accuracy(X_train, y_train)\r\n",
        "            X_valid, y_valid = self.valid\r\n",
        "            valid_loss, valid_accuracy, _ = self.compute_loss_and_accuracy(X_valid, y_valid)\r\n",
        "\r\n",
        "            self.train_logs['train_accuracy'].append(train_accuracy)\r\n",
        "            self.train_logs['validation_accuracy'].append(valid_accuracy)\r\n",
        "            self.train_logs['train_loss'].append(train_loss)\r\n",
        "            self.train_logs['validation_loss'].append(valid_loss)\r\n",
        "\r\n",
        "        return self.train_logs\r\n",
        "\r\n",
        "    def evaluate(self):\r\n",
        "        X_test, y_test = self.test\r\n",
        "        test_loss, test_accuracy, _ = self.compute_loss_and_accuracy(X_test, y_test)\r\n",
        "        return test_loss, test_accuracy\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca7Df2foG5_r",
        "outputId": "665ea794-8b67-4c71-fec9-a335601030d8"
      },
      "source": [
        "data = load_cifar10('/tmp/data', flatten=True)  # can use flatten=False to get the image shape.\r\n",
        "train_data, valid_data, test_data = data\r\n",
        "image, label = train_data[0][0], train_data[1][0]\r\n",
        "image.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3072,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "x3cKQ4qny4Oq"
      },
      "source": [
        "import time\n",
        "nn = NN(data=data)\n",
        "start = time.time()\n",
        "logs = nn.train_loop(1)\n",
        "print(time.time()-start)\n",
        "print(nn.evaluate())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QM9lTZIAyJq6",
        "outputId": "8addab33-c6c5-4e22-e9ac-c5f0dda8c83b"
      },
      "source": [
        "print(nn.weights.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['b1', 'W1', 'b2', 'W2', 'b3', 'W3', 'b4', 'W4', 'b5', 'W5'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAYD9dWMFMiR"
      },
      "source": [
        "last_layer = 5\r\n",
        "\r\n",
        "N = np.reshape(np.array([10**j for j in range(1,6)]),(1,5))\r\n",
        "k = np.reshape(np.arange(1,6),(5,1))\r\n",
        "N = N*k\r\n",
        "p = 100\r\n",
        "# Ns \r\n",
        "num_of_Ns = 15\r\n",
        "rows = np.random.choice([0,1,2,3,4],num_of_Ns)\r\n",
        "cols = np.random.choice([0,1,2,3,4],num_of_Ns)\r\n",
        "\r\n",
        "Ns = [N[rows[i],cols[i]] for i in range(len(rows))]\r\n",
        "Ns = np.sort(Ns)\r\n",
        "\r\n",
        "sample_id = np.random.randint(0,train_data[0].shape[0])\r\n",
        "x_ = train_data[0][sample_id]\r\n",
        "y_onehot = train_data[1][sample_id]\r\n",
        "y_ = np.argmax(y_onehot)\r\n",
        "\r\n",
        "max_diff = []\r\n",
        "\r\n",
        "for n in Ns:\r\n",
        "    epsilon = 1/n\r\n",
        "    nabla_N = []\r\n",
        "    exact_grads = []\r\n",
        "    for k in range(1,p+1):\r\n",
        "        grad_approx = (loss_single_sample(nn,x_,y_,epsilon,k)-loss_single_sample(nn,x_,y_,-epsilon,k))/(2*epsilon)\r\n",
        "        nabla_N.append(grad_approx)\r\n",
        "\r\n",
        "        grad_exact = exact_grad(nn,nn.forward(x_),y_onehot,k)\r\n",
        "        exact_grads.append(grad_exact)\r\n",
        "    \r\n",
        "    difference = np.max(np.abs(np.array(nabla_N)-np.array(exact_grads)))\r\n",
        "    # print(difference)\r\n",
        "    max_diff.append(difference)\r\n",
        "\r\n",
        "\r\n",
        "# print(nabla_N)\r\n",
        "# print(len(nabla_N))\r\n",
        "# print(exact_grads)\r\n",
        "# print(len(exact_grads))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvGOQEyWS2m8"
      },
      "source": [
        "import pickle\r\n",
        "with open('max_diffs.pickle', 'rb') as f:\r\n",
        "    dict = pickle.load(f)\r\n",
        "\r\n",
        "Ns = dict['Ns']\r\n",
        "max_diff = dict['diff']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "id": "G-AqUfzQWKOP",
        "outputId": "641b854d-8c59-4414-dd3e-8a251fa4636e"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "from matplotlib.pyplot import figure\r\n",
        "figure(num=None, figsize=(10, 8), dpi=80, facecolor='w', edgecolor='k')\r\n",
        "\r\n",
        "plt.loglog(Ns, max_diff, '*', linestyle='dashed')\r\n",
        "\r\n",
        "plt.xlabel('N')\r\n",
        "plt.ylabel('maximum difference')\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 800x640 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGwEij_TKWHP",
        "outputId": "bd06607d-81b6-4af6-fa4e-1f74be3a9b35"
      },
      "source": [
        "nn.weights[f\"W{last_layer}\"].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOG0cxklbCyV"
      },
      "source": [
        "def loss_single_sample(nn,x,y,eps,k):\r\n",
        "    dims = nn.weights[f\"W{last_layer}\"].shape\r\n",
        "    row = np.int(np.floor(k/dims[1]))\r\n",
        "    col = np.mod(k,dims[1])-1\r\n",
        "    nn.weights[f\"W{last_layer}\"][row,col] = nn.weights[f\"W{last_layer}\"][row,col] + eps\r\n",
        "    cache = nn.forward(x)\r\n",
        "    nn.weights[f\"W{last_layer}\"][row,col] = nn.weights[f\"W{last_layer}\"][row,col] - eps\r\n",
        "    pred = cache[f\"Z{last_layer}\"][0]\r\n",
        "    return -np.log(pred[y])\r\n",
        "\r\n",
        "def exact_grad(nn,cache,y,k):\r\n",
        "\r\n",
        "    dims = nn.weights[f\"W{last_layer}\"].shape\r\n",
        "    row = np.int(np.floor(k/dims[1]))\r\n",
        "    col = np.mod(k,dims[1])-1\r\n",
        "\r\n",
        "    output = cache[f\"Z{last_layer}\"]\r\n",
        "    grads = {}\r\n",
        "\r\n",
        "    # labels are already one-hotted\r\n",
        "    grads[f\"dA{last_layer}\"] = -(y-output)\r\n",
        "    grads[f\"dW{last_layer}\"] = (cache[f\"Z{last_layer-1}\"].T)@(grads[f\"dA{last_layer}\"])\r\n",
        "    return grads[f\"dW{last_layer}\"][row,col]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}